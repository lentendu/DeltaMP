# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Christina Wei√übecker, Anna Heintz-Buschart, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# load modules
module load DeltaMP/DELTAMP_VERSION

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
. $BIN/check_previous_step

# Choose a sample
LIB=(`sed -n "$ARRAY_TASK"'p' config/lib4.list`)
SAMP=${LIB[0]}
if [ ! -z "$(grep $SAMP config/*.missing 2> /dev/null)" ]
then
	MISSING=$(grep -H $SAMP config/*.missing | sed 's@.*/@@;s@\.missing.*@@')
	echo $MISSING > missing
	echo -e "The sample $SAMP had no read at the end of the step $MISSING.\nSkip"
	(. $BIN/list_step_files.sh)
	echo END
	exit 0
fi
LIB_NAME=(`echo ${LIB[@]} | cut -d " " -f 2-`)
LOG=mothur.${TECH}_trim.$SAMP.logfile
cd processing && mkdir $SAMP
cd $SAMP

# Trim for each library of the sample and merge
for i in "${LIB_NAME[@]}"
do
	if [ $TECH == "454" ]
	then
		if [ $BDIFFS == "a" ]
		then
			unset BDIFFS && BDIFFS=$(grep ${i#*.} ../bdiffs.$SUBPROJECT | cut -d " " -f 2)
		fi
		# Get quality and length for trimming
		QUAL=`cut -d "." -f 2 $EXEC/quality_check/trimming.parameters.txt`
		LENGTH=`cut -d "." -f 1 $EXEC/quality_check/trimming.parameters.txt`
		if [ $BARC_ANCH == "yes" ] ; then BANCH="^" ; else BANCH="X" ; fi
		if [ $PRIM_ANCH == "yes" ] ; then PANCH="^" ; else PANCH="" ; fi
		if [ $DENOISE == "yes" ]
		then
			#trim flows with FlowClus, using all set of primers allowed by PDIFFS mismatches as detected by cutadapt (also work with MOTHUR trim.seqs) because FlowClust does not take into account homopolymers extension in primer mismatches (which append quite often for example for ITS4)
			if [ $EXT == "bz2" ]
			then
				bunzip2 -c $RAW_DIR/$i.sff.$EXT > $i.sff
			else
				unpigz -p 1 -c $RAW_DIR/$i.sff.$EXT > $i.sff
			fi
			process_sff.py -i $i.sff -f -o ./ 
			rm $i.sff
			ln -s $EXEC/libraries/fasta/oligos.$i ./
			sed 's/forward/primer,'$i'/;s/^#//;s/barcode/midtag/' $EXEC/libraries/fasta/oligos.$i | awk '{if($1=="midtag"){print $1,$3,$2} else print $0}' | sed 's/ /,/g' > master.$i.csv
			FWD_E=$(awk -v F=${#FWD} -v P=$PDIFFS 'BEGIN{printf "%.2f",P/F+0.005}')
			# allow looping over multiple barcodes for same sample
			while read name samp mid
			do
				MID_E=$(awk -v F=${#mid} -v B=$BDIFFS 'BEGIN{printf "%.2f",B/F+0.005}')
				awk '{print $1}' $EXEC/libraries/fasta/$i.fasta | cutadapt -g ${BANCH}${mid} -e ${MID_E} -O ${#mid} --no-indels --trimmed-only - 2> log.cutadapt.${i}_${mid} | cutadapt -g ${PANCH}${FWD} -e ${FWD_E} --trimmed-only --info-file=cutadapt.${i}_$mid - 2>> log.cutadapt.${i}_${mid} > ${i}_$mid.cut.fasta
				while read count prim
				do
					sed '1 s/,[^,]*$/_'$count','$prim'/' master.$i.csv
				done < <(awk -v F=${#FWD} 'length($5)>=F{print $5}' cutadapt.${i}_$mid | sort -u | awk '{print NR,$1}') > master.all.$i.csv
			done < <(grep "^midtag" master.$i.csv | tr "," "\t") > master.all.$i.csv
			# Filter reads for each combination of barcode and primer variant into flows
			MID=$(grep -m 1 midtag master.all.$i.csv | cut -d "," -f 3)
			if [[ ($TARG == "ITS") && ($ITSX != "no") ]] || [[ $CLIPPING == "both" ]]
			then
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW
			else # truncate end of sequences
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -t $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW 
			fi
			# Merge flows for each barcode
			awk -v I=$i '{if($0~"^primer"){F=$0} else if($0~"^reverse"){R=$0} else if($0~"^midtag"){M[NR]=$0}}END{for(x in M){split(M[x],mid,",");sub(I".*,",I"_"mid[3]",",F);printf "%s\n%s\n%s\n",F,R,M[x]}}' master.$i.csv > master.$i.ok.csv
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				for j in ${k%_*}_[0-9]*.flow; do sed '1d' $j ; done | cat <(head -1 $(ls ${k%_*}_*.flow | head -1)) - > ${k}.flow
				rm ${k%_*}_[0-9]*.flow ${k}.cut.fasta cutadapt.${k}
			done
			# Denoise for each barcode separetedly
			FlowClus -b -m master.$i.ok.csv -j 0.50 -ch -cu .denoised.fasta -cm .denoised.names -o $i.denoised_all.fasta
			# Merge all denoised reads and mapping files from the same library
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				awk '{if($2~","){sub(",*"$1"$","",$2);print $1"\t"$1","$2} else print}' ${k}.denoised.names >> $i.temp.names
				awk '{print $1}' ${k}.denoised.fasta >> $i.temp.fasta
				rm ${k}.denoised* ${k}.flow
			done
			mothur "#set.logfile(name=$LOG, append=T);
			trim.seqs(fasta=$i.temp.fasta, name=$i.temp.names, maxambig=$MAXAMBIG, processors=$NCPUS)"
			rm $i.txt $i.temp.scrap.fasta $i.temp*.qual $i.temp.fasta $i.temp.names
		else
			if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
			then
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=./);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, processors=$NCPUS)"
				if [ $SEQ_DIR == "both" ]
				then
					mkdir rev.$i
					mothur "#set.logfile(name=$LOG, append=T);
					set.dir(input=$EXEC/libraries/fasta, output=rev.$i);
					trim.seqs(fasta=$i.fasta, oligos=oligos.rev.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, processors=$NCPUS, flip=T)"
					cat $i.trim.fasta rev.$i/$i.trim.fasta > tmp.$i.fasta && mv tmp.$i.fasta $i.trim.fasta
					rm -r rev.$i/
				fi
			elif [ $CLIPPING == "both" ]
			then
				# ensure reverse primer is removed at 5' end
				BLENGTH=$(awk '$0!~"^>"{match($1,"[ATCG][ATCG]*");print RLENGTH; exit}' $EXEC/libraries/fasta/oligos.${LIB_NAME}.fasta)
				BDISS=$(awk -v L=$BLENGTH -v D=$BDIFFS 'BEGIN{printf "%.2g\n", D/L}')
				RVS_RC=$(echo -e ">rvs\n$RVS" | seqkit seq -p -t dna -v | tail -1)
				DISS=`awk -v F=${#FWD} -v R=${#RVS} -v D=$PDIFFS 'BEGIN{DISS=D/F;if(D/R>DISS){DISS=D/R};printf "%.2g\n", DISS}'`
				cutadapt -g file:$EXEC/libraries/fasta/oligos.${LIB_NAME}.fasta -e ${BDISS} -O $BLENGTH --no-indels --trimmed-only $EXEC/libraries/fasta/$LIB_NAME.fastq 2> log.cutadapt.$LIB_NAME | cutadapt -a ${PANCH}$FWD...$RVS_RC -e $DISS --no-indels --trimmed-only -m $LENGTH -M $MAXLEN -o $LIB_NAME.fastq - >> log.cutadapt.$LIB_NAME
				if [ $SEQ_DIR == "both" ]
				then
					FWD_RC=$(echo -e ">fwd\n$FWD" | seqkit seq -p -t dna -v | tail -1)
					cutadapt -g file:$EXEC/libraries/fasta/oligos.${LIB_NAME}.fasta -e ${BDISS} -O $BLENGTH --no-indels --trimmed-only $EXEC/libraries/fasta/$LIB_NAME.fastq 2>> log.cutadapt.$LIB_NAME | cutadapt -a ${PANCH}$RVS...$FWD_RC -e $DISS --no-indels --trimmed-only -m $LENGTH -M $MAXLEN - 2>> log.cutadapt.$LIB_NAME | vsearch --quiet --fastx_revcomp - --fastqout $LIB_NAME.rev.fastq
					cat $LIB_NAME.fastq $LIB_NAME.rev.fastq > tmp.$LIB_NAME.fastq && mv tmp.$LIB_NAME.fastq $LIB_NAME.fastq
				fi
				mothur "#set.logfile(name=$LOG, append=T);
				fastq.info(fastq=$LIB_NAME.fastq);
				trim.seqs(fasta=current, qfile=current, qaverage=$QUAL, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, processors=$NCPUS)"
			else
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=./);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, keepfirst=$LENGTH, processors=$NCPUS)"
				if [ $SEQ_DIR == "both" ]
				then
					mkdir rev.$i
					mothur "#set.logfile(name=$LOG, append=T);
					set.dir(input=$EXEC/libraries/fasta, output=rev.$i);
					trim.seqs(fasta=$i.fasta, oligos=oligos.rev.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, keepfirst=$LENGTH, processors=$NCPUS, flip=T)"
					cat $i.trim.fasta rev.$i/$i.trim.fasta > tmp.$i.fasta && mv tmp.$i.fasta $i.trim.fasta
					rm -r rev.$i/
				fi
			fi
		fi
	elif [ $TECH == "Illumina" ]
	then
		# trim
		if [ $TRUNCBE == "no" ]
		then
			# Concatenate reads in both direction
			if [ -f $EXEC/libraries/fastq/$FWD_NAME.$RVS_NAME.$i.pairend.fastq.$EXT ]
			then
				if [ -f $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT ]
				then
					vsearch --quiet --fastx_revcomp $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT --fastqout - | cat <(eval $DECOMP $EXEC/libraries/fastq/$FWD_NAME.$RVS_NAME.$i.pairend.fastq.$EXT) - | eval $COMP > $i.pairend.fastq.$EXT
				else
					ln -s $EXEC/libraries/fastq/$FWD_NAME.$RVS_NAME.$i.pairend.fastq.$EXT $PWD/$i.pairend.fastq.$EXT
				fi
			elif [ -f $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT ]
			then
				vsearch --quiet --fastx_revcomp $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT --fastqout - | eval $COMP > $i.pairend.fastq.$EXT
			fi
			# Quality filtering
			QUAL=`cat $EXEC/quality_check/optimized.quality.txt`
			if [ $QFILT == "average" ]
			then
				eval $DECOMP $i.pairend.fastq.$EXT > $i.pairend.fastq
				mothur "#set.logfile(name=$LOG, append=T);
				fastq.info(fastq=$i.pairend.fastq);
				trim.seqs(fasta=$i.pairend.fasta, qfile=$i.pairend.qual, qaverage=$QUAL, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$MINLEN, maxlength=$MAXLEN, processors=$NCPUS)"
				rm $i.pairend.fastq $i.pairend.fasta $i.pairend.scrap.fasta $i.pairend.*qual
			elif [ $QFILT == "maxee" ]
			then
				vsearch --quiet --fastq_filter $i.pairend.fastq.$EXT --fastq_maxee $QUAL --fastq_maxlen $MAXLEN --fastq_maxns $MAXAMBIG --fastq_minlen $MINLEN --fastaout - | twofasta | awk '{if($1~"^>"){gsub(":","_",$1)};print $1}' > $i.pairend.trim.fasta
				rm $i.pairend.fastq.$EXT
			fi
		else
			# Truncate and pair-end merge
			read FWD_LIB RVS_LIB < <(grep $i $EXEC/config/lib3.list | cut -f 2-3)
			for x in ${FWD_NAME} ${RVS_NAME}
			do
				if [ $x == "$FWD_NAME" ] ; then y=${RVS_NAME} ; else y=${FWD_NAME} ; fi
				if [ -f $EXEC/libraries/fastq/$x.$y.$i.pairend.fastq.$EXT ]
				then
					if [ $TRUNCLEN == "no" ]
					then
						read FEE REE < <(paste $EXEC/quality_check/$x.fwd.optimized.quality.txt $EXEC/quality_check/$y.rvs.optimized.quality.txt)
					else
						read FTLEN FEE RTLEN REE < <(paste $EXEC/quality_check/$x.fwd.optimized.quality.txt $EXEC/quality_check/$y.rvs.optimized.quality.txt)
						TRUNCEEF=" --fastq_trunclen $FTLEN"
						TRUNCEER=" --fastq_trunclen $RTLEN"
					fi
			        vsearch --quiet --fastq_filter $EXEC/libraries/fastq/$x.${FWD_LIB}.fastq.$EXT --fastq_maxns $MAXAMBIG --fastq_truncee $FEE$TRUNCEEF --fastqout $x.${FWD_LIB}.trunc.fastq
			        vsearch --quiet --fastq_filter $EXEC/libraries/fastq/$y.${RVS_LIB}.fastq.$EXT --fastq_maxns $MAXAMBIG --fastq_truncee $REE$TRUNCEER --fastqout $y.${RVS_LIB}.trunc.fastq
					join <(sed -n '1~4{s/[\t ].*$//;p}' $x.${FWD_LIB}.trunc.fastq | sort) <(sed -n '1~4{s/[\t ].*$//;p}' $y.${RVS_LIB}.trunc.fastq | sort) | sed 's/^@//' > $x.$y.$i.trunc.accnos
					seqkit grep -f $x.$y.$i.trunc.accnos $x.${FWD_LIB}.trunc.fastq > $x.$i.fwd.filtered.fastq
					seqkit grep -f $x.$y.$i.trunc.accnos $y.${RVS_LIB}.trunc.fastq > $y.$i.rvs.filtered.fastq
					rm $x.${FWD_LIB}.trunc.fastq $y.${RVS_LIB}.trunc.fastq $x.$y.$i.trunc.accnos
					if [ $ASV == "no" ]
					then
						if [ $PALG == "vsearch" ]
						then
							ASCII=$(vsearch --fastq_chars $x.$i.fwd.filtered.fastq 2>&1 | grep -m 1 "^Guess" | sed 's/.* //')
							PCTTRESH=$(awk -v P=$PTRESH 'BEGIN{print (1-P)*100}')
							vsearch --quiet --threads $NCPUS --fastq_mergepairs $x.$i.fwd.filtered.fastq --reverse $y.$i.rvs.filtered.fastq --fastq_ascii $ASCII --fastq_minovlen $MIN_OV --fastq_maxdiffpct $PCTTRESH --fastq_allowmergestagger --fastqout $x.$y.$i.pairend.fastq 2> log.pairend.$x.$i.txt
						elif [ $PALG == "ngmerge" ]
						then
							NGmerge -1 $x.$i.fwd.filtered.fastq -2 $y.$i.rvs.filtered.fastq -m $MIN_OV -p $(echo 1 - $PTRESH | bc) -v -y -o $x.$y.$i.pairend.fastq 2> log.pairend.$x.$i.txt
						else
							pandaseq -f $x.$i.fwd.filtered.fastq -r $y.$i.rvs.filtered.fastq -g log.pairend.$x.$i.txt -F -A $PALG -o $MIN_OV -O $((MAXLEN+MIN_OV-MINLEN)) -t $PTRESH -T $NCPUS > $x.$y.$i.pairend.fastq
						fi
					fi
				fi
			done
			# Concatenate both direction or start pseudo-pooling approach for dada2
			if [ $ASV == "no" ]
			then
				if [ -s $FWD_NAME.$RVS_NAME.$i.pairend.fastq ]
				then
					if [ -s $RVS_NAME.$FWD_NAME.$i.pairend.fastq ]
					then
						vsearch --fastx_revcomp $RVS_NAME.$FWD_NAME.$i.pairend.fastq --fastqout - | cat $FWD_NAME.$RVS_NAME.$i.pairend.fastq - | vsearch --quiet --fastq_filter - --fastq_maxns $MAXAMBIG --fastq_maxlen $MAXLEN --fastq_minlen $MINLEN --fastaout - | twofasta | sed '/>/{s/:/_/;s/[ \t].*$//;}' > $i.pairend.trim.fasta
						rm $RVS_NAME.$FWD_NAME.$i.pairend.fastq $FWD_NAME.$RVS_NAME.$i.pairend.fastq
					else
						vsearch --quiet --fastq_filter $FWD_NAME.$RVS_NAME.$i.pairend.fastq --fastq_maxns $MAXAMBIG --fastq_maxlen $MAXLEN --fastq_minlen $MINLEN --fastaout - | twofasta | sed '/>/{s/:/_/;s/[ \t].*$//;}' > $i.pairend.trim.fasta
						rm $FWD_NAME.$RVS_NAME.$i.pairend.fastq
					fi
				elif [ -s $RVS_NAME.$FWD_NAME.$i.pairend.fastq ]
				then
					vsearch --fastx_revcomp $RVS_NAME.$FWD_NAME.$i.pairend.fastq --fastqout - | vsearch --quiet --fastq_filter - --fastq_maxns $MAXAMBIG --fastq_maxlen $MAXLEN --fastq_minlen $MINLEN --fastaout - | twofasta | awk '{if($1~"^>"){gsub(":","_",$1)};print $1}' > $i.pairend.trim.fasta
					rm $RVS_NAME.$FWD_NAME.$i.pairend.fastq
				fi
			else
				Rscript --vanilla $BIN/Rscript_dada2_library.R $NCPUS $i $PERRUN
			fi
		fi
	fi
done


# Process trimmed reads of all libraries of the sample together
if [ $ASV == "no" ]
then
	# concatenate fasta files
	TRIMMED=(*.trim.fasta)
	if [ ${#TRIMMED[@]} -gt 1 ]
	then
		cat *.trim.fasta > $SAMP.trim.fasta
	else
		ln -s $TRIMMED $SAMP.trim.fasta
	fi
	FASTA=$SAMP.trim
	
	# Reverse-complement
	if [ $TECH == "454" ] && [ $FLIP == "true" ]
	then
		vsearch --quiet --fastx_revcomp $FASTA.fasta --fastaout - | twofasta > $FASTA.rc.fasta
		FASTA=$FASTA.rc
	fi
	
	# Dereplicate
	if [ $TECH == "454" ] && [ "$DENOISE" == "yes" ]
	then
		cat *.trim.names > $SAMP.names
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$FASTA.fasta, name=$SAMP.names, format=count);
		get.current()"
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
	else
		vsearch --no_progress --derep_fulllength $FASTA.fasta --sizeout --output - | twofasta | sed '/>/s/;/ /' | tee $FASTA.unique.fasta | sed -n "/>/{s/>//;s/ size=/\t/;p}" | cat <(echo -e "Representative_Sequence\ttotal") - > $FASTA.unique.count_table
		FASTA=$FASTA.unique
		COUNT=$FASTA
		echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
	fi
	
	# Subsample
	if [ $SUBSAMPLE == "yes" ]
	then
		SIZE=$(grep "Minimum" $EXEC/quality_check/$SUBPROJECT.summary.stat.tsv | cut -f 3 | cut -d "." -f 1)
		mothur "#set.logfile(name=$LOG, append=T);
		sub.sample(fasta=$FASTA.fasta, count=$COUNT.count_table, size=$SIZE);
		get.current()"
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
	fi
	
	# Precluster
	if [ $PRECLUST == "mothur" ]
	then
		# pre-cluster at max 1% after aligning to reference and removing the 5 % worse aligned reads
		if [ $TECH == "454" ] && [ $ITSX == "no" ]
		then
			PRECDIFF=$(( ${LENGTH} / 100 ))
		else
			PRECDIFF=$(twofasta $FASTA.fasta | awk -v M=$MAXLEN 'BEGIN{min=M}length($1)<M{min=length($1)}END{print int(min/100)'awk '$1!~"^>"{sum+=length($1)}END{print int(sum/(FNR/2)/100)}')
		fi
		if [ $PRECDIFF -ge 1 ]
		then
			mothur "#set.logfile(name=$LOG, append=T);
			set.dir(tempdefault=$DBFOLD);
			align.seqs(candidate=$FASTA.fasta, template=$DBCHOP.fasta, align=needleman, processors=$NCPUS);
			screen.seqs(fasta=current, count=$COUNT.count_table, optimize=start-end, criteria=95, processors=$NCPUS);
			filter.seqs(fasta=current, vertical=T, trump=., processors=$NCPUS);
			pre.cluster(fasta=current, count=current, diffs=$PRECDIFF, processors=$NCPUS);
			get.current()"
			unset FASTA COUNT
			FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
			COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
		else
			echo "The pre-culstering step was skipped because the smallest sequence have less than 100nt."
		fi
	elif [ $PRECLUST == "cdhit454" ]
	then
		# pre-cluster with cd-hit-454, allowing 1% dissimilarity with indel of max 1 nt long
		cdhit4542mothur () {
			bak=$1 ; fasta=$2 ; count=$3
			nl $bak | sed 's/>//;s/\.\.\.//' | awk '{print $4,$1,$2}' | sort -k 1,1 | join - <(sed '1d' $count | sort -k 1,1) | sort -k 3,3n -k 4,4nr | awk '{if(NR==1){nb=$3;printf "%s\t%s", $1,$2;sum=$4} else {if($3==nb){sum+=$4} else {nb=$3;printf "\t%s\n%s\t%s",sum,$1,$2;sum=$4}}}END{printf "\t%s\n",sum}' | sort -k 2,2n -t $'\t' | cut -f 1,3 | cat <(head -1 $count) - > ${count%.*}.precl.count_table
			obigrep --without-progress-bar --uppercase --id-list=<(sed '1d' ${count%.*}.precl.count_table | cut -f 1) $fasta | twofasta > ${fasta%.*}.precl.fasta
		}
		cd-hit-454 -T $NCPUS -B 1 -g 1 -M 6000 -c 0.99 -bak 1 -i $FASTA.fasta -o $FASTA.precl.fasta.temp
		cdhit4542mothur $FASTA.precl.fasta.temp.bak.clstr $FASTA.fasta $COUNT.count_table
		rm $FASTA.precl.fasta.temp*
		FASTA=$FASTA.precl
		COUNT=$COUNT.precl
		echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
	fi
	
	# ITSx or Chimera removal
	if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
	then
		ITSx --cpu $NCPUS -i $FASTA.fasta --save_regions $ITSX --preserve T --graphical F -o $FASTA.itsx
		awk '$0~"^>"{sub(">","");print $1}' $FASTA.itsx.$ITSX.fasta | sort | join -t $'\t' - <(sed '1d' $COUNT.count_table | sort -t $'\t' -k 1,1) | cat <(head -1 $COUNT.count_table) - > $COUNT.itsx.$ITSX.count_table
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$FASTA.itsx.$ITSX.fasta, count=$COUNT.itsx.$ITSX.count_table);
		get.current()"
		unset FASTA COUNT
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
	elif [ $CHIMERA1 == "yes" ]
	then
		if [ $TECH == "454" ] || [ $(sed -n '$=' $COUNT.count_table) -lt 20000 ]
		then
			twofasta $FASTA.fasta | awk '{print $1}' | paste - - | sed 's/^>//' | sort -k 1,1 | join - <(sort -k 1,1 $COUNT.count_table) | awk '{print ">"$1";size="$3"\n"$2}' | vsearch --no_progress --uchime_denovo - --nonchimeras - --xsize | twofasta > $FASTA.ok.fasta
		else
			. $BIN/parallel_uchime.sh
		fi
		if [ $(grep -c "^>" $FASTA.fasta) -eq $(grep -c "^>" $FASTA.ok.fasta) ]
		then
			ln -s $COUNT.count_table $COUNT.ok.count_table
		else
			grep "^>" $FASTA.ok.fasta | sed 's/>//' | sort | join - <(sed '1d' $COUNT.count_table | sort -k 1,1) | cat <(head -1 $COUNT.count_table) - > $COUNT.ok.count_table
		fi
		FASTA=$FASTA.ok
		COUNT=$COUNT.ok
		echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
	fi
fi

# list files and directories
(. $BIN/list_step_files.sh)

echo END
