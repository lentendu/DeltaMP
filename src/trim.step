# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Christina Wei√übecker, Anna Heintz-Buschart, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# load modules
module load DeltaMP/DELTAMP_VERSION

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
. $BIN/check_previous_step

# Choose a sample
LIB=(`sed -n "$ARRAY_TASK"'p' config/lib4.list`)
SAMP=${LIB[0]}
LIB_NAME=(`echo ${LIB[@]} | cut -d " " -f 2-`)
LOG=mothur.${TECH}_trim.$SAMP.logfile
cd processing && mkdir $SAMP
cd $SAMP

# Trim for each library of the sample and merge
for i in "${LIB_NAME[@]}"
do
	if [ $TECH == "454" ]
	then
		if [ $BDIFFS == "a" ]
		then
			unset BDIFFS && BDIFFS=$(grep ${i#*.} ../bdiffs.$SUBPROJECT | cut -d " " -f 2)
		fi
		# Get quality and length for trimming
		QUAL=`cut -d "." -f 2 $EXEC/quality_check/trimming.parameters.txt`
		LENGTH=`cut -d "." -f 1 $EXEC/quality_check/trimming.parameters.txt`
		if [ $DENOISE == "yes" ]
		then
			#trim flows with FlowClus, using all set of primers allowed by PDIFFS mismatches as detected by cutadapt (also work with MOTHUR trim.seqs) because FlowClust does not take into account homopolymers extension in primer mismatches (which append quite often for example for ITS4)
			if [ $DEMULTI == "no" ]
			then
				process_sff.py -i $EXEC/libraries/sff/$i.sff -f -o ./ 
			else
				process_sff.py -i $EXEC/libraries/$i.sff -f -o ./ 
			fi
			ln -s $EXEC/libraries/fasta/oligos.$i ./
			sed 's/forward/primer,'$i'/;s/^#//;s/barcode/midtag/' $EXEC/libraries/fasta/oligos.$i | awk '{if($1=="midtag"){print $1,$3,$2} else print $0}' | sed 's/ /,/g' > master.$i.csv
			FWD_E=$(awk -v F=${#FWD} -v P=$PDIFFS 'BEGIN{printf "%.2f",P/F+0.005}')
			# allow looping over multiple barcodes for same sample
			while read name samp mid
			do
				MID_E=$(awk -v F=${#mid} -v B=$BDIFFS 'BEGIN{printf "%.2f",B/F+0.005}')
				awk '{print $1}' $EXEC/libraries/fasta/$i.fasta | cutadapt -g ^${mid} -e ${MID_E} -O ${#mid} --no-indels --trimmed-only - | cutadapt -g ${FWD} -e ${FWD_E} --trimmed-only --info-file=cutadapt.${i}_$mid - > ${i}_$mid.cut.fasta
				while read count prim
				do
					sed '1 s/,[^,]*$/_'$count','$prim'/' master.$i.csv
				done < <(awk -v F=${#FWD} 'length($5)>=F{print $5}' cutadapt.${i}_$mid | sort -u | awk '{print NR,$1}') > master.all.$i.csv
			done < <(grep "^midtag" master.$i.csv | tr "," "\t") > master.all.$i.csv
			# Filter reads for each combination of barcode and primer variant into flows
			MID=$(grep -m 1 midtag master.all.$i.csv | cut -d "," -f 3)
			if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
			then
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW
			else
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -t $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW 
			fi
			# Merge flows for each barcode
			awk -v I=$i '{if($0~"^primer"){F=$0} else if($0~"^reverse"){R=$0} else if($0~"^midtag"){M[NR]=$0}}END{for(x in M){split(M[x],mid,",");sub(I".*,",I"_"mid[3]",",F);printf "%s\n%s\n%s\n",F,R,M[x]}}' master.$i.csv > master.$i.ok.csv
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				for j in ${k%_*}_[0-9]*.flow; do sed '1d' $j ; done | cat <(head -1 $(ls ${k%_*}_*.flow | head -1)) - > ${k}.flow
				rm ${k%_*}_[0-9]*.flow ${k}.cut.fasta cutadapt.${k}
			done
			# Denoise for each barcode separetedly
			FlowClus -b -m master.$i.ok.csv -j 0.50 -ch -cu .denoised.fasta -cm .denoised.names -o $i.denoised_all.fasta
			# Merge all denoised reads and mapping files from the same library
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				awk '{if($2~","){sub(",*"$1"$","",$2);print $1"\t"$1","$2} else print}' ${k}.denoised.names >> $i.temp.names
				awk '{print $1}' ${k}.denoised.fasta >> $i.temp.fasta
				rm ${k}.denoised* ${k}.flow
			done
			mothur "#set.logfile(name=$LOG, append=T);
			trim.seqs(fasta=$i.temp.fasta, name=$i.temp.names, maxambig=$MAXAMBIG, processors=$NCPUS)"
			rm $i.txt $i.temp.scrap.fasta $i.temp*.qual $i.temp.fasta $i.temp.names
		else
			if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
			then
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=./);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, processors=$NCPUS)"
				if [ $SEQ_DIR == "both" ]
				then
					awk -v R=$RVS 'BEGIN{print "forward\t"R} NR>2{print}' $EXEC/libraries/fasta/oligos.$i > oligos.rev.$i
					mothur "#set.logfile(name=$LOG, append=T);
					trim.seqs(fasta=$i.scrap.fasta, qfile=$i.scrap.qual, oligos=oligos.rev.$i, average=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, processors=$NCPUS, flip=T)"
					cat $i.trim.fasta $i.scrap.trim.fasta > tmp.$i.fasta && mv tmp.$i.fasta $i.trim.fasta
				fi
			else
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=./);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, keepfirst=$LENGTH, processors=$NCPUS)"
				if [ $SEQ_DIR == "both" ]
				then
					awk -v R=$RVS 'BEGIN{print "forward\t"R} NR>2{print}' $EXEC/libraries/fasta/oligos.$i > oligos.rev.$i
					mothur "#set.logfile(name=$LOG, append=T);
					trim.seqs(fasta=$i.scrap.fasta, qfile=$i.scrap.qual, oligos=oligos.rev.$i, average=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, keepfirst=$LENGTH, processors=$NCPUS, flip=T)"
					cat $i.trim.fasta $i.scrap.trim.fasta > tmp.$i.fasta && mv tmp.$i.fasta $i.trim.fasta
				fi
			fi
		fi
	elif [ $TECH == "Illumina" ]
	then
		QUAL=`cat $EXEC/quality_check/optimized.quality.txt`
		mothur "#set.logfile(name=$LOG, append=T);
		set.dir(input=$EXEC/libraries/fasta, output=./);
		trim.seqs(fasta=$i.pairend.fasta, qfile=$i.pairend.qual, qaverage=$QUAL, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$MINLEN, maxlength=$MAXLEN, processors=$NCPUS)"
	fi
done

# Merge trimmed reads of all libraries of the sample
TRIMMED=(*.trim.fasta)
if [ ${#TRIMMED[@]} -gt 1 ]
then
	cat *.trim.fasta > $SAMP.trim.fasta
else
	ln -s $TRIMMED $SAMP.trim.fasta
fi
rm *scrap* *qual
FASTA=$SAMP.trim

# Reverse-complement
if [ $TECH == "454" ] && [ $FLIP == "true" ]
then
	vsearch --quiet --fastx_revcomp $FASTA.fasta --fastaout - | twofasta > $FASTA.rc.fasta
	FASTA=$FASTA.rc
fi

# Dereplicate
if [ $TECH == "454" ] && [ "$DENOISE" == "yes" ]
then
	cat *.trim.names > $SAMP.names
	mothur "#set.logfile(name=$LOG, append=T);
	unique.seqs(fasta=$FASTA.fasta, name=$SAMP.names, format=count);
	get.current()"
	FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
	COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
else
	vsearch --no_progress --derep_fulllength $FASTA.fasta --sizeout --output - | twofasta | sed '/>/s/;/ /' | tee $FASTA.unique.fasta | sed -n "/>/{s/>//;s/ size=/\t/;p}" | cat <(echo -e "Representative_Sequence\ttotal") - > $FASTA.unique.count_table
	FASTA=$FASTA.unique
	COUNT=$FASTA
	echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
fi

# Subsample
if [ $SUBSAMPLE == "yes" ]
then
	SIZE=$(grep "Minimum" $EXEC/quality_check/$SUBPROJECT.summary.stat.tsv | cut -f 3 | cut -d "." -f 1)
	mothur "#set.logfile(name=$LOG, append=T);
	sub.sample(fasta=$FASTA.fasta, count=$COUNT.count_table, size=$SIZE);
	get.current()"
	FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
	COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
fi

# Precluster
if [ $PRECLUST == "mothur" ]
then
	# pre-cluster at max 1% after aligning to reference and removing the 5 % worse aligned reads
	if [ $TECH == "454" ] && [ $ITSX == "no" ]
	then
		PRECDIFF=$(( ${LENGTH} / 100 ))
	else
		PRECDIFF=$(twofasta $FASTA.fasta | awk -v M=$MAXLEN 'BEGIN{min=M}length($1)<M{min=length($1)}END{print int(min/100)'awk '$1!~"^>"{sum+=length($1)}END{print int(sum/(FNR/2)/100)}')
	fi
	if [ $PRECDIFF -ge 1 ]
	then
		mothur "#set.logfile(name=$LOG, append=T);
		set.dir(tempdefault=$DBFOLD);
		align.seqs(candidate=$FASTA.fasta, template=$DBCHOP.fasta, align=needleman, processors=$NCPUS);
		screen.seqs(fasta=current, count=$COUNT.count_table, optimize=start-end, criteria=95, processors=$NCPUS);
		filter.seqs(fasta=current, vertical=T, trump=., processors=$NCPUS);
		pre.cluster(fasta=current, count=current, diffs=$PRECDIFF, processors=$NCPUS);
		get.current()"
		unset FASTA COUNT
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
	else
		echo "The pre-culstering step was skipped because the smallest sequence have less than 100nt."
	fi
elif [ $PRECLUST == "cdhit454" ]
then
	# pre-cluster with cd-hit-454, allowing 1% dissimilarity with indel of max 1 nt long
	cdhit4542mothur () {
		bak=$1 ; fasta=$2 ; count=$3
		nl $bak | sed 's/>//;s/\.\.\.//' | awk '{print $4,$1,$2}' | sort -k 1,1 | join - <(sed '1d' $count | sort -k 1,1) | sort -k 3,3n -k 4,4nr | awk '{if(NR==1){nb=$3;printf "%s\t%s", $1,$2;sum=$4} else {if($3==nb){sum+=$4} else {nb=$3;printf "\t%s\n%s\t%s",sum,$1,$2;sum=$4}}}END{printf "\t%s\n",sum}' | sort -k 2,2n -t $'\t' | cut -f 1,3 | cat <(head -1 $count) - > ${count%.*}.precl.count_table
		obigrep --without-progress-bar --uppercase --id-list=<(sed '1d' ${count%.*}.precl.count_table | cut -f 1) $fasta | twofasta > ${fasta%.*}.precl.fasta
	}
	cd-hit-454 -T $NCPUS -B 1 -g 1 -M 6000 -c 0.99 -bak 1 -i $FASTA.fasta -o $FASTA.precl.fasta.temp
	cdhit4542mothur $FASTA.precl.fasta.temp.bak.clstr $FASTA.fasta $COUNT.count_table
	rm $FASTA.precl.fasta.temp*
	FASTA=$FASTA.precl
	COUNT=$COUNT.precl
	echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
fi

# ITSx or Chimera removal
if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
then
	ITSx --cpu $NCPUS -i $FASTA.fasta --save_regions $ITSX --preserve T --graphical F -o $FASTA.itsx
	awk '$0~"^>"{sub(">","");print $1}' $FASTA.itsx.$ITSX.fasta | sort | join -t $'\t' - <(sed '1d' $COUNT.count_table | sort -t $'\t' -k 1,1) | cat <(head -1 $COUNT.count_table) - > $COUNT.itsx.$ITSX.count_table
	mothur "#set.logfile(name=$LOG, append=T);
	unique.seqs(fasta=$FASTA.itsx.$ITSX.fasta, count=$COUNT.itsx.$ITSX.count_table);
	get.current()"
	unset FASTA COUNT
	FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
	COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
elif [ $CHIMERA1 == "yes" ]
then
	if [ $TECH == "454" ] || [ $(sed -n '$=' $COUNT.count_table) -lt 20000 ]
	then
		twofasta $FASTA.fasta | awk '{print $1}' | paste - - | sed 's/^>//' | sort -k 1,1 | join - <(sort -k 1,1 $COUNT.count_table) | awk '{print ">"$1,"size="$3";\n"$2}' | vsearch --no_progress --uchime_denovo - --nonchimeras - | twofasta > $FASTA.ok.fasta
	else
		. $BIN/parallel_uchime.sh
	fi
	if [ $(grep -c "^>" $FASTA.fasta) -eq $(grep -c "^>" $FASTA.ok.fasta) ]
	then
		ln -s $COUNT.count_table $COUNT.ok.count_table
	else
		grep "^>" $FASTA.ok.fasta | sed 's/>//' | sort | join - <(sed '1d' $COUNT.count_table | sort -k 1,1) | cat <(head -1 $COUNT.count_table) - > $COUNT.ok.count_table
	fi
	FASTA=$FASTA.ok
	COUNT=$COUNT.ok
	echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
fi

# list files and directories
. $BIN/list_step_files.sh

echo END
