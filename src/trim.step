# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Christina Wei√übecker, Anna Heintz-Buschart, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
. $BIN/check_previous_step

# load modules
module load DeltaMP/${VERSION[DELTAMP]}

# Choose a sample
LIB=(`sed -n "$ARRAY_TASK"'p' config/lib4.list`)
SAMP=${LIB[0]}
LIB_NAME=(`echo ${LIB[@]} | cut -d " " -f 2-`)
LOG=mothur.${TECH}_trim.$SAMP.logfile
cd processing && mkdir $SAMP
cd $SAMP

# Trim for each library of the sample and merge
for i in "${LIB_NAME[@]}"
do
	if [ $TECH == "454" ]
	then
		if [ $BDIFFS == "a" ]
		then
			unset BDIFFS && BDIFFS=$(grep ${i#*.} ../bdiffs.$SUBPROJECT | cut -d " " -f 2)
		fi
		# Get quality and length for trimming
		QUAL=`cut -d "." -f 2 $EXEC/quality_check/trimming.parameters.txt`
		LENGTH=`cut -d "." -f 1 $EXEC/quality_check/trimming.parameters.txt`
		if [ $DENOISE == "yes" ]
		then
			#trim flows with FlowClus, using all set of primers allowed by PDIFFS mismatches as detected by cutadapt (also work with MOTHUR trim.seqs) because FlowClust does not take into account homopolymers extension in primer mismatches (which append quite often for ITS4)
			if [ $DEMULTI == "no" ]
			then
				process_sff.py -i $EXEC/libraries/sff/$i.sff -f -o ./ 
			else
				process_sff.py -i $EXEC/libraries/$i.sff -f -o ./ 
			fi
			ln -s $EXEC/libraries/fasta/oligos.$i ./
			sed 's/forward/primer,'$i'/;s/^#//;s/barcode/midtag/' $EXEC/libraries/fasta/oligos.$i | awk '{if($1=="midtag"){print $1,$3,$2} else print $0}' | sed 's/ /,/g' > master.$i.csv
			FWD_E=$(awk -v F=${#FWD} -v P=$PDIFFS 'BEGIN{printf "%.2f",P/F+0.005}')
			# allow looping over multiple barcodes for same sample
			while read name samp mid
			do
				MID_E=$(awk -v F=${#mid} -v B=$BDIFFS 'BEGIN{printf "%.2f",B/F+0.005}')
				awk '{print $1}' $EXEC/libraries/fasta/$i.fasta | cutadapt -g ${mid} -e ${MID_E} --trimmed-only - | cutadapt -g ${FWD} -e ${FWD_E} --trimmed-only --info-file=cutadapt.${i}_$mid - > ${i}_$mid.cut.fasta
				while read count prim
				do
					sed '1 s/,[^,]*$/_'$count','$prim'/' master.$i.csv
				done < <(awk -v F=${#FWD} 'length($5)>=F{print $5}' cutadapt.${i}_$mid | sort -u | awk '{print NR,$1}') > master.all.$i.csv
			done < <(grep "^midtag" master.$i.csv | tr "," "\t") > master.all.$i.csv
			# Filter reads for each combination of barcode and primer variant into flows
			if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
			then
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW
			else
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -t $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW 
			fi
			# Merge flows for each barcode
			awk -v I=$i '{if($0~"^primer"){F=$0} else if($0~"^reverse"){R=$0} else if($0~"^midtag"){M[NR]=$0}}END{for(x in M){split(M[x],mid,",");sub(I".*,",I"_"mid[3]",",F);printf "%s\n%s\n%s\n",F,R,M[x]}}' master.$i.csv > master.$i.ok.csv
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				for j in ${k%_*}_[0-9]*.flow; do sed '1d' $j ; done | cat <(head -1 $(ls ${k%_*}_*.flow | head -1)) - > ${k}.flow
				rm ${k%_*}_[0-9]*.flow ${k}.cut.fasta cutadapt.${k}
			done
			# Denoise for each barcode separetedly
			FlowClus -b -m master.$i.ok.csv -j 0.50 -ch -cu .denoised.fasta -cm .denoised.names -o $i.denoised_all.fasta
			# Merge all denoised reads and mapping files from the same library
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				awk '{if($2~","){sub(",*"$1"$","",$2);print $1"\t"$1","$2} else print}' ${k}.denoised.names >> $i.names
				if [ $FLIP == "yes" ]
				then
					obicomplement --without-progress-bar --uppercase ${k}.denoised.fasta | sed 's/_CMP.*$//' | twofasta >> $i.trim.fasta
				else
					awk '{print $1}' ${k}.denoised.fasta >> $i.trim.fasta
				fi
				rm ${k}.denoised* ${k}.flow
			done
			rm $i.txt
			
		else
			if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
			then
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=$EXEC/processing/$SAMP);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, flip=$FLIP, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH)"
			else
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=$EXEC/processing/$SAMP);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, flip=$FLIP, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, keepfirst=$LENGTH)"
			fi
		fi
	elif [ $TECH == "Illumina" ]
	then
		QUAL=`cat $EXEC/quality_check/optimized.quality.txt`
		mothur "#set.logfile(name=$LOG, append=T);
		set.dir(input=$EXEC/libraries/fasta, output=$EXEC/processing/$SAMP);
		trim.seqs(fasta=$i.pairend.fasta, qfile=$i.pairend.qual, qaverage=$QUAL, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$MINLEN, maxlength=$MAXLEN)"
	fi
done
# Merge trimmed reads of all libraries of the sample
cat *.trim.fasta > $SAMP.trim.fasta
if [ $TECH == "454" ] && [ "$DENOISE" == "yes" ] ; then cat *.names > $SAMP.names ; fi

# unique and subsample
if [ $SUBSAMPLE == "yes" ]
then
	SIZE=$(grep "Minimum" $EXEC/quality_check/$SUBPROJECT.summary.stat.tsv | cut -f 3 | cut -d "." -f 1)
	if [ $TECH == "454" ] && [ "$DENOISE" == "yes" ]
	then
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$SAMP.trim.fasta, name=$SAMP.names);
		sub.sample(fasta=current, name=current, size=$SIZE);
		get.current()"
	else
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$SAMP.trim.fasta);
		sub.sample(fasta=current, name=current, size=$SIZE);
		get.current()"
	fi
else
	if [ $TECH == "454" ] && [ "$DENOISE" == "yes" ]
	then
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$SAMP.trim.fasta, name=$SAMP.names);
		get.current()"
	else
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$SAMP.trim.fasta);
		get.current()"
	fi
fi

#store current files in variables
unset FASTA NAMES
FASTA=`tac $LOG | sed -n '1,/get.current()/p' | grep "^fasta=" | sed 's/fasta=//;s/\.fasta//'`
NAMES=`tac $LOG | sed -n '1,/get.current()/p' | grep "^name=" | sed 's/name=//;s/\.names//'`

# Precluster
if [ $PRECLUST == "mothur" ]
then
	# pre-cluster at max 1% after aligning to reference and removing the 5 % worse aligned reads
	if [ $TECH == "454" ] && [ $ITSX == "no" ]
	then
		PRECDIFF=$(( ${LENGTH} / 100 ))
	else
		PRECDIFF=$(twofasta $FASTA.fasta | awk -v M=$MAXLEN 'BEGIN{min=M}length($1)<M{min=length($1)}END{print int(min/100)'awk '$1!~"^>"{sum+=length($1)}END{print int(sum/(FNR/2)/100)}')
	fi
	if [ $PRECDIFF -ge 1 ]
	then
		mothur "#set.logfile(name=$LOG, append=T);
		set.dir(tempdefault=/data/ecogen/databases/mothur);
		align.seqs(candidate=$FASTA.fasta, template=$DBCHOP.fasta, align=needleman);
		screen.seqs(fasta=current, name=$NAMES.names, optimize=start-end, criteria=95);
		filter.seqs(fasta=current, vertical=T, trump=.);
		pre.cluster(fasta=current, name=current, diffs=$PRECDIFF);
		get.current()"
		unset FASTA NAMES
		FASTA=`tac $LOG | sed -n '1,/get.current()/p' | grep "^fasta=" | sed 's/fasta=//;s/\.fasta//'`
		NAMES=`tac $LOG | sed -n '1,/get.current()/p' | grep "^name=" | sed 's/name=//;s/\.names//'`
	else
		echo "The pre-culstering step was skipped because the smallest sequence have less than 100nt."
	fi
elif [ $PRECLUST == "cdhit454" ]
then
	# pre-cluster with cd-hit-454, allowing 1% dissimilarity with indel of max 1 nt long
	cdhit4542mothur () {
		bak=$1 ; fasta=$2 ; names=$3
		nl $bak | sed 's/>//;s/\.\.\.//' | awk '{print $4,$1,$2}' | sort -k 1,1 | join - <(sort -k 1,1 $names) | awk '{size=split($4,a,",");print $0,size}' | sort -k 3,3n -k 5,5nr | awk '{if(NR==1){nb=$3;printf "%s\t%s\t%s", $1,$2,$4} else {if($3==nb){printf ",%s", $4} else {nb=$3;printf "\n%s\t%s\t%s",$1,$2,$4}}}END{printf "\n"}' | sort -k 2,2n | cut -f 1,3 > ${names%.*}.precl.names
		obigrep --without-progress-bar --uppercase --id-list=<(cut -f 1 ${names%.*}.precl.names) $fasta | twofasta > ${fasta%.*}.precl.fasta
	}
	cd-hit-454 -B 1 -g 1 -M 6000 -c 0.99 -bak 1 -i $FASTA.fasta -o $FASTA.precl.fasta.temp
	cdhit4542mothur $FASTA.precl.fasta.temp.bak.clstr $FASTA.fasta $NAMES.names
	rm $FASTA.precl.fasta.temp*
	FASTA=$FASTA.precl
	NAMES=$NAMES.precl
fi

# [ITSx and] Chimera removal
if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
then
	ITSx -i $FASTA.fasta --save_regions $ITSX --preserve T --graphical F -o $FASTA.itsx
	awk '$0~"^>"{sub(">","");print $1}' $FASTA.itsx.$ITSX.fasta | sort | join - <(sort -k 1,1 $NAMES.names) > $NAMES.itsx.$ITSX.names
	mothur "#set.logfile(name=$LOG, append=T);
	unique.seqs(fasta=$FASTA.itsx.$ITSX.fasta, name=$NAMES.itsx.$ITSX.names);
	get.current()"
	unset FASTA NAMES
	FASTA=`tac $LOG | sed -n '1,/get.current()/p' | grep "^fasta=" | sed 's/fasta=//;s/\.fasta//'`
	NAMES=`tac $LOG | sed -n '1,/get.current()/p' | grep "^name=" | sed 's/name=//;s/\.names//'`
elif [ $CHIMERA == "before" ] || [ $CHIMERA == "both" ]
then
	mothur "#set.logfile(name=$LOG, append=T);
	chimera.uchime(fasta=$FASTA.fasta, name=$NAMES.names, reference=self);
	get.current()"
	unset FASTA NAMES ACCNOS
	FASTA=`tac $LOG | sed -n '1,/get.current()/p' | grep "^fasta=" | sed 's/fasta=//;s/\.fasta//'`
	NAMES=`tac $LOG | sed -n '1,/get.current()/p' | grep "^name=" | sed 's/name=//;s/\.names//'`
	ACCNOS=`tac $LOG | sed -n '1,/get.current()/p' | grep "^accnos=" | sed 's/accnos=//;s/\.accnos//'`
	if [ -s $ACCNOS.accnos ]
	then
		mothur "#set.logfile(name=$LOG, append=T);
		remove.seqs(accnos=$ACCNOS.accnos, fasta=$FASTA.fasta, name=$NAMES.names);
		get.current()"
	fi
fi

# list files and directories
. $BIN/list_step_files.sh

echo END
