# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# load modules
module load DeltaMP/DELTAMP_VERSION

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
. $BIN/check_previous_step

uc2na() {
awk '{if($1=="S"){print $9,$9} else {if($1=="H"){print $9,$10}}}' "${@--}"
}

# Choose a sample
LIB=(`sed -n "$ARRAY_TASK"'p' config/lib4.list`)
SAMP=${LIB[0]}
if [ ! -z "$(grep $SAMP config/*.missing 2> /dev/null)" ]
then
	MISSING=$(grep -H $SAMP config/*.missing | sed 's@.*/@@;s@\.missing.*@@')
	echo $MISSING > missing
	echo -e "The sample $SAMP had no read at the end of the step $MISSING.\nSkip"
	(. $BIN/list_step_files.sh)
	echo END
	exit 0
fi
LIB_NAME=(`echo ${LIB[@]} | cut -d " " -f 2-`)
LOG=mothur.${TECH}_trim.$SAMP.logfile
cd processing && mkdir $SAMP
cd $SAMP

# Trim for each library of the sample and merge
for i in "${LIB_NAME[@]}"
do
	if [ $TECH == "454" ]
	then
		if [ $BDIFFS == "a" ]
		then
			unset BDIFFS && BDIFFS=$(grep ${i#*.} ../bdiffs.$SUBPROJECT | cut -d " " -f 2)
		fi
		# Get quality and length for trimming
		QUAL=`cut -d "." -f 2 $EXEC/quality_check/trimming.parameters.txt`
		LENGTH=`cut -d "." -f 1 $EXEC/quality_check/trimming.parameters.txt`
		if [ $BARC_ANCH == "yes" ] ; then BANCH="^" ; else BANCH="X" ; fi
		if [ $PRIM_ANCH == "yes" ] ; then PANCH="^" ; else PANCH="" ; fi
		if [ $DENOISE == "yes" ]
		then
			#trim flows with FlowClus, using all set of primers allowed by PDIFFS mismatches as detected by cutadapt (also work with MOTHUR trim.seqs) because FlowClust does not take into account homopolymers extension in primer mismatches (which append quite often for example for ITS4)
			if [ $EXT == "bz2" ]
			then
				bunzip2 -c $RAW_DIR/$i.sff.$EXT > $i.sff
			else
				unpigz -p 1 -c $RAW_DIR/$i.sff.$EXT > $i.sff
			fi
			process_sff.py -i $i.sff -f -o ./ 
			rm $i.sff
			ln -s $EXEC/libraries/fasta/oligos.$i ./
			sed 's/forward/primer,'$i'/;s/^#//;s/barcode/midtag/' $EXEC/libraries/fasta/oligos.$i | awk '{if($1=="midtag"){print $1,$3,$2} else print $0}' | sed 's/ /,/g' > master.$i.csv
			FWD_E=$(awk -v F=${#FWD} -v P=$PDIFFS 'BEGIN{printf "%.2f",P/F+0.005}')
			# allow looping over multiple barcodes for same sample
			while read name samp mid
			do
				MID_E=$(awk -v F=${#mid} -v B=$BDIFFS 'BEGIN{printf "%.2f",B/F+0.005}')
				awk '{print $1}' $EXEC/libraries/fasta/$i.fasta | cutadapt -g ${BANCH}${mid} -e ${MID_E} -O ${#mid} --no-indels --trimmed-only - 2> log.cutadapt.${i}_${mid} | cutadapt -g ${PANCH}${FWD} -e ${FWD_E} --trimmed-only --info-file=cutadapt.${i}_$mid - 2>> log.cutadapt.${i}_${mid} > ${i}_$mid.cut.fasta
				while read count prim
				do
					sed '1 s/,[^,]*$/_'$count','$prim'/' master.$i.csv
				done < <(awk -v F=${#FWD} 'length($5)>=F{print $5}' cutadapt.${i}_$mid | sort -u | awk '{print NR,$1}') > master.all.$i.csv
			done < <(grep "^midtag" master.$i.csv | tr "," "\t") > master.all.$i.csv
			# Filter reads for each combination of barcode and primer variant into flows
			MID=$(grep -m 1 midtag master.all.$i.csv | cut -d "," -f 3)
			if [[ ($TARG == "ITS") && ($ITSX != "no") ]] || [[ $CLIPPING == "both" ]]
			then
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW
			else # truncate end of sequences
				FlowClus -a -m master.all.$i.csv -i $i.txt -em $BDIFFS -ep 0 -r -er $PDIFFS -l $((LENGTH + ${#MID} + ${#FWD})) -t $((LENGTH + ${#MID} + ${#FWD})) -n $MAXAMBIG -g $MAXHOMOP -s $QUAL -lf $MINFLOW -c FlowClus.$i.stat.txt #-Lf $MAXFLOW 
			fi
			# Merge flows for each barcode
			awk -v I=$i '{if($0~"^primer"){F=$0} else if($0~"^reverse"){R=$0} else if($0~"^midtag"){M[NR]=$0}}END{for(x in M){split(M[x],mid,",");sub(I".*,",I"_"mid[3]",",F);printf "%s\n%s\n%s\n",F,R,M[x]}}' master.$i.csv > master.$i.ok.csv
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				for j in ${k%_*}_[0-9]*.flow; do sed '1d' $j ; done | cat <(head -1 $(ls ${k%_*}_*.flow | head -1)) - > ${k}.flow
				rm ${k%_*}_[0-9]*.flow ${k}.cut.fasta cutadapt.${k}
			done
			# Denoise for each barcode separetedly
			FlowClus -b -m master.$i.ok.csv -j 0.50 -ch -cu .denoised.fasta -cm .denoised.names -o $i.denoised_all.fasta
			# Merge all denoised reads and mapping files from the same library
			for k in $(grep primer master.$i.ok.csv | cut -d "," -f 2)
			do
				awk '{if($2~","){sub(",*"$1"$","",$2);print $1"\t"$1","$2} else print}' ${k}.denoised.names >> $i.temp.names
				awk '{print $1}' ${k}.denoised.fasta >> $i.temp.fasta
				rm ${k}.denoised* ${k}.flow
			done
			mothur "#set.logfile(name=$LOG, append=T);
			trim.seqs(fasta=$i.temp.fasta, name=$i.temp.names, maxambig=$MAXAMBIG, processors=$NCPUS)"
			rm $i.txt $i.temp.scrap.fasta $i.temp*.qual $i.temp.fasta $i.temp.names
		else
			if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
			then
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=./);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, processors=$NCPUS)"
				if [ $SEQ_DIR == "both" ]
				then
					mkdir rev.$i
					mothur "#set.logfile(name=$LOG, append=T);
					set.dir(input=$EXEC/libraries/fasta, output=rev.$i);
					trim.seqs(fasta=$i.fasta, oligos=oligos.rev.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, processors=$NCPUS, flip=T)"
					cat $i.trim.fasta rev.$i/$i.trim.fasta > tmp.$i.fasta && mv tmp.$i.fasta $i.trim.fasta
					rm -r rev.$i/
				fi
			elif [ $CLIPPING == "both" ]
			then
				# ensure reverse primer is removed at 5' end
				BLENGTH=$(awk '$0!~"^>"{match($1,"[ATCG][ATCG]*");print RLENGTH; exit}' $EXEC/libraries/fasta/oligos.${LIB_NAME}.fasta)
				BDISS=$(awk -v L=$BLENGTH -v D=$BDIFFS 'BEGIN{printf "%.2g\n", D/L}')
				RVS_RC=$(echo -e ">rvs\n$RVS" | seqkit seq -p -t dna -v | tail -1)
				DISS=`awk -v F=${#FWD} -v R=${#RVS} -v D=$PDIFFS 'BEGIN{DISS=D/F;if(D/R>DISS){DISS=D/R};printf "%.2g\n", DISS}'`
				cutadapt -g file:$EXEC/libraries/fasta/oligos.${LIB_NAME}.fasta -e ${BDISS} -O $BLENGTH --no-indels --trimmed-only $EXEC/libraries/fasta/$LIB_NAME.fastq 2> log.cutadapt.$LIB_NAME | cutadapt -a ${PANCH}$FWD...$RVS_RC -e $DISS --no-indels --trimmed-only -m $LENGTH -M $MAXLEN -o $LIB_NAME.fastq - >> log.cutadapt.$LIB_NAME
				if [ $SEQ_DIR == "both" ]
				then
					FWD_RC=$(echo -e ">fwd\n$FWD" | seqkit seq -p -t dna -v | tail -1)
					cutadapt -g file:$EXEC/libraries/fasta/oligos.${LIB_NAME}.fasta -e ${BDISS} -O $BLENGTH --no-indels --trimmed-only $EXEC/libraries/fasta/$LIB_NAME.fastq 2>> log.cutadapt.$LIB_NAME | cutadapt -a ${PANCH}$RVS...$FWD_RC -e $DISS --no-indels --trimmed-only -m $LENGTH -M $MAXLEN - 2>> log.cutadapt.$LIB_NAME | vsearch --quiet --fastx_revcomp - --fastqout $LIB_NAME.rev.fastq
					cat $LIB_NAME.fastq $LIB_NAME.rev.fastq > tmp.$LIB_NAME.fastq && mv tmp.$LIB_NAME.fastq $LIB_NAME.fastq
				fi
				mothur "#set.logfile(name=$LOG, append=T);
				fastq.info(fastq=$LIB_NAME.fastq);
				trim.seqs(fasta=current, qfile=current, qaverage=$QUAL, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, processors=$NCPUS)"
			else
				mothur "#set.logfile(name=$LOG, append=T);
				set.dir(input=$EXEC/libraries/fasta, output=./);
				trim.seqs(fasta=$i.fasta, oligos=oligos.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, keepfirst=$LENGTH, processors=$NCPUS)"
				if [ $SEQ_DIR == "both" ]
				then
					mkdir rev.$i
					mothur "#set.logfile(name=$LOG, append=T);
					set.dir(input=$EXEC/libraries/fasta, output=rev.$i);
					trim.seqs(fasta=$i.fasta, oligos=oligos.rev.$i, qfile=$i.qual, qaverage=$QUAL, bdiffs=$BDIFFS, pdiffs=$PDIFFS, maxambig=$MAXAMBIG, maxhomop=$MAXHOMOP, minlength=$LENGTH, keepfirst=$LENGTH, processors=$NCPUS, flip=T)"
					cat $i.trim.fasta rev.$i/$i.trim.fasta > tmp.$i.fasta && mv tmp.$i.fasta $i.trim.fasta
					rm -r rev.$i/
				fi
			fi
		fi
	elif [ $TECH == "Illumina" ]
	then
		# trim
		if [ $TRUNCBE == "no" ]
		then
			# Concatenate reads in both direction
			if [ -f $EXEC/libraries/fastq/$FWD_NAME.$RVS_NAME.$i.pairend.fastq.$EXT ]
			then
				if [ -f $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT ]
				then
					vsearch --quiet --fastx_revcomp $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT --fastqout - | cat <(eval $DECOMP $EXEC/libraries/fastq/$FWD_NAME.$RVS_NAME.$i.pairend.fastq.$EXT) - > $i.pairend.fastq
				else
					eval $DECOMP $EXEC/libraries/fastq/$FWD_NAME.$RVS_NAME.$i.pairend.fastq.$EXT > $i.pairend.fastq
				fi
			elif [ -f $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT ]
			then
				vsearch --quiet --fastx_revcomp $EXEC/libraries/fastq/$RVS_NAME.$FWD_NAME.$i.pairend.fastq.$EXT --fastqout - > $i.pairend.fastq
			fi
			# Quality filtering
			QUAL=`cat $EXEC/quality_check/optimized.quality.txt`
			if [ $QFILT == "average" ]
			then
				seqkit seq -j $NCPUS -Q $QUAL -m $MINLEN -M $MAXLEN $i.pairend.fastq | seqkit fq2fa | seqkit grep -sr -p "\"N{0,$MAXAMBIG}\"" | seqkit grep -w 0 -srv -p "\"A{$MAXHOMOP,}\",\"C{$MAXHOMOP,}\"" | awk '{if($1~"^>"){gsub(":","_",$1)};print $1}' > $i.pairend.trim.fasta
			elif [ $QFILT == "maxee" ]
			then
				vsearch --quiet --fastq_filter $i.pairend.fastq.$EXT --fastq_maxee $QUAL --fastq_maxlen $MAXLEN --fastq_maxns $MAXAMBIG --fastq_minlen $MINLEN --fastaout - | seqkit grep -w 0 -srv -p "\"A{$MAXHOMOP,}\",\"C{$MAXHOMOP,}\"" | awk '{if($1~"^>"){gsub(":","_",$1)};print $1}' > $i.pairend.trim.fasta
			fi
			rm $i.pairend.fastq
		else
			# Truncate and pair-end merge
			read FWD_LIB RVS_LIB < <(grep $i $EXEC/config/lib3.list | cut -f 2-3)
			for x in ${FWD_NAME} ${RVS_NAME}
			do
				if [ $x == "$FWD_NAME" ] ; then y=${RVS_NAME} ; else y=${FWD_NAME} ; fi
				if [ -f $EXEC/libraries/fastq/$x.$y.$i.pairend.fastq.$EXT ] || [ -f $EXEC/libraries/fastq/$x.${FWD_LIB}.noN.fastq.$EXT ]
				then
					if [ $UNPAIR == "yes" ]
					then
						ADD=".noN"
					fi
					if [ $TRUNCLEN == "no" ]
					then
						read FEE REE < <(paste $EXEC/quality_check/$x.fwd.optimized.quality.txt $EXEC/quality_check/$y.rvs.optimized.quality.txt)
					else
						read FTLEN FEE RTLEN REE < <(paste $EXEC/quality_check/$x.fwd.optimized.quality.txt $EXEC/quality_check/$y.rvs.optimized.quality.txt)
						TRUNCEEF=" --fastq_trunclen $FTLEN"
						TRUNCEER=" --fastq_trunclen $RTLEN"
					fi
			        if [ $ASV == "no" ]
			        then
				        vsearch --quiet --fastq_filter $EXEC/libraries/fastq/$x.${FWD_LIB}$ADD.fastq.$EXT --fastq_truncee $FEE$TRUNCEEF --fastqout $x.${FWD_LIB}.trunc.fastq # --fastq_maxns $MAXAMBIG
				        vsearch --quiet --fastq_filter $EXEC/libraries/fastq/$y.${RVS_LIB}$ADD.fastq.$EXT --fastq_truncee $REE$TRUNCEER --fastqout $y.${RVS_LIB}.trunc.fastq #  --fastq_maxns $MAXAMBIG
					else
						vsearch --quiet --fastq_filter $EXEC/libraries/fastq/$x.${FWD_LIB}$ADD.fastq.$EXT --fastq_truncee $FEE$TRUNCEEF --fastq_maxns $MAXAMBIG --fastqout - | seqkit grep -srv -p "\"A{$MAXHOMOP,}\",\"C{$MAXHOMOP,}\"" > $x.${FWD_LIB}.trunc.fastq
				        vsearch --quiet --fastq_filter $EXEC/libraries/fastq/$y.${RVS_LIB}$ADD.fastq.$EXT --fastq_truncee $REE$TRUNCEER --fastq_maxns $MAXAMBIG --fastqout - | seqkit grep -srv -p "\"A{$MAXHOMOP,}\",\"C{$MAXHOMOP,}\"" > $y.${RVS_LIB}.trunc.fastq
					fi
					join <(sed -n '1~4{s/[\t ].*$//;p}' $x.${FWD_LIB}.trunc.fastq | sort) <(sed -n '1~4{s/[\t ].*$//;p}' $y.${RVS_LIB}.trunc.fastq | sort) | sed 's/^@//' > $x.$y.$i.trunc.accnos
					seqkit grep -f $x.$y.$i.trunc.accnos $x.${FWD_LIB}.trunc.fastq > $x.$i.fwd.filtered.fastq
					seqkit grep -f $x.$y.$i.trunc.accnos $y.${RVS_LIB}.trunc.fastq > $y.$i.rvs.filtered.fastq
					rm $x.${FWD_LIB}.trunc.fastq $y.${RVS_LIB}.trunc.fastq $x.$y.$i.trunc.accnos
					if [ $ASV == "no" ]
					then
						if [ $UNPAIR == "yes" ]
						then
							vsearch --quiet --fastq_join $x.$i.fwd.filtered.fastq --reverse $y.$i.rvs.filtered.fastq --join_padgap NNNNN --fastqout $x.$y.$i.join.fastq 2> log.join.$x.$i.txt
						elif [ $PALG == "vsearch" ]
						then
							ASCII=$(vsearch --fastq_chars $x.$i.fwd.filtered.fastq 2>&1 | grep -m 1 "^Guess" | sed 's/.* //')
							PCTTRESH=$(awk -v P=$PTRESH 'BEGIN{print (1-P)*100}')
							vsearch --quiet --threads $NCPUS --fastq_mergepairs $x.$i.fwd.filtered.fastq --reverse $y.$i.rvs.filtered.fastq --fastq_ascii $ASCII --fastq_minovlen $MIN_OV --fastq_maxdiffpct $PCTTRESH --fastq_allowmergestagger --fastqout $x.$y.$i.pairend.fastq 2> log.pairend.$x.$i.txt
						elif [ $PALG == "ngmerge" ]
						then
							NGmerge -1 $x.$i.fwd.filtered.fastq -2 $y.$i.rvs.filtered.fastq -m $MIN_OV -p $(echo 1 - $PTRESH | bc) -v -y -o $x.$y.$i.pairend.fastq 2> log.pairend.$x.$i.txt
						else
							pandaseq -f $x.$i.fwd.filtered.fastq -r $y.$i.rvs.filtered.fastq -g log.pairend.$x.$i.txt -F -A $PALG -o $MIN_OV -O $((MAXLEN+MIN_OV-MINLEN)) -t $PTRESH -T $NCPUS > $x.$y.$i.pairend.fastq
						fi
					fi
				unset ADD
				fi
			done
			# Concatenate both direction or start pseudo-pooling approach for dada2
			if [ $ASV == "no" ]
			then
				if [ $UNPAIR == "no" ]
				then
					PAIRSUF=pairend
				else
					PAIRSUF=join
					MAXAMBIG=5 # for the padding N sequence
					MINLEN=$(awk -v F=$(awk -v m=$MINLEN '{if($1<m){m=$1}}END{print m}' $EXEC/quality_check/*.fwd.optimized.quality.txt) -v R=$(awk -v m=$MINLEN '{if($1<m){m=$1}}END{print m}' $EXEC/quality_check/*.rvs.optimized.quality.txt) -v A=$MAXAMBIG 'BEGIN{print F+R+A}')
					# smallest unpaired length

				fi
				if [ -s $FWD_NAME.$RVS_NAME.$i.$PAIRSUF.fastq ]
				then
					if [ -s $RVS_NAME.$FWD_NAME.$i.$PAIRSUF.fastq ]
					then
						vsearch --fastx_revcomp $RVS_NAME.$FWD_NAME.$i.$PAIRSUF.fastq --fastqout - | cat $FWD_NAME.$RVS_NAME.$i.$PAIRSUF.fastq - | vsearch --quiet --fastq_filter - --fastq_maxns $MAXAMBIG --fastq_maxlen $MAXLEN --fastq_minlen $MINLEN --fastaout - | seqkit grep -w 0 -srv -p "\"A{$MAXHOMOP,}\",\"C{$MAXHOMOP,}\"" | sed '/>/{s/:/_/;s/[ \t].*$//;}' > $i.$PAIRSUF.trim.fasta
						rm $RVS_NAME.$FWD_NAME.$i.$PAIRSUF.fastq $FWD_NAME.$RVS_NAME.$i.$PAIRSUF.fastq
					else
						vsearch --quiet --fastq_filter $FWD_NAME.$RVS_NAME.$i.$PAIRSUF.fastq --fastq_maxns $MAXAMBIG --fastq_maxlen $MAXLEN --fastq_minlen $MINLEN --fastaout - | seqkit grep -w 0 -srv -p "\"A{$MAXHOMOP,}\",\"C{$MAXHOMOP,}\"" | sed '/>/{s/:/_/;s/[ \t].*$//;}' > $i.$PAIRSUF.trim.fasta
						rm $FWD_NAME.$RVS_NAME.$i.$PAIRSUF.fastq
					fi
				elif [ -s $RVS_NAME.$FWD_NAME.$i.$PAIRSUF.fastq ]
				then
					vsearch --fastx_revcomp $RVS_NAME.$FWD_NAME.$i.$PAIRSUF.fastq --fastqout - | vsearch --quiet --fastq_filter - --fastq_maxns $MAXAMBIG --fastq_maxlen $MAXLEN --fastq_minlen $MINLEN --fastaout - | seqkit grep -w 0 -srv -p "\"A{$MAXHOMOP,}\",\"C{$MAXHOMOP,}\"" | awk '{if($1~"^>"){gsub(":","_",$1)};print $1}' > $i.$PAIRSUF.trim.fasta
					rm $RVS_NAME.$FWD_NAME.$i.$PAIRSUF.fastq
				fi
				# clean filtered
				rm *.$i.*.filtered.fastq
			else
				Rscript --vanilla $BIN/Rscript_dada2_library.R $NCPUS $i $PERRUN
				if [ $PERRUN == "no" ]
				then
					eval $COMP *.$i.*.asv.fasta
				fi
				# compress filtered
				eval $COMP *.$i.*.filtered.fastq
			fi
		fi
	elif [ $TECH == "Nanopore" ] || [ $TECH == "Pacbio" ]
	then
		# Concatenate reads in both direction and filter
		if [ -f $EXEC/libraries/fastq/$FWD_NAME.$i.fastq.$EXT ]
		then
			if [ -f $EXEC/libraries/fastq/$RVS_NAME.$i.fastq.$EXT ]
			then
				seqkit seq -vrp -t dna $EXEC/libraries/fastq/$RVS_NAME.$i.fastq.$EXT | cat <(eval $DECOMP $EXEC/libraries/fastq/$FWD_NAME.$i.fastq.$EXT) - | seqkit rename > $i.both.fastq
			else
				eval $DECOMP $EXEC/libraries/fastq/$FWD_NAME.$i.fastq.$EXT > $i.both.fastq
			fi
		elif [ -f $EXEC/libraries/fastq/$RVS_NAME.$i.fastq.$EXT ]
		then
			seqkit seq -vrp -t dna $EXEC/libraries/fastq/$RVS_NAME.$i.fastq.$EXT > $i.both.fastq
		fi
		# Quality filtering
		QUAL=`cat $EXEC/quality_check/optimized.quality.txt`
		seqkit seq -w0 -j $NCPUS -Q $QUAL -m $MINLEN -M $MAXLEN $i.both.fastq > $i.trim.fastq
		rm $i.both.fastq
	fi
done

# Process trimmed reads of all libraries of the sample together
if [ $TECH == "Nanopore" ]
then
	# concatenate fastq files
	TRIMMED=(*.trim.fastq)
	if [ ${#TRIMMED[@]} -gt 1 ]
	then
		cat *.trim.fastq > $SAMP.trim.fastq
	else
		ln -s $TRIMMED $SAMP.trim.fastq
	fi
	# cluster and correct
	seqkit fq2fa $SAMP.trim.fastq > $SAMP.trim.fasta
	#meshclust -d $SAMP.trim.fasta -o $SAMP.trim.clust -t $MINSIM -c $NCPUS -v 10000 -b 5000 > log.meshclust
	#seqkit grep -f <(awk -v M=$MINREADS '{if(NR==1){p=$1;c=1} else {if($1==p){c+=1} else {if(c>=M){print r}; p=$1; c=1}}; if($4=="C"){r=$2}}' $SAMP.trim.clust | sed 's/>//') $SAMP.trim.fasta > $SAMP.rep.fasta
	vsearch --quiet --threads $NCPUS --cluster_fast $SAMP.trim.fasta --id $MINSIM --iddef 0 --sizeout --centroids - | vsearch --fastx_filter - --minsize $MINREADS --fastaout $SAMP.rep.fasta
	#clust-mst -t $NCPUS -m $MINLEN -d $(echo "1 - $MINSIM" | bc -l) -o $SAMP.trim.clust -i $SAMP.trim.fasta
	#sumaclust -t $MINSIM -p $NCPUS -e $SAMP.trim.fasta | seqkit grep -nr -w 0 -p "cluster_center=True" | awk -v M=$MINREADS '{if($1~"^>"){flag=0; l=split($0,a,"; ");for(i=1;i<=l;i++){split(a[i],b,"=");if(b[1]=="cluster_weight" && b[2]>=M){print $1; flag=1}}} else {if(flag==1){print toupper($0)}}}' > $SAMP.rep.fasta
	echo "initiate $NANOCLUS correction with $(grep -c '^>' $SAMP.rep.fasta) clusters"
	if [ $NANOCLUS == "rattle" ]
	then
		# force rattle to use own clusters (much faster using sumaclust)
		rattle cluster -i $SAMP.rep.fasta -t $NCPUS -s $MINSIM --iso-score-threshold 0.01 --iso-max-variance 50
		rattle correct -i $SAMP.trim.fasta -t $NCPUS -c clusters.out -r 0
		seqkit fq2fa consensi.fq > $SAMP.rep.polish.fasta
		rm *.fq clusters.out
	elif [ $NANOCLUS == "racon" ]
	then
		# until five loop of racon correction or until similarity between two run is higher than 98%
		POLSIM=90
		i=0
		while [ $POLSIM -lt 98 ] && [ $i -lt 5 ]
		do
			i=$((i+1))
			if [ -s $SAMP.rep.polish.fasta ]
			then
				mv $SAMP.rep.polish.fasta $SAMP.rep.fasta
			elif [ -f $SAMP.rep.polish.fasta ]
			then
				echo "Warning: empty file $SAMP.rep.polish.fasta"
				break
			fi
			minimap2 -ax map-ont -2 -t $NCPUS $SAMP.rep.fasta $SAMP.trim.fasta > $SAMP.rep_map.sam
			racon -t $NCPUS $SAMP.trim.fasta $SAMP.rep_map.sam $SAMP.rep.fasta | sed "/^>/{s/>/>r${i};/;s/ .*//}" > $SAMP.rep.polish.fasta
			POLSIM=$(for i in $(sed -n '/^>/s/>//p' $SAMP.rep.fasta) ; do seqkit grep -r -p $i $SAMP.rep.fasta | cat - <(seqkit grep -r -p $i $SAMP.rep.polish.fasta) | sumatra - 2> /dev/null ; done | awk '{sim+=$3}END{print int(sim/NR*100+0.5)}')
			echo "similarity before / after polishing: $POLSIM"
		done
		echo "Stop racon polishing after $i iterations"
		sed -i 's/^>\(r[0-9];\)*/>/' $SAMP.rep.polish.fasta
		rm $SAMP.rep_map.sam
	fi
	# polish with medaka
	echo "Use $(grep -c '^>' $SAMP.rep.polish.fasta) corrected reads for medaka polishing"
	medaka_consensus -t $NCPUS -i $SAMP.trim.fastq -d $SAMP.rep.polish.fasta -m $MODEL 2> log.medaka
	# sort and relabel
	seqkit bam --idx-count medaka/calls_to_draft.bam 2>&1 | sed '1d' | sort -k 1,1 | join - <(seqkit fx2tab medaka/consensus.fasta | sort -k 1,1) | awk '{print ">"$1";size="$2"\n"$3}' | vsearch --quiet --sortbysize - --relabel_sha1 --sizeout --output - | vsearch --quiet --derep_fulllength - --sizein --sizeout --output - | seqkit seq -w0 | sed '/>/s/;size/ size/' | tee $SAMP.clean.fasta | sed -n "/>/{s/>//;s/ size=/\t/;p}" | cat <(echo -e "Representative_Sequence\ttotal") - > $SAMP.clean.count_table
	rm -r medaka $SAMP.trim.fasta $SAMP.rep.fasta $SAMP.rep.polish.fasta*
	FASTA=$SAMP.clean
	COUNT=$FASTA
	echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
elif [ $ASV == "no" ]
then
	if [ $TECH == "Pacbio" ]
	then
		for i in *.trim.fastq ; do seqkit fq2fa -w 0 $i > ${i%.*}.fasta ; rm $i ; done
	fi
	# concatenate fasta files
	TRIMMED=(*.trim.fasta)
	if [ ${#TRIMMED[@]} -gt 1 ]
	then
		cat *.trim.fasta > $SAMP.trim.fasta
	else
		ln -s $TRIMMED $SAMP.trim.fasta
	fi
	FASTA=$SAMP.trim
	
	# Reverse-complement
	if [ $TECH == "454" ] && [ $FLIP == "true" ]
	then
		vsearch --quiet --fastx_revcomp $FASTA.fasta --fastaout - | twofasta > $FASTA.rc.fasta
		FASTA=$FASTA.rc
	fi
	
	# Dereplicate
	if [ $TECH == "454" ] && [ "$DENOISE" == "yes" ]
	then
		cat *.trim.names > $SAMP.names
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$FASTA.fasta, name=$SAMP.names, format=count);
		get.current()"
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
	else
		vsearch --no_progress --derep_fulllength $FASTA.fasta --sizeout --uc $FASTA.unique.uc --output - | twofasta | sed '/>/s/;/ /' | tee $FASTA.unique.fasta | sed -n "/>/{s/>//;s/ size=/\t/;p}" | cat <(echo -e "Representative_Sequence\ttotal") - > $FASTA.unique.count_table
		awk '$1~"^[SH]$" {if(NR==1){printf "%s\t%s",$9,$9} else {if($1=="S"){printf "\n%s\t%s",$9,$9} else {printf ",%s",$9}}}END{printf "\n"}' $FASTA.unique.uc > $FASTA.unique.names
		FASTA=$FASTA.unique
		NAMES=$FASTA
		COUNT=$FASTA
		echo -e "fasta=$FASTA.fasta\nnames=$NAMES.names\ncount=$COUNT.count_table" > current_files.summary
		rm $NAMES.uc
	fi
fi

if [ $ASV == "no" ]
then
	# Subsample
	if [ $SUBSAMPLE == "yes" ]
	then
		SIZE=$(grep "Minimum" $EXEC/quality_check/$SUBPROJECT.summary.stat.tsv | cut -f 3 | cut -d "." -f 1)
		mothur "#set.logfile(name=$LOG, append=T);
		sub.sample(fasta=$FASTA.fasta, count=$COUNT.count_table, size=$SIZE);
		get.current()"
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
	fi
	
	# Precluster
	if [ $PRECLUST == "mothur" ]
	then
		# pre-cluster at max 1% after aligning to reference and removing the 5 % worse aligned reads
		if [ $TECH == "454" ] && [ $ITSX == "no" ]
		then
			PRECDIFF=$(( ${LENGTH} / 100 ))
		else
			PRECDIFF=$(twofasta $FASTA.fasta | awk -v M=$MAXLEN 'BEGIN{min=M}length($1)<M{min=length($1)}END{print int(min/100)'awk '$1!~"^>"{sum+=length($1)}END{print int(sum/(FNR/2)/100)}')
		fi
		if [ $PRECDIFF -ge 1 ]
		then
			mothur "#set.logfile(name=$LOG, append=T);
			set.dir(tempdefault=$DBFOLD);
			align.seqs(candidate=$FASTA.fasta, template=$DBCHOP.fasta, align=needleman, processors=$NCPUS);
			screen.seqs(fasta=current, count=$COUNT.count_table, optimize=start-end, criteria=95, processors=$NCPUS);
			filter.seqs(fasta=current, vertical=T, trump=., processors=$NCPUS);
			pre.cluster(fasta=current, count=current, diffs=$PRECDIFF, processors=$NCPUS);
			get.current()"
			unset FASTA COUNT
			FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
			COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
		else
			echo "The pre-culstering step was skipped because the smallest sequence have less than 100nt."
		fi
	elif [ $PRECLUST == "cdhit454" ]
	then
		# pre-cluster with cd-hit-454, allowing 1% dissimilarity with indel of max 1 nt long
		cdhit4542mothur () {
			bak=$1 ; fasta=$2 ; count=$3
			nl $bak | sed 's/>//;s/\.\.\.//' | awk '{print $4,$1,$2}' | sort -k 1,1 | join - <(sed '1d' $count | sort -k 1,1) | sort -k 3,3n -k 4,4nr | awk '{if(NR==1){nb=$3;printf "%s\t%s", $1,$2;sum=$4} else {if($3==nb){sum+=$4} else {nb=$3;printf "\t%s\n%s\t%s",sum,$1,$2;sum=$4}}}END{printf "\t%s\n",sum}' | sort -k 2,2n -t $'\t' | cut -f 1,3 | cat <(head -1 $count) - > ${count%.*}.precl.count_table
			seqkit grep -w 0 -f <(sed '1d' ${count%.*}.precl.count_table | cut -f 1) $fasta > ${fasta%.*}.precl.fasta
		}
		cd-hit-454 -T $NCPUS -B 1 -g 1 -M 6000 -c 0.99 -bak 1 -i $FASTA.fasta -o $FASTA.precl.fasta.temp
		cdhit4542mothur $FASTA.precl.fasta.temp.bak.clstr $FASTA.fasta $COUNT.count_table
		rm $FASTA.precl.fasta.temp*
		FASTA=$FASTA.precl
		COUNT=$COUNT.precl
		echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
		
	elif [ $PRECLUST == "homopolymer" ]
	then
		# cluster sequences with max 0.1% dissimilarity after removing every nucleotide repeats
		# dereplicate and swarm homopolymer compressed reads
		cat $FASTA.fasta | parallel -j $NCPUS --block 1M --pipe -k 'sed "/^>/s/[; ]size=.*//;/^>/!s/\([ATCGN]\)\1\+/\1/g"' | seqkit fx2tab -i | sort -k 1,1 | join <(sed '1d' $COUNT.count_table | sort -k 1,1) - | awk '{print ">"$1";size="$2"\n"$3}' | vsearch --derep_prefix - --quiet --sizein --sizeout --uc $NAMES.prefix.uc --output - | swarm -t $NCPUS -f -z -u $NAMES.homop.uc -w $FASTA.homop - > /dev/null
		# unoise only on homopolymer compressed reads of more than one copy
		vsearch --cluster_unoise $FASTA.homop --unoise_alpha 1.2 --iddef 3 --minsize 2 --threads $NCPUS --sizein --sizeout --uc $NAMES.seed.uc --centroids $FASTA.seed
		# map singletons on compressed reads at 99% similarity, drop unmapped
		seqkit grep -w0 -rv -f <(cut -f 9 $NAMES.seed.uc | sed 's/;size=.*//' | sort -u) $FASTA.homop | vsearch --usearch_global - --db $FASTA.seed --threads $NCPUS --top_hits_only --id 0.99 --iddef 3 --uc $FASTA.match
		awk '$1=="H"{split($9,a,";size=");split($10,b,";size="); print b[1],gensub(";","","g",b[2]),gensub(";","","g",a[2])}' $FASTA.match | sort -k 1,1 | awk '{if(NR==1){p=$1;s=$2+$3} else {if($1==p){s+=$3} else {print p"\t"s;p=$1;s=$2+$3}}}END{print p"\t"s}' | sort -k 2,2nr -t $'\t' | cat <(echo -e "Representative_Sequence\ttotal") - > $COUNT.precl.count_table
		# get back original sequence
		sed '/^>/s/[; ]size=.*//' $FASTA.fasta | seqkit fx2tab -i | sort -k 1,1 | join <(sed '1d' $COUNT.precl.count_table | sort -k 1,1) - | awk '{print ">"$1" size="$2"\n"$3}' > $FASTA.precl.fasta
		# climb back uc files for names file
		awk -F'\t' '{l=split($2,a,","); if(l>1){for(i=1;i<=l;i++){print $1,a[i]}} else {print $1,$2}}' $NAMES.names | sort -k 1,1 | join -1 1 -2 1 <(uc2na $NAMES.prefix.uc | sed 's/;size=[0-9]*;*//g' | sort -k 1,1) - | sort -k 2,2 | join -1 1 -2 2 <(uc2na $NAMES.homop.uc | sed 's/;size=[0-9]*;*//g' | sort -k 1,1) - | sort -k 2,2 | join -1 1 -2 2 <(cat $NAMES.seed.uc $FASTA.match | uc2na | sed 's/;size=[0-9]*;*//g' | sort -k 1,1) - | cut -d " " -f 2,5 | sort -k 1,1 | awk '$1!=$2{print}' | awk '{if(NR==1){p=$1; printf "%s\t%s,%s",p,p,$2} else {if($1==p){printf ",%s",$2} else {p=$1; printf "\n%s\t%s,%s",p,p,$2}}}END{printf "\n"}' > $NAMES.precl.names		
		rm $FASTA.seed $FASTA.homop $FASTA.match $NAMES.prefix.uc $NAMES.homop.uc $NAMES.seed.uc
		FASTA=$FASTA.precl
		COUNT=$COUNT.precl
		NAMES=$NAMES.precl
		echo -e "fasta=$FASTA.fasta\nnames=$NAMES.names\ncount=$COUNT.count_table" > current_files.summary
	fi
	
	# Remove singletons
	if [ ${DEL_FIRSTSING} == "yes" ]
	then
		awk 'NR==1 || $2>1{print}' $COUNT.count_table > $COUNT.pick.count_table
		seqkit grep -w0 -f <(awk 'NR>1{print $1}' $COUNT.pick.count_table) $FASTA.fasta > $FASTA.pick.fasta
		FASTA=$FASTA.pick
		COUNT=$COUNT.pick
		echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
		if [ -z "$NAMES" ]
		then
			cut -f 1 $COUNT.count_table | sed '1d' | sort | join -t $'\t' - <(sort -k 1,1 $NAMES.names) > $NAMES.pick.names
			NAMES=$NAMES.pick
			echo -e "names=$NAMES.names" >> current_files.summary
		fi
	fi
	
	# ITSx or Chimera removal
	if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
	then
		ITSx --cpu $NCPUS -i $FASTA.fasta --save_regions $ITSX --preserve T --graphical F -o $FASTA.itsx
		awk '$0~"^>"{sub(">","");print $1}' $FASTA.itsx.$ITSX.fasta | sort | join -t $'\t' - <(sed '1d' $COUNT.count_table | sort -t $'\t' -k 1,1) | cat <(head -1 $COUNT.count_table) - > $COUNT.itsx.$ITSX.count_table
		mothur "#set.logfile(name=$LOG, append=T);
		unique.seqs(fasta=$FASTA.itsx.$ITSX.fasta, count=$COUNT.itsx.$ITSX.count_table);
		get.current()"
		unset FASTA COUNT
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
		if [ -z "$NAMES" ]
		then
			cut -f 1 $COUNT.count_table | sed '1d' | sort | join -t $'\t' - <(sort -k 1,1 $NAMES.names) > $NAMES.itsx.names
			NAMES=$NAMES.itsx
			echo -e "names=$NAMES.names" >> current_files.summary
		fi
	elif [ $CHIMERA1 == "yes" ]
	then
		if [ $TECH == "454" ] || [ $(sed -n '$=' $COUNT.count_table) -lt 5000 ]
		then
			seqkit fx2tab -i $FASTA.fasta | sort -k 1,1 | join - <(sort -k 1,1 $COUNT.count_table) | awk '{print ">"$1";size="$3"\n"$2}' | vsearch --no_progress --uchime3_denovo - --nonchimeras - --xsize --qmask none > $FASTA.ok.fasta
		else
			. $BIN/parallel_uchime.sh
		fi
		if [ $(grep -c "^>" $FASTA.fasta) -eq $(grep -c "^>" $FASTA.ok.fasta) ]
		then
			ln -s $COUNT.count_table $COUNT.ok.count_table
		else
			grep "^>" $FASTA.ok.fasta | sed 's/>//' | sort | join - <(sed '1d' $COUNT.count_table | sort -k 1,1) | cat <(head -1 $COUNT.count_table) - > $COUNT.ok.count_table
		fi
		FASTA=$FASTA.ok
		COUNT=$COUNT.ok
		echo -e "fasta=$FASTA.fasta\ncount=$COUNT.count_table" > current_files.summary
		if [ ! -z "$NAMES" ]
		then
			if [ -L $COUNT.count_table ]
			then
				ln -s $NAMES.names $NAMES.ok.names
			else
				cut -f 1 $COUNT.count_table | sed '1d' | sort | join -t $'\t' - <(sort -k 1,1 $NAMES.names) > $NAMES.ok.names
			fi
			NAMES=$NAMES.ok
			echo -e "names=$NAMES.names" >> current_files.summary
		fi
	fi
	
	# clean intermediate files and compress
	eval $COMP $FASTA.fasta
	eval $COMP $COUNT.count_table
	rm -f *fasta *.count_table
	if [ ! -z "$NAMES" ]
	then
		eval $COMP $NAMES.names && rm -f *names
	fi
fi

# list files and directories
(. $BIN/list_step_files.sh)

echo END
