# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# load modules
module load DeltaMP/DELTAMP_VERSION

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/prev.txt
. $BIN/check_previous_step

# record newly set variables and load environment of previous step
(set -o posix; set > config/id.set)
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; if [ $REF_SUBPROJECT != "no" ] ; then declare $var=$(eval echo "$"$var | sed 's/'$REF_SUBPROJECT'/'$SUBPROJECT'/') ; fi ; done < config/OTU_env.txt

cd processing
NBOTUS=$(sed -n '$=' $NAMES_OTUS.names)
if [ $TARG == "COI" ] && [ $CLASSIF == "bayesian" ]
then
	NCPUS=`awk -v N=$NCPUS 'BEGIN{printf "%.f",N/2}'`
fi

# LCA function
lca() {
	parallel --recstart ">" --remove-rec-sep --pipe -k -N1 awk -v cons=$CONS -f $BIN/lca_vsearch.awk
}
export -f lca
export CONS BIN

# use full or primer/ITSx cut database
if [ -z $DBCUT ]
then
	TEMPLATE=$DB
	IDDEF=2 # end gap allowed
else
	TEMPLATE=$DBCUT
	IDDEF=1 # no end gap allowed
fi
if [ $UNPAIR == "yes" ]
then
	IDDEF=0 # similarity only based on matching columns, ignoring all gaps (end and internal, due to missing pair-end)
	if [ $ASSIGN_ALL == "yes" ] ; then PREF=${FASTA} ; else PREF=${FASTA_OTUS} ; fi
	sed '/^>/!s/NNNNNN*//' $PREF.fasta > $PREF.noN.fasta
	ADD=".noN"
	QCOV=" --query_cov 0.9" # fix a high query coverage to avoid too much internal gaps and wrong identification
fi

# incorporate additional sequences if provided
if [ $DBADD != "no" ]
then
	# check files presence
	if [ ! -f $DBADD.taxonomy ] | [ ! -f $DBADD.fasta ]
	then
		echo -e "Error: additionnal database file(s) is/are missing\nCheck directory $(dirname $DBADD) for files $(basename $DBADD).taxonomy and $(basename $DBADD).fasta\nAborting"
		exit 100
	fi
	# control absence of duplicate identifiers : not for the moment
	# control primer presence in new sequences : not for the moment
	# merge fasta and taxonomy
	if [ ! -f ${OUT%/*}/$(basename $DBADD)_plus_$TEMPLATE.fasta ]
	then
		cat $DBADD.fasta $DBFOLD/$TEMPLATE.fasta > ${OUT%/*}/$(basename $DBADD)_plus_$TEMPLATE.fasta
		cat $DBADD.taxonomy $DBFOLD/$TEMPLATE.taxonomy > ${OUT%/*}/$(basename $DBADD)_plus_$TEMPLATE.taxonomy
	fi
	DBFOLD=${OUT%/*}
	TEMPLATE=$(basename $DBADD)_plus_$TEMPLATE
	if [ $CLASSIF == "vsearch" ] && [ ! -f $DBFOLD/$TEMPLATE.udb ]
	then
		seqkit fx2tab -i $DBFOLD/$TEMPLATE.fasta | sed 's/\t$//g' | sort -k 1,1 -t $'\t' | join -t $'\t' - <(sort -k 1,1 -t $'\t' $DBFOLD/$TEMPLATE.taxonomy) | sed 's/;$//;s/;/,/g' | awk -F'\t' '{print ">"$1";tax="$3";\n"$2}' > $DBFOLD/vsearch.$TEMPLATE.fasta
		vsearch --makeudb_usearch $DBFOLD/vsearch.$TEMPLATE.fasta --output $DBFOLD/$TEMPLATE.udb
		rm $DBFOLD/vsearch.$TEMPLATE.fasta
	fi
	if [ $UNPAIR == "no" ]
	then
		IDDEF=2 # ignore end gap as there is no info about the additionnal sequences (cut to amplified fragment or not)
	fi
fi

# taxonomic assignment
if [ $CLASSIF == "bayesian" ]
then
	if [ $ASSIGN_ALL == "yes" ]
	then
		mothur "#set.dir(tempdefault=$DBFOLD);
		classify.seqs(fasta=$FASTA.fasta, template=$TEMPLATE.fasta, taxonomy=$TEMPLATE.taxonomy, cutoff=$CONS, method=wang, processors=$NCPUS);
		cluster(method=unique, name=$NAMES_OTUS.names);
		classify.otu(taxonomy=current, list=current, count=$COUNT.count_table, cutoff=$CONS);
		get.current()"
		LIST=`sed -n '/^list=/{s/.*=//;s/\.list//;p}' current_files.summary`
		CTAXO=`sed -n '/^constaxonomy=/{s/.*=//;s/\.cons.taxonomy//;p}' current_files.summary`
		transpose_tab $LIST.list | awk 'NR>2{split($2,a,",");for(i in a){print $1"\t"a[i]}}' | sort -k 2,2 | join -1 2 - <(awk '$1~"^>"{sub(">","",$1);print $1}' ${FASTA_OTUS}.fasta | sort) | sort -k 2,2 | join -2 2 <(sed '1d' $CTAXO.taxonomy) - | tr " " "\t" | cat <(paste <(head -1 $CTAXO.taxonomy) <(echo "repseq")) - > ${FASTA_OTUS}.cons.taxonomy
		rm $CTAXO.taxonomy $LIST.list *.rabund *.sabund *.tax.summary
		CTAXO=${FASTA_OTUS}.cons
	else
		mothur "#set.dir(tempdefault=$DBFOLD);
		classify.seqs(fasta=${FASTA_OTUS}.fasta, template=$TEMPLATE.fasta, taxonomy=$TEMPLATE.taxonomy, cutoff=$CONS, method=wang, processors=$NCPUS);
		get.current()"
		TAXO=`sed -n '/^taxonomy=/{s/.*=//;s/\.taxonomy//;p}' current_files.summary`
		CTAXO=$TAXO.cons
		sort -k 1,1 ${TAXO}.taxonomy | join -2 2 - <(sed '1d' ${COUNT_OTUS}.count_table | cut -f 1,2 | sort -k 2,2nr -k 1,1 | nl -n rz -w ${#NBOTUS} | sort -k 2,2) | sort -k 3,3n | awk 'BEGIN{OFS="\t";print "OTU","Size","Taxonomy","repseq"} {print "Otu"$3,$4,$2,$1}' > $CTAXO.taxonomy
		rm $TAXO.tax.summary $TAXO.taxonomy
	fi
elif [ $CLASSIF == "vsearch" ]
then
	if [ $ASSIGN_ALL == "yes" ]
	then
		vsearch --no_progress --usearch_global ${FASTA}$ADD.fasta --threads $NCPUS --db ${DBFOLD}/${TEMPLATE}.udb --dbmask none --qmask none --rowlen 0 --notrunclabels --userfields query+id${IDDEF}+target --maxaccepts 0 --maxrejects 32 --top_hits_only --output_no_hits --id 0.6 --iddef ${IDDEF}$QCOV --userout ${FASTA}.hits
		# Consensus among best matches
		awk '{split($2,a,",");for(i in a){print a[i],$1}}' $NAMES_OTUS.names | sort --parallel=$NCPUS -k 1,1 | join -o 1.2,2.2,2.3 - <(sed 's/;\t/\t/;s/;$//;s/ size=[0-9]*//' ${FASTA}.hits | sort --parallel=$NCPUS -k 1,1) | sed 's/;tax=/\t/' | sort --parallel=$NCPUS -k 1,1 -k 2,2nr | awk '{if($1!=p){sim=$2};if($2>=sim-1){print;p=$1}}' | sort --parallel=$NCPUS -k 1,1 -k 4,4 -k 3,3 | awk '$1 != p{printf ">"}{p=$1}1' | parallel -j $NCPUS --recstart ">" --pipe -k lca > ${FASTA_OTUS}.taxonomy
	else
		vsearch --no_progress --usearch_global ${FASTA_OTUS}$ADD.fasta --threads $NCPUS --db ${DBFOLD}/${TEMPLATE}.udb --dbmask none --qmask none --rowlen 0 --notrunclabels --userfields query+id${IDDEF}+target --maxaccepts 0 --maxrejects 32 --top_hits_only --output_no_hits --id 0.6 --iddef ${IDDEF}$QCOV --userout ${FASTA_OTUS}.hits
		# Consensus among best matches
		sed 's/;\t/\t/;s/;$//;s/;tax=/\t/' ${FASTA_OTUS}.hits | sort --parallel=$NCPUS -k 1,1 -k 4,4 | awk '$1 != p{printf ">"}{p=$1}1' | parallel -j $NCPUS --recstart ">" --pipe -k lca > ${FASTA_OTUS}.taxonomy
	fi
	CTAXO=${FASTA_OTUS}.cons
	sort -k 1,1 ${FASTA_OTUS}.taxonomy | join -2 2 - <(sed '1d' ${COUNT_OTUS}.count_table | cut -f 1,2 | sort -k 2,2nr -k 1,1 | nl -n rz -w ${#NBOTUS} | sort -k 2,2) | sort -k 5,5n | awk 'BEGIN{OFS="\t";print "OTU","Size","Taxonomy","similarity","references","repseq"} {print "Otu"$5,$6,$3,$2,$4,$1}' > $CTAXO.taxonomy
	rm ${FASTA_OTUS}*.hits ${FASTA_OTUS}.taxonomy
fi
if [ $UNPAIR == "yes" ]; then rm $PREF.noN.fasta ; fi

# ASV renaming
if [ $CLUST == "dada2" ]
then
	sed 's/O[Tt][Uu]/ASV/' $CTAXO.taxonomy > tmp.$CTAXO.taxonomy && mv tmp.$CTAXO.taxonomy $CTAXO.taxonomy
fi

# Integrate back OTUs found in previous subproject OTUs and re-number OTUs starting from last OTU of last previous subproject
if [ $PREV_PATH != "no" ]
then
	if [ $CLUST == "dada2" ]
	then
		declare -a PREV_TABLE PREV_NBOTUS PREV_REPSEQ
		for i in ${!PREV_PATH[@]}
		do
			PREV_TABLE[$i]=${PREV_SUB[$i]/%/.all_ASVs.tsv}
			tar xzvf ${PREV_PATH[$i]}/${PREV_SUB[$i]}.outputs.tar.gz ${PREV_SUB[$i]}.outputs/${PREV_TABLE[$i]}
			PREV_NBOTUS[$i]=$(sed '1d;s/^ASV0*//' ${PREV_SUB[$i]}.outputs/${PREV_TABLE[$i]} | cut -f 1 | sort -n | tail -1)
			PREV_REPSEQ[$i]=$(awk 'BEGIN{FS="\t"}NR==1{for(i=1;i<=NF;i++){if($i=="repseq"){print i}}}' ${PREV_SUB[$i]}.outputs/${PREV_TABLE[$i]})
		done
		MAXPREV_NBOTUS=$(echo ${PREV_NBOTUS[@]} | tr " " "\n" | awk '$1>M{M=$1}END{print M}')
		TOT_NBOTUS=$((NBOTUS+MAXPREV_NBOTUS))
		if [ $CLASSIF == "bayesian" ]
		then
			cut -f 1-2 previous.match_otu.pick.count_table | sed '1d' | sort -t $'\t' -k 1,1 | join -t $'\t' -2 3 - <( for i in ${!PREV_PATH[@]} ; do cut -f 1,$((${PREV_REPSEQ[$i]}-1))-${PREV_REPSEQ[$i]} ${PREV_SUB[$i]}.outputs/${PREV_TABLE[$i]} | sed '1d' ; done | sort -u | sort -k 3,3 -t $'\t') | sort -k 3,3 -t $'\t' | awk 'BEGIN{FS=OFS="\t"}{print $3,$2,$4,$1}' | cat <(head -1 $CTAXO.taxonomy) - <(sed '1d;s/^ASV0*//' $CTAXO.taxonomy | awk -v P=$MAXPREV_NBOTUS -v T=${#TOT_NBOTUS} 'BEGIN{FS="\t"}{printf "ASV%0"T"d\t%s\t%s\n",$1+P,$2,$3,$4}') > $CTAXO.match.taxonomy
		elif [ $CLASSIF == "vsearch" ]
		then
			cut -f 1-2 previous.match_otu.pick.count_table | sed '1d' | sort -t $'\t' -k 1,1 | join -t $'\t' -2 5 - <( for i in ${!PREV_PATH[@]} ; do cut -f 1,$((${PREV_REPSEQ[$i]}-3))-${PREV_REPSEQ[$i]} ${PREV_SUB[$i]}.outputs/${PREV_TABLE[$i]} | sed '1d' ; done | sort -u | sort -k 5,5 -t $'\t') | sort -k 3,3 -t $'\t' | awk 'BEGIN{FS=OFS="\t"}{print $3,$2,$4,$5,$6,$1}' | cat <(head -1 $CTAXO.taxonomy) - <(sed '1d;s/^ASV0*//' $CTAXO.taxonomy | awk -v P=$MAXPREV_NBOTUS -v T=${#TOT_NBOTUS} 'BEGIN{FS="\t"}{printf "ASV%0"T"d\t%s\t%s\t%s\t%s\t%s\n",$1+P,$2,$3,$4,$5,$6}') > $CTAXO.match.taxonomy
		fi
		cat previous.match_otu.pick.fasta $FASTA_OTUS.fasta > $FASTA_OTUS.match.fasta
		# add back missing sample(s) in count tables
		if [ ! -z "$(diff <(head -1 previous.match_otu.pick.count_table | tr "\t" "\n") <(head -1 $COUNT_OTUS.count_table | tr "\t" "\n"))" ]
		then
			LMISS=$(comm -13 <(head -1 previous.match_otu.pick.count_table | tr "\t" "\n") <(head -1 $COUNT_OTUS.count_table | tr "\t" "\n"))
			RMISS=$(comm -23 <(head -1 previous.match_otu.pick.count_table | tr "\t" "\n") <(head -1 $COUNT_OTUS.count_table | tr "\t" "\n"))
			declare -A MISSF
			MISSF[LMISS]=previous.match_otu.pick.count_table
			MISSF[RMISS]=$COUNT_OTUS.count_table
			SAMP_NAME=$(cut -f 1 $EXEC/config/lib4.list)
			for i in LMISS RMISS
			do
				if [ ! -z "${!i}" ]
				then
					for j in ${!i}
					do
						pos=$(echo $SAMP_NAME | awk -v J="$j" '{if($1==J){print "total#2"} else {for(i=2;i<=NF;i++){if($i==J){print $(i-1)"#"i+1}}}}')
						awk -v P="$pos" -v J="$j" 'BEGIN{FS=OFS="\t"; split(P,a,"#")}{if(NR==1){sub(a[1],a[1]"\t"J,$0)} else {sub("$","\t0",$(a[2]))};print}' ${MISSF[$i]} > tmp.${MISSF[$i]} && mv tmp.${MISSF[$i]} ${MISSF[$i]}
					done
				fi
			done
			unset SAMP_NAME LMISS RMISS MISSF
		fi
		cat previous.match_otu.pick.count_table <(sed '1d' $COUNT_OTUS.count_table) > $COUNT_OTUS.match.count_table
		for i in ${!PREV_PATH[@]}; do rm ${PREV_SUB[$i]}.outputs/${PREV_TABLE[$i]} ; done
	else
		declare -a PREV_CTAXO PREV_NBOTUS
		for i in ${!PREV_PATH[@]}
		do
			PREV_CTAXO[$i]=$(basename $(tar tzvf ${PREV_PATH[$i]}/${PREV_SUB[$i]}.processing.files.tar.gz | sed -n '/cons\.taxonomy/{s/^.* //;s/\.taxonomy//;p}'))
			tar xzvf ${PREV_PATH[$i]}/${PREV_SUB[$i]}.processing.files.tar.gz ${PREV_SUB[$i]}.processing/${PREV_CTAXO[$i]}.taxonomy
			PREV_NBOTUS[$i]=$(($(sed -n '$=' ${PREV_SUB[$i]}.processing/${PREV_CTAXO[$i]}.taxonomy) -1))
		done
		MAXPREV_NBOTUS=$(echo ${PREV_NBOTUS[@]} | tr " " "\n" | awk '$1>M{M=$1}END{print M}')
		TOT_NBOTUS=$((NBOTUS+MAXPREV_NBOTUS))
		sort -k 1,1 otus.aa.tmp | join -v 1 - <(cut -f 1 -d " " otus.aa.sosmop.tmp) | awk -v P=${#MAXPREV_NBOTUS} '{printf "%s Otu%0"P"d\n", $1,$4}' > otus.ao.tmp
		awk '{print $1,split($2,a,",")}' previous.match_otu.pick.names | sort -k 1,1 | join -o 1.2,2.2 otus.ao.tmp - | sort -k 1,1 | awk '{if(NR==1){p=$1;s=$2} else {if($1==p){s+=$2} else {print p"\t"s;p=$1;s=$2}}}END{print p"\t"s}' | join -t $'\t' - <( for i in ${!PREV_PATH[@]} ; do sed '1d' ${PREV_SUB[$i]}.processing/${PREV_CTAXO[$i]}.taxonomy | cut -f 1,3- ; done | sort -u | sort -t $'\t' -k 1,1) | cat <(head -1 $CTAXO.taxonomy) - <(sed '1d' $CTAXO.taxonomy | sed 's/^Otu0*//' | awk -v P=$MAXPREV_NBOTUS -v T=${#TOT_NBOTUS} '{a=$1;sub("^[^\t]*\t",""); printf "Otu%0"T"d\t%s\n",a+P,$0}') > $CTAXO.match.taxonomy
		sort -k 1,1 previous.match_otu.pick.names | awk '{print $1,split($2,a,","),$2}' | join otus.ao.tmp - | sort -k 2,2 -k 3,3nr | awk '{if(NR==1){p=$2;r=$1;a=$4} else {if($2==p){a=a","$4} else {print r"\t"a;p=$2;r=$1;a=$4}}}END{print r"\t"a}' | cat - $NAMES_OTUS.names > $NAMES_OTUS.match.names
		seqkit grep -f <(head -n $(cut -d " " -f 2 otus.ao.tmp | sort -u | wc -l) $NAMES_OTUS.match.names | cut -f 1) previous.match_otu.pick.fasta | twofasta | cat - $FASTA_OTUS.fasta > $FASTA_OTUS.match.fasta
		sed '1d' previous.match_otu.pick.count_table | sort -k 1,1 | join otus.ao.tmp - | join <(awk '{print $1,split($2,a,",")}' previous.match_otu.pick.names | sort -k 1,1) - | sort -k 3,3 -k 2,2nr | awk '{if(NR==1){p=$3;r=$1;for(i=4;i<=NF;i++){s[i]=$i}} else {if($3==p){for(i=4;i<=NF;i++){s[i]+=$i}} else {printf "%s",r;for(i=4;i<=NF;i++){printf "\t%s",s[i]};printf "\n";p=$3;r=$1;for(i=4;i<=NF;i++){s[i]=$i}}}}END{printf "%s",r;for(i=4;i<=NF;i++){printf "\t%s",s[i]};printf "\n"}' | cat <(head -1 $COUNT_OTUS.count_table) - <(sed '1d' $COUNT_OTUS.count_table) > $COUNT_OTUS.match.count_table
		cat previous.match.pick.fasta $FASTA.fasta > $FASTA.match.fasta
		for i in FASTA COUNT; do j=$i ; eval "$i=${!i}.match" ; done
		cat previous.match.pick.count_table <(sed '1d' $COUNT.count_table) > $COUNT.match.count_table
		rm $CTAXO.taxonomy
		for i in ${!PREV_PATH[@]} ; do rm ${PREV_SUB[$i]}.processing/${PREV_CTAXO[$i]}.taxonomy ; done
	fi
	for i in CTAXO FASTA_OTUS COUNT_OTUS NAMES_OTUS; do j=$i ; eval "$i=${!i}.match" ; done
fi


# Save newly set and updated variables
cd ..
comm -23 <(set -o posix; set | sort) <(sort config/id.set) | tr "=" "\t" | grep -v "^[a-z]" | grep -P -v "^PWD\t" | sed "s/'//g" > config/id_env.txt
rm config/id.set

# list files and directories
(. $BIN/list_step_files.sh)

echo END
