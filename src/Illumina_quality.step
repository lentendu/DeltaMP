# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Christina Wei√übecker, Anna Heintz-Buschart, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# load modules
module load DeltaMP/DELTAMP_VERSION

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
. $BIN/check_previous_step

# Demultiplex check
if [ $DEMULTI == "no" ]
then
	if [ -z $DUALID ]
	then
		. $BIN/check_${TECH}_barcodes.sh > archives/$SUBPROJECT.outputs/demultiplexing_check.tsv
	else
		cp libraries/fastq/demultiplexing_info.* archives/$SUBPROJECT.outputs/
	fi
fi

# Raw, primer detected [, filter], pair-end [, trim] read counts per library
if [ $TRUNCLEN == "no" ]
then
	if [ $QFILT == "average" ]
	then
		TRIMSTEPS=(raw raw_with_primer pairend trim)
		HEADER=($(echo "Sample Library Raw Primer_detected Pair-end $(seq -s " " $MINQUAL 30 | sed 's/\([0-9\.]*\)/Trimmed_at_\1_Phred_score/g')"))
	elif [ $QFILT == "maxee" ]
	then
		if [ $TRUNCBE == "yes" ]
		then
			TRIMSTEPS=(raw raw_with_primer)
			EESEQ=$(seq -s " " $MINEE $EESTEP $MAXEE)
			HEADER=($(echo "Sample Library Raw Primer_detected Pair-end $(parallel -k echo {1}-{2} ::: $EESEQ ::: $EESEQ | sed 's/^/Pair-end_/;s/$/_maxEE/' | tr "\n" " ")"))
		else
			TRIMSTEPS=(raw raw_with_primer pairend trim)
			HEADER=($(echo "Sample Library Raw Primer_detected Pair-end $(seq -s " " $MAXEE -$EESTEP $MINEE | sed 's/\([0-9\.]*\)/Trimmed_at_\1_maxEE/g')"))
		fi
	fi
else
	TRIMSTEPS=(raw raw_with_primer truncated pairend)
	HEADER=(Sample Library Raw Primer_detected Minimal_length_and_quality_truncation Pair-end)	
	if [ $UNPAIR == "yes" ] || [ $ASV == "yes" ]
	then
		TRIMSTEPS=(${TRIMSTEPS[@]:0:3})
		HEADER=(${HEADER[@]:0:5})
	fi
fi

while read samp fwd rvs
do
	lib=$(echo $fwd $rvs | sed 's/\(.*\)[^ ]* \1.*$/\1/')
	if [ $CLIPPING == "no" ]
	then
		if [ $UNPAIR == "yes" ]
		then
			RAW_COUNT=$(awk '{s+=$2}END{print s}' libraries/raw_stat/${FWD_NAME}.$lib.fwd.length)
		elif [ $PALG == "vsearch" ]
		then
			RAW_COUNT=$(awk '$2=="Pairs"{print $1;exit}' libraries/fastq/log.pairend.${FWD_NAME}.$lib.txt)
		elif [ $PALG == "ngmerge" ]
		then
			RAW_COUNT=$(sed -n '/analyzed:/s/.*: //p' libraries/fastq/log.pairend.${FWD_NAME}.$lib.txt)
		else
			RAW_COUNT=$(tac libraries/fastq/log.pairend.${FWD_NAME}.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4)
		fi
	else
		RAW_COUNT=$(grep -m 1 "^Total read pairs processed" libraries/fastq/log.cutadapt.$lib.fr.txt | awk '{gsub(",","",$NF); print $NF}')
	fi
	if [ -z "$RAW_COUNT" ]
	then
		seq -s $'\t' 1 $((${#HEADER[@]}-2)) | sed "s/\([^\t]*\)/0/g;s/^/$samp\t$lib\t/"
	else
		for i in ${FWD_NAME} ${RVS_NAME}
		do
			if [ $i == "$FWD_NAME" ] ; then j=${RVS_NAME} ; else j=${FWD_NAME} ; fi
			if [ $UNPAIR == "yes" ] && [ -f libraries/raw_stat/$i.$lib.fwd.length ]
			then
				PRIMER_COUNT=$(awk '{sum+=$2}END{print sum}' libraries/raw_stat/$i.$lib.fwd.length)
				# Minimum value with most relaxed length and maxEE parameters
				if [ -f quality_check/$i.$fwd.eestat ]
				then
					paste <(echo -e "$PRIMER_COUNT") <(awk -v F=$(awk 'NR==1{print $(NF-1)}' quality_check/$i.$fwd.eestat) -v R=$(awk 'NR==1{print $(NF-1)}' quality_check/$j.$rvs.eestat) 'BEGIN{if(F>R){print R} else print F}')
				else
					echo -e "$PRIMER_COUNT\t0"
				fi
			elif [ -f libraries/fastq/$i.$j.$lib.pairend.fastq.$EXT ]
			then
				if [ $TRUNCLEN == "no" ]
				then
					if [ $TRUNCBE == "yes" ]
					then
						if [ $PALG == "vsearch" ]
						then
							paste <(awk '$2=="Pairs" || $2=="Merged"{print $1}' libraries/fastq/log.pairend.$i.$lib.txt | tr "\n" "\t") <(cut -d " " -f 3 quality_check/$i.$j.$lib.pairend.eestat | tr "\n" "\t")
						elif [ $PALG == "ngmerge" ]
						then
							paste <(sed '1d;s/.*: //' libraries/fastq/log.pairend.$i.$lib.txt | tr "\n" "\t") <(cut -d " " -f 3 quality_check/$i.$j.$lib.pairend.eestat | tr "\n" "\t")
						else
							paste <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4) <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tOK\t" | cut -f 4) <(cut -d " " -f 3 quality_check/$i.$j.$lib.pairend.eestat | tr "\n" "\t")
						fi
					else
						if [ $PALG == "vsearch" ]
						then
							paste <(awk '$2=="Pairs" || $2=="Merged"{print $1}' libraries/fastq/log.pairend.$i.$lib.txt | tr "\n" "\t") quality_check/$i.$j.$lib.stat
						elif [ $PALG == "ngmerge" ]
						then
							paste <(sed '1d;s/.*: //' libraries/fastq/log.pairend.$i.$lib.txt | tr "\n" "\t") quality_check/$i.$j.$lib.stat
						else
							paste <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4) <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tOK\t" | cut -f 4) quality_check/$i.$j.$lib.stat
						fi
					fi
				else
					PRIMER_COUNT=$(awk '{sum+=$2}END{print sum}' libraries/raw_stat/$i.$lib.fwd.length)
					if [ $TRUNCBE == "yes" ]
					then
						if [ $PALG == "vsearch" ]
						then
							paste <(echo -e "$PRIMER_COUNT") <(awk '$2=="Pairs"{print $1}' libraries/fastq/log.pairend.$i.$lib.txt | tr "\n" "\t")
						elif [ $PALG == "ngmerge" ]
						then
							paste <(echo -e "$PRIMER_COUNT") <(sed '1d;s/.*: //' libraries/fastq/log.pairend.$i.$lib.txt | head -1)
						else
							paste <(echo -e "$PRIMER_COUNT") <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4)
						fi
					else
						if [ $PALG == "vsearch" ]
						then
							paste <(echo -e "$PRIMER_COUNT") <(awk '$2=="Pairs" || $2=="Merged"{print $1}' libraries/fastq/log.pairend.$i.$lib.txt | tr "\n" "\t")
						elif [ $PALG == "ngmerge" ]
						then
							paste <(echo -e "$PRIMER_COUNT") <(sed '1d;s/.*: //' libraries/fastq/log.pairend.$i.$lib.txt | tr "\n" "\t")
						else
							paste <(echo -e "$PRIMER_COUNT") <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4) <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tOK\t" | cut -f 4)
						fi
					fi
				fi
			fi
		# sum accross orientation if multiple
		done | awk -v L=${#HEADER[@]} '{for(i=1;i<=NF;i++){s[i]+=$i;if(NF>m){m=NF}}}END{for(i=1;i<=m;i++){printf "\t%s", s[i]}; if(m<(L-3)){for(i=m+1;i<=(L-3);i++){printf "\t0"}}}' | sed "s/^/$samp\t$lib\t${RAW_COUNT}/;s/$/\n/"
	fi
done < config/lib3.list | cat <(echo ${HEADER[@]} | tr " " "\t") - > quality_check/$SUBPROJECT.lib_counts.tsv
cd quality_check

# per sample
sed '1d' $SUBPROJECT.lib_counts.tsv | sort -k 1,1 -t $'\t' | awk 'BEGIN{FS="\t"}{if(NR==1){S=$1;L=NF;for(i=3;i<=L;i++){a[i]=$i}} else {if($1==S){if(NF>L){L=NF};for(i=3;i<=L;i++){a[i]+=$i}} else {printf "%s",S;for(i=3;i<=L;i++){printf "\t%s",a[i]};printf "\n";S=$1;L=NF;for(i=3;i<=L;i++){a[i]=$i}}}}END{printf "%s",S;for(i=3;i<=L;i++){printf "\t%s",a[i]};printf "\n"}' | mimato | cat <(head -1 $SUBPROJECT.lib_counts.tsv | sed 's/\tLibrary\t/\t/') - > $SUBPROJECT.sample_counts.tsv

# Count check
declare -a MINTRESH MIN_DEPTH_ECHO
for i in $(seq 1 $((${#TRIMSTEPS[@]}-1)))
do
	if [ "${TRIMSTEPS[$i]}" == "pairend" ] && [ ! -z "$MINPAIR" ]
	then
		MINTRESH[$i]=$MINPAIR
	else
		MINTRESH[$i]=$MIN_DEPTH
	fi
	if (( $(echo "${MINTRESH[$i]} > 1" |bc -l) ))
	then
		MIN_DEPTH_ECHO[$i]=${MINTRESH[$i]}
	else
		MIN_DEPTH_ECHO[$i]="${MINTRESH[$i]} times the amount of \${TRIMSTEPS[\$((i-1))]}"
	fi
	head -n -4 $SUBPROJECT.sample_counts.tsv | awk -v I=$((i+1)) -v M=${MINTRESH[$i]} 'BEGIN{OFS="\t"}NR>1{if(M<=1){if($(I+1)<M*$I) print $1,$(I+1),$(I+1)/$I} else if(M>1){if($(I+1)<M)print $1,$(I+1)}}' > min_depth.${TRIMSTEPS[$i]}.test
done
SKIP_SAMP=$(awk -v S=$(sed -n '$=' $SUBPROJECT.sample_counts.tsv) -v T=$SKIP_TRESH 'BEGIN{M=(S-5)*T/100; printf "%.0f", int(M) }')
for i in $(seq 1 $((${#TRIMSTEPS[@]}-1)))
do
	if [ -s min_depth.${TRIMSTEPS[$i]}.test ]
	then
		echo "The following sample(s) do not have the requested minimum amount of ${TRIMSTEPS[$i]} reads fixed at "$(eval echo ${MIN_DEPTH_ECHO[$i]})" reads:"
		cat <(echo -e "Sample\t${TRIMSTEPS[$((i-1))]} reads\tpercent") min_depth.${TRIMSTEPS[$i]}.test | column -t -s $'\t'
		echo ""
		# compare amount of samples to the skip threshod
		if [ $(cat min_depth.${TRIMSTEPS[$i]}.test | wc -l) -le $SKIP_SAMP ]
		then
			echo "However, $SKIP_SAMP samples are allowed to have their read count below the minimum threshold, so the qualtiy check continues."
			echo ""
		else
			if [ $SKIP_TRESH -gt 0 ]; then echo "This is more than the allowed amount of samples to be below the minimum threshold fixed at $SKIP_SAMP :"; fi
			echo "Aborting"
			awk -F'\t' -v L=${#TRIMSTEPS[@]} '{printf "%s",$1;for(i=2;i<=L+1;i++){printf "\t%s",$i};printf "\n"}' $SUBPROJECT.sample_counts.tsv > $SUBPROJECT.summary.stat.tsv
			ln -s $PWD/$SUBPROJECT.summary.stat.tsv $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.read_counts.tsv
			(. $BIN/list_step_files.sh)
			exit 100
		fi
	else
		eval echo "All samples have at least the minimum amount of ${TRIMSTEPS[$i]} reads fixed at ${MIN_DEPTH_ECHO[$i]} reads."
		echo ""
	fi
done

# Optimize quality
# only with samples which have more than 10 reads
head -n -4 $SUBPROJECT.sample_counts.tsv | awk -v T=${#TRIMSTEPS[@]} 'NR>1 && $(T+1)>10{print $1}' | join -t $'\t' - ../config/lib3.list > libgood.list
if [ $TRUNCBE == "no" ]
then
	if [ $SKIP_TRESH -eq 100 ]
	then
		if [ $QFILT == "average" ] ; then echo $MINQUAL > optimized.quality.txt ; else echo $MAXEE > optimized.quality.txt ; fi
	elif (( $(echo "${MINTRESH[$((${#MINTRESH[@]}-1))]} > 1" |bc -l) ))
	then
		# above integer threshold and more than 75% of raw reads
		head -n -4 $SUBPROJECT.sample_counts.tsv | transpose_tab | sed '1,4d;/^[ \t]*$/d' | tac | cat <(head -n -4 $SUBPROJECT.sample_counts.tsv | cut -f 5 | transpose_tab) - | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"} {if(NR==1){for(i=2;i<=NF;i++){ref[i]=$i}} ; C=0 ;for(i=2;i<=NF;i++){if($i<M || $i<ref[i]*0.75){C+=1}};if(C<=S){print $1;exit}}' | sed 's/Trimmed at //;s/ Phred score//;s/ maxEE//' > optimized.quality.txt
	else
		# above ratio of pair-end reads
		head -n -4 $SUBPROJECT.sample_counts.tsv | cut -f 5- | paste - <(head -n -4 $SUBPROJECT.sample_counts.tsv | cut -f 4) | transpose_tab | tac | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for (i=2;i<=NF;i++){R[i]=$i}} else {C=0 ; for(i=2;i<=NF;i++){if($i<R[i]*M){C+=1}};if(C<=S){print $1;exit}}}' | sed 's/Trimmed at //;s/ Phred score//;s/ maxEE//' > optimized.quality.txt
	fi
	QUAL=`cat optimized.quality.txt`
	if [ $QFILT == "average" ]
	then
		echo "Minimum average quality optimized to $QUAL"
		QUALPOS=$(($QUAL - $MINQUAL + 5))
	elif [ $QFILT == "maxee" ]
	then
		echo "Maximum expected error optimized to $QUAL"
		QUALPOS=$(printf %.0f $(echo "($MAXEE - $QUAL) * (1 / $EESTEP) + 5" | bc))
	fi
	cut -f 1-4,$QUALPOS $SUBPROJECT.sample_counts.tsv > $SUBPROJECT.summary.stat.tsv
	ln -s $PWD/$SUBPROJECT.summary.stat.tsv $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.read_counts.tsv
else
	if [ $TRUNCLEN != "no" ] && [ $UNPAIR == "no" ] && ( [ $MEANLEN == "auto" ] || ( [ $MEANLEN != "auto" ] && [ $CLIPPING == "both" ] ) )
	then
		MEANLEN=$(cat ../libraries/raw_stat/*pairend.length | awk '{m+=$1*$2;s+=$2}END{x=m/s; print int(x)+(x>int(x))}')
		echo "Mean expected length of pair-end reads computed and fixed at $MEANLEN"
		if [ $MEANLEN -lt $MINLEN ]
		then
			MEANLEN=$MINLEN
		elif [ $MEANLEN -gt $MAXLEN ]
		then
			MEANLEN=$MAXLEN
		fi
	fi
	for i in ${FWD_NAME} ${RVS_NAME}
	do
		if [ $i == "$FWD_NAME" ] ; then j=${RVS_NAME} ; else j=${FWD_NAME} ; fi
		# only proceed if enough samples in this orientation
		NBOK=$(ls ../libraries/raw_stat/$i.*.fwd.length 2> /dev/null | sed -n '$=')
		if (( $(echo "${NBOK:-0} <= ( $SAMP_SIZE * $SKIP_TRESH / 100 )" | bc -l) ))
		then
			echo "There is only ${NBOK:-0} samples with reads in the $i.fwd & $j.rvs orientation. This orientation is ignored for the truncation parameter optimization."
			break
		else
			echo "Truncation parameter optimization for orientation $i.fwd & $j.rvs"
		fi
		#
		if [ $TRUNCLEN == "no" ] && [ ! -z "$(find ../libraries/fastq -name $i.$j.*.pairend.fastq.$EXT)" ]
		then
			if [ $SKIP_TRESH -eq 100 ]
			then
				echo $MAXEE > $i.fwd.optimized.quality.txt && echo $MAXEE > $j.rvs.optimized.quality.txt
			else
				# keep pair of maxEE meeting threshold criteria and with highest number of paired reads
				while read sam fwd rvs
				do
					lib=$(echo $fwd $rvs | sed -r 's/^(.*)[^ ]* \1.*/\1/')
					if [ $sam == $(awk 'NR==1{print $1}' libgood.list) ]
					then
						cut -f 1-2 -d " " $i.$j.$lib.pairend.eestat | sed 's/ /-/' | transpose | sed 's/^/raw /'
					fi
					raw=$(if [ $PALG == "vsearch" ] ; then awk '$2=="Pairs"{print $1;exit}' ../libraries/fastq/log.pairend.$i.$lib.txt ; elif [ $PALG == "ngmerge" ] ; then sed -n '/analyzed:/s/.*: //p' ../libraries/fastq/log.pairend.$i.$lib.txt ; else tac ../libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4 ; fi)
					cut -f 3 -d " " $i.$j.$lib.pairend.eestat | cat <(echo $raw) - | transpose
				done < libgood.list | transpose > $i.$j.eestat
				awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP '{if(NR==1){L=NF;for(i=2;i<=L;i++){R[i]=$i*M}} else {split($1,a,"-");T=0;C=0;for(i=2;i<=L;i++){T+=$i;if($i>=R[i]){C+=1}};if(C>=L-1-S){print a[1],a[2],a[1]+a[2],C"/"L-1,int(T/10^(length(T)-3))}}}' $i.$j.eestat | sort -k 5,5nr -k 3,3n -k 1,1n | awk -v I=$i -v J=$j 'NR==1{print $1 > I".fwd.optimized.quality.txt" ; print $2 > J".rvs.optimized.quality.txt"}'
				if [ ! -s $i.fwd.optimized.quality.txt ] || [ ! -s $j.rvs.optimized.quality.txt ]
				then
					echo "No combination of maxEE ranging from $MINEE to $MAXEE used to truncate reads before pair-end asssembly allows to keep at least ${MINTRESH[$((${#MINTRESH[@]}-1))]} x the number of raw reads with primers in at least $(($(sed -n '$=' libgood.list)-SKIP_SAMP)) samples after pair-end assembly."
					echo "Aborting"
					(. $BIN/list_step_files.sh)
					exit 100
				fi
				awk -v E=$(paste -d"-" $i.fwd.optimized.quality.txt $j.rvs.optimized.quality.txt) '$1==E{print $0}' $i.$j.eestat | transpose | sed '1d' > $i.$j.trunc.nb
				rm $i.$j.eestat
			fi
		elif [ ! -z "$(find ../libraries/raw_stat -name $i.*.fwd.length)" ] && [ ! -z "$(find ../libraries/raw_stat -name $j.*.rvs.length)" ]
		then
			MAXLF=$(while read lib ; do awk 'END{print $1}' ../libraries/raw_stat/$i.$lib.fwd.length ; done < <(cut -f 2-3 libgood.list | sed 's/\(.*\)[^\t]*\t\1.*$/\1/') | sort -n | awk -v l=$LENSTEP 'NR==1{print int($1/l)*l}')
			MAXLR=$(while read lib ; do awk 'END{print $1}' ../libraries/raw_stat/$j.$lib.rvs.length ; done < <(cut -f 2-3 libgood.list | sed 's/\(.*\)[^\t]*\t\1.*$/\1/') | sort -n | awk -v l=$LENSTEP 'NR==1{print int($1/l)*l}')
			if [ $SKIP_TRESH -eq 100 ]
			then
				while read samp fwd rvs
				do
					for x in $(seq $TRUNCLEN $LENSTEP $MAXLF)
					do
						for y in $(seq $TRUNCLEN $LENSTEP $MAXLR)
						do
							if [ $((x+y-MIN_OV)) -eq $MAXLEN ]
							then
								paste <(awk -v X=$x '$1==X{print X,$(NF-1)}' $i.$fwd.eestat) <(awk -v Y=$y '$1==Y{print Y,$(NF-1)}' $j.$rvs.eestat)
							fi
						done
					done | awk -v S=$samp '{if($2>$4){m=$4} else {m=$2}; print S,$1,$3,m}'
				done < libgood.list > $i.maxlen.stat
				read LENFWD LENRVS LENTOP < <(sort -k 2,2 -k 3,3 $i.maxlen.stat | awk '{if(NR==1){p2=$2;p3=$3;s=$4} else {if($2==p2 && $3==p3){s+=$4} else {print p2,p3,s;p2=$2;p3=$3;s=$4}}}END{print p2,p3,s}' | sort -k 3,3nr | head -1)
				echo $LENFWD $MAXEE > $i.fwd.optimized.quality.txt
				echo $LENRVS $MAXEE > $j.rvs.optimized.quality.txt
				awk -v F=$LENFWD -v R=$LENRVS '$2==F && $3==R{print $4}' $i.maxlen.stat > $i.$j.trunc.nb
				rm $i.maxlen.stat
			else
				# initialize
				if [ $MAXTRUNCLEN != "no" ]
				then
					if [ $MAXTRUNCLEN -lt $MAXLF ] ; then MAXLF=$MAXTRUNCLEN ; fi
					if [ $MAXTRUNCLEN -lt $MAXLR ] ; then MAXLR=$MAXTRUNCLEN ; fi
				fi
				parallel -k echo ::: $(seq $TRUNCLEN $LENSTEP $MAXLF) ::: $(seq $MINEE $EESTEP $MAXEE) | awk -v EE=$MAXEE -v ME=$MINEE '{print $1,$2,$1*sqrt(0.5-($2-ME+0.05)/(EE-ME)/2+0.5)}' > $i.fwd.stat
				parallel -k echo ::: $(seq $TRUNCLEN $LENSTEP $MAXLR) ::: $(seq $MINEE $EESTEP $MAXEE) | awk -v EE=$MAXEE -v ME=$MINEE '{print $1,$2,$1*sqrt(0.5-($2-ME+0.05)/(EE-ME)/2+0.5)}' > $j.rvs.stat
				# optimize combination of length and maxEE
				while read samp fwd rvs
				do
					if [ -f $i.$fwd.eestat ]
					then
						sort -k 1,1 $i.$fwd.eestat | join -t $'\t' -a 2 - <(seq $TRUNCLEN $LENSTEP $MAXLF | sort) | sort -k 1,1n | awk -v L=$(seq $MINEE $EESTEP $MAXEE | wc -w) 'BEGIN{FS="\t"}{for(i=2;i<=L+1;i++){if(NF==1){print "0 0"}else{print $i}}}' | paste $i.fwd.stat - > $i.fwd.temp && mv $i.fwd.temp $i.fwd.stat
						sort -k 1,1 $j.$rvs.eestat | join -t $'\t' -a 2 - <(seq $TRUNCLEN $LENSTEP $MAXLR | sort) | sort -k 1,1n | awk -v L=$(seq $MINEE $EESTEP $MAXEE | wc -w)  'BEGIN{FS="\t"}{for(i=2;i<=L+1;i++){if(NF==1){print "0 0"}else{print $i}}}' | paste $j.rvs.stat - > $j.rvs.temp && mv $j.rvs.temp $j.rvs.stat
					else
						awk -v N=$(sed -n '$=' $i.fwd.stat) 'BEGIN{for(i=1;i<=N;i++){print 0,0.0}}' | paste $i.fwd.stat - > $i.fwd.temp && mv $i.fwd.temp $i.fwd.stat
						awk -v N=$(sed -n '$=' $i.rvs.stat) 'BEGIN{for(i=1;i<=N;i++){print 0,0.0}}' | paste $i.rvs.stat - > $i.rvs.temp && mv $i.rvs.temp $i.rvs.stat
					fi
				done < libgood.list
				# initial count for this direction and total count for each sample
				parallel --colsep "\t" -k "lib=\$(echo {2} {3} | sed 's/\(.*\)[^ ]* \1.*\$/\1/') ; awk '{sum+=\$2}END{print sum}' ../libraries/raw_stat/$i.\$lib.fwd.length" :::: libgood.list | paste -d " " - <(head -n -4 $SUBPROJECT.sample_counts.tsv | sed '1d' | join - libgood.list | cut -d " " -f 3) | tr "\n" "\t" | sed 's/^/primer removed\t/;s/\t$/\n/' > $i.$j.ref_count
				# First on reverse reads
				sort -k 3,3nr -k 1,1nr $j.rvs.stat | cat $i.$j.ref_count - | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $j.rvs.optimized.quality.txt
				# then, for the same maxEE, length optimzation for forward reads if mean expected length of paired reads can be reached
				if [ $UNPAIR == "yes" ]
				then
					MINOPTL=$TRUNCLEN
					MEANLEN=$((TRUNCLEN*2))
				else
					MINOPTL=$(awk -v m=$((MEANLEN+MIN_OV)) '{print m-$1}END{if(NR==0){print m}}' $j.rvs.optimized.quality.txt)
				fi
				if [ -s $j.rvs.optimized.quality.txt ] && [ $MINOPTL -le $MAXLR ]
				then
					awk -v EE=$(cut -d " " -f 2 $j.rvs.optimized.quality.txt) -v m=$MINOPTL '$1>=m && $2==EE{print}' $i.fwd.stat | sort -k 1,1nr | cat $i.$j.ref_count - | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $i.fwd.optimized.quality.txt
					# with different maxEE if no good solution
					if [ ! -s $i.fwd.optimized.quality.txt ]
					then
						awk -v m=$MINOPTL '$1>=m{print}' $i.fwd.stat | sort -k 3,3nr -k 1,1nr | cat $i.$j.ref_count - | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $i.fwd.optimized.quality.txt
					fi
				fi
				# the otherway around if it does not work or if not long enough
				if [ ! -s $j.rvs.optimized.quality.txt ] || [ $(paste $i.fwd.optimized.quality.txt $j.rvs.optimized.quality.txt | awk '{print $1+$3}') -lt $((MEANLEN+MIN_OV)) ]
				then
					sort -k 3,3nr -k 2,2n $i.fwd.stat | cat $i.$j.ref_count - | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $i.fwd.optimized.quality.txt
					awk -v EE=$(cut -d " " -f 2 $i.fwd.optimized.quality.txt) '$2==EE{print}' $j.rvs.stat | sort -k 1,1nr | cat $i.$j.ref_count - | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $j.rvs.optimized.quality.txt
					# with different maxEE if it is still not working
					if [ ! -s $j.rvs.optimized.quality.txt ]
					then
						sort -k 3,3nr -k 2,2n $j.rvs.stat | cat $i.$j.ref_count - | awk -v M=${MINTRESH[$((${#MINTRESH[@]}-1))]} -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $j.rvs.optimized.quality.txt
					fi
				fi
				if [ ! -s $i.fwd.optimized.quality.txt ] || [ ! -s $j.rvs.optimized.quality.txt ]
				then
					if [ ! -z "$MINPAIR" ] ; then MINPAIRECHO=" and the 'Minimum number of pair-end reads per sample'" ; fi
					echo "There is no truncation parameters which can satisfy the trimming parameters, the mean expected length of paired reads and the minimum number of reads kept."
					echo "Relax the quality filtration parameter (e.g. increase maxEE), increase the 'Samples percentage allowed below the read count threshold', decrease the 'Minimum number of trimmed reads per sample'$MINPAIRECHO, or set an appropriate value to the 'Expected mean length of amplified barcode gene'"
					echo "Aborting"
					(. $BIN/list_step_files.sh)
					exit 100
				fi
				cat <(grep "$(cat $i.fwd.optimized.quality.txt)" $i.fwd.stat) <(grep "$(cat $j.rvs.optimized.quality.txt)" $j.rvs.stat) | cut -f 2- | sed 's/ [0-9\.]*//g' | transpose_tab | awk '{if($1>$2){print $2} else print $1}' > $i.$j.trunc.nb
				rm $i.fwd.stat $j.rvs.stat $i.$j.ref_count
				echo "Truncation length and maximum expected error for $i orientated forward reads to $(cat $i.fwd.optimized.quality.txt | sed 's/ / and /')"
				echo "Truncation length and maximum expected error for $j orientated reverse reads to $(cat $j.rvs.optimized.quality.txt | sed 's/ / and /')"
				# control that the mean expected length can be reached
				if [ $(paste $i.fwd.optimized.quality.txt $j.rvs.optimized.quality.txt | awk '{print $1+$3}') -lt $((MEANLEN+MIN_OV)) ]
				then
					echo "These truncation parameters do not allow to reach the mean expected length $MEANLEN after pair-end assembly."
					echo "Relax the quality filtration parameter, increase the 'Samples percentage allowed below the read count threshold', or set an appropriate value to the 'Expected mean length of amplified barcode gene'"
					echo "Aborting"
					(. $BIN/list_step_files.sh)
					exit 100
				fi
			fi
		fi
	done
	paste <(cut -f 1 libgood.list) *trunc.nb | awk '{s=$2;if(NF==3){s+=$3};print $1"\t"s}' | awk '{if(NR==1){p=$1;s=$2} else {if($1==p){s+=$2} else {print p"\t"s;p=$1;s=$2}}}END{print p"\t"s}' | mimato | cat <(echo -e "Sample\tOptimized_truncation_estimates") - | sort -k 1,1 | join -a 1 -1 2 <(cut -f 1-$((${#TRIMSTEPS[@]}+1)) $SUBPROJECT.sample_counts.tsv | nl | sort -k 2,2) - | sort -k 2,2n | cut -f 1,3- -d " " | awk -v l=${#TRIMSTEPS[@]} '{if(NF<l+2){print $0,"NA"} else print $0}' | sed 's/ /\t/g;1 s/_/ /g' > $SUBPROJECT.summary.stat.tsv
	rm *trunc.nb
fi
ln -s $PWD/$SUBPROJECT.summary.stat.tsv $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.read_counts.tsv

# check for no read
QMISS=$(head -n -4 $SUBPROJECT.summary.stat.tsv | awk 'NR>1 && $(NF-1)>0 && ($NF==0 || $NF=="NA"){print $1}')
if [ ! -z "$QMISS" ]
then
	MY_TMP_NAME=`echo $JOBNAME | sed "s/$DELTAMP_VER\.//;s/\.$SUBPROJECT//"`
	echo $QMISS | tr " " "\n" > $EXEC/config/${MY_TMP_NAME}.missing
fi

# Merge raw stat statistics
cd $EXEC/libraries/raw_stat
if ( [ $DEMULTI == "no" ] || [ $PERRUN == "yes" ] ) && [ $ONERUN == "no" ]
then
	if [ $PERRUN == "yes" ]
	then
		LIB_NAME=($(cut -f 3 $EXEC/config/librun.list | sort -u))
	else
		LIB_NAME=($(cut -f 1 $EXEC/config/lib2.list))
	fi
	for i in ${LIB_NAME[@]}
	do
		Rscript --vanilla $BIN/Rscript_raw_stat_figures_Illumina.R $SUBPROJECT $BIN DeltaMP_${VERSION[DELTAMP]} $i $FWD_NAME $RVS_NAME $TRUNCLEN
		gs -q -sDEVICE=pdfwrite -o $i.raw_and_pair-end_reads_statistics.pdf $SUBPROJECT.$i.quality.*.pdf $SUBPROJECT.$i.length.*.pdf $SUBPROJECT.$i.position_quality.*.pdf $SUBPROJECT.$i.legend.pdf
		rm $SUBPROJECT.$i.quality.*.pdf $SUBPROJECT.$i.length.*.pdf $SUBPROJECT.$i.position_quality.*.pdf $SUBPROJECT.$i.legend.pdf
	done
	gs -q -sDEVICE=pdfwrite -o $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.raw_and_pair-end_reads_statistics.pdf *.raw_and_pair-end_reads_statistics.pdf
	rm *.raw_and_pair-end_reads_statistics.pdf
else
	Rscript --vanilla $BIN/Rscript_raw_stat_figures_Illumina.R $SUBPROJECT $BIN DeltaMP_${VERSION[DELTAMP]} all $FWD_NAME $RVS_NAME $TRUNCLEN
	gs -q -sDEVICE=pdfwrite -o $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.raw_and_pair-end_reads_statistics.pdf $SUBPROJECT.quality*.pdf $SUBPROJECT.length*.pdf $SUBPROJECT.position_quality*.pdf $SUBPROJECT.legend.pdf
fi

# access previous subproject ASVs
if [ $CLUST == "dada2" ] && [ "$PREV_PATH" != "no" ]
then
	cd $EXEC/processing
	for i in ${!PREV_PATH[@]}
	do
		PREV_ASV=${PREV_SUB[$i]}.all_repseq
		tar xzvf ${PREV_PATH[$i]}/${PREV_SUB[$i]}.outputs.tar.gz ${PREV_SUB[$i]}.outputs/${PREV_ASV}.fasta
		# cut previous ASVs to forward and reverse truncation length
		for j in fwd_rvs rvs_fwd
		do
			k=(${j/_/ })
			if [ -f ../quality_check/${FWD_NAME}.${k[0]}.optimized.quality.txt ]
			then
				OQUAL=($(cat ../quality_check/${FWD_NAME}.${k[0]}.optimized.quality.txt))
				seqkit subseq -w 0 -r 1:${OQUAL[0]} ${PREV_SUB[$i]}.outputs/${PREV_ASV}.fasta > ${PREV_SUB[$i]}.${FWD_NAME}.${k[0]}.fasta
				RQUAL=($(cat ../quality_check/${RVS_NAME}.${k[1]}.optimized.quality.txt))
				vsearch --quiet --fastx_revcomp ${PREV_SUB[$i]}.outputs/${PREV_ASV}.fasta --fastaout - | seqkit subseq -w 0 -r 1:${RQUAL[0]} > ${PREV_SUB[$i]}.${RVS_NAME}.${k[1]}.fasta
				unset OQUAL RQUAL
			fi
		done
	done
fi

# list files and directories
(. $BIN/list_step_files.sh)

echo END

