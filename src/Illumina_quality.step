# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Christina Wei√übecker, Anna Heintz-Buschart, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# load modules
module load DeltaMP/DELTAMP_VERSION

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
. $BIN/check_previous_step

# Demultiplex check
if [ $DEMULTI == "no" ]
then
	if [ -z $DUALID ]
	then
		. $BIN/check_${TECH}_barcodes.sh > archives/$SUBPROJECT.outputs/demultiplexing_check.tsv
	else
		cp libraries/fastq/demultiplexing_info.* archives/$SUBPROJECT.outputs/
	fi
fi

# Raw, primer detected [, filter], pair-end [, trim] read counts per library
if [ $TRUNCLEN == "no" ]
then
	TRIMSTEPS=(raw raw_with_primer pairend trim)
	if [ $QFILT == "average" ]
	then
		HEADER=$(echo "Sample\tLibrary\tRaw\tPrimer detected\tPair-end\t$(seq -s "#" $MINQUAL 30 | sed 's/\([0-9\.]*\)/Trimmed at \1 Phred score/g')" | sed 's/#/\\t/g')
	elif [ $QFILT == "maxee" ]
	then
		HEADER=$(echo "Sample\tLibrary\tRaw\tPrimer detected\tPair-end\t$(seq -s "#" $MAXEE -$EESTEP 0.5 | sed 's/\([0-9\.]*\)/Trimmed at \1 maxEE/g')" | sed 's/#/\\t/g')
	fi
else
	TRIMSTEPS=(raw raw_with_primer truncated pairend)
	HEADER="Sample\tLibrary\tRaw\tPrimer detected\tMinimal length and quality truncation\tPair-end"
fi
while read samp fwd rvs
do
	lib=$(echo $fwd $rvs | sed 's/\(.*\)[^ ]* \1.*$/\1/')
	if [ $CLIPPING == "no" ]
	then
		if [ $PALG == "vsearch" ]
		then
			RAW_COUNT=$(awk '$2=="Pairs"{print $1;exit}' libraries/fastq/log.pairend.${FWD_NAME}.$lib.txt)
		else
			RAW_COUNT=$(tac libraries/fastq/log.pairend.${FWD_NAME}.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4)
		fi
	else
		RAW_COUNT=$(grep -m 1 "^Total read pairs processed" libraries/fastq/log.cutadapt.$lib.fr.txt | awk '{print $NF}' | sed 's/,//g')
	fi
	for i in ${FWD_NAME} ${RVS_NAME}
	do
		if [ $i == "$FWD_NAME" ] ; then j=${RVS_NAME} ; else j=${FWD_NAME} ; fi
		if [ -f libraries/fastq/$i.$j.$lib.pairend.fastq.$EXT ]
		then
			if [ $TRUNCLEN == "no" ]
			then
				if [ $PALG == "vsearch" ]
				then
					paste <(awk '$2=="Pairs"{print $1;exit}' libraries/fastq/log.pairend.$i.$lib.txt) <(awk '$2=="Merged"{print $1;exit}' libraries/fastq/log.pairend.$i.$lib.txt) quality_check/$i.$j.$lib.stat
				else
					paste <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4) <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tOK\t" | cut -f 4) quality_check/$i.$j.$lib.stat
				fi
			else
				PRIMER_COUNT=$(awk '{sum+=$2}END{print sum}' libraries/raw_stat/$i.$lib.fwd.length)
				if [ $PALG == "vsearch" ]
				then
					paste <(echo -e "$PRIMER_COUNT") <(awk '$2=="Pairs"{print $1;exit}' libraries/fastq/log.pairend.$i.$lib.txt) <(awk '$2=="Merged"{print $1;exit}' libraries/fastq/log.pairend.$i.$lib.txt)
				else
					paste <(echo -e "$PRIMER_COUNT") <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tREADS" | cut -f 4) <(tac libraries/fastq/log.pairend.$i.$lib.txt | grep -m 1 -P "STAT\tOK\t" | cut -f 4)
				fi
			fi
		fi
	done | awk '{for(i=1;i<=NF;i++){s[i]+=$i}}END{for(i=1;i<=NF;i++){printf "\t%s", s[i]}}' | sed "s/^/$samp\t$lib\t${RAW_COUNT}/;s/$/\n/"
done < config/lib3.list | cat <(echo -e $HEADER) - > quality_check/$SUBPROJECT.lib_counts.tsv
cd quality_check

# per sample
sed '1d' $SUBPROJECT.lib_counts.tsv | sort -k 1,1 | awk 'BEGIN{FS="\t"}{if(NR==1){S=$1;for(i=3;i<=NF;i++){a[i]=$i};printf "%s",S} else {if($1==S){for(i=3;i<=NF;i++){a[i]+=$i}} else {S=$1;for(i=3;i<=NF;i++){printf "\t%s",a[i];a[i]=$i};printf "\n%s",S}}}END{for(i=3;i<=NF;i++){printf "\t%s",a[i]};printf "\n"}' | mimato | cat <(head -1 $SUBPROJECT.lib_counts.tsv | sed 's/\tLibrary\t/\t/') - > $SUBPROJECT.sample_counts.tsv

# Count check
for i in {2..4}
do
	head -n -4 $SUBPROJECT.sample_counts.tsv | awk -v I=$i -v M=$MIN_DEPTH 'NR>1{if(M<=1){if($(I+1)<M*$I) print $1,$(I+1),$(I+1)/$I} else if(M>1){if($(I+1)<M)print $1,$(I+1)}}' > min_depth.${TRIMSTEPS[$((i-1))]}.test
done
if (( $(echo "$MIN_DEPTH > 1" |bc -l) ))
then
	MIN_DEPTH_ECHO=$MIN_DEPTH
else
	MIN_DEPTH_ECHO="$MIN_DEPTH times the amount of \${TRIMSTEPS[\$((i-1))]}"
fi
SKIP_SAMP=$(awk -v S=$(sed -n '$=' $SUBPROJECT.sample_counts.tsv) -v T=$SKIP_TRESH 'BEGIN{M=(S-5)*T/100; printf "%.0f", int(M) }')
for i in $(seq 1 $((${#TRIMSTEPS[@]}-1)))
do
	if [ -s min_depth.${TRIMSTEPS[$i]}.test ]
	then
		echo "The following sample(s) do not have the requested minimum amount of ${TRIMSTEPS[$i]} reads fixed at "$(eval echo $MIN_DEPTH_ECHO)" reads:"
		echo "Sample Reads"
		cat min_depth.${TRIMSTEPS[$i]}.test
		echo ""
		# compare amount of samples to the skip threshod
		if [ $(cat min_depth.${TRIMSTEPS[$i]}.test | wc -l) -le $SKIP_SAMP ]
		then
			echo "However, $SKIP_SAMP samples are allowed to have their read count below the minimum threshold, so the qualtiy check continues."
			echo ""
		else
			if [ $SKIP_TRESH -gt 0 ]; then echo "This is more than the allowed amount of samples to be below the minimum threshold fixed at $SKIP_SAMP :"; fi
			echo "Aborting"
			awk 'BEGIN{FS=OFS="\t"};{print $1,$2,$3,$4,$5}' $SUBPROJECT.sample_counts.tsv > $SUBPROJECT.summary.stat.tsv
			ln -s $PWD/$SUBPROJECT.summary.stat.tsv $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.read_counts.tsv
			. $BIN/list_step_files.sh
			exit 100
		fi
	else
		eval echo "All samples have at least the minimum amount of ${TRIMSTEPS[$i]} reads fixed at $MIN_DEPTH_ECHO reads."
		echo ""
	fi
done

# Optimize quality
if [ $TRUNCLEN == "no" ]
then
	if [ $SKIP_TRESH -eq 100 ]
	then
		if [ $QFILT == "average" ] ; then echo $MINQUAL > optimized.quality.txt ; else echo $MAXEE > optimized.quality.txt ; fi
	elif (( $(echo "$MIN_DEPTH > 1" |bc -l) ))
	then
		# above integer threshold and more than 75% of raw reads
		head -n -4 $SUBPROJECT.sample_counts.tsv | transpose_tab | sed '1,4d;/^[ \t]*$/d' | tac | cat <(head -n -4 $SUBPROJECT.sample_counts.tsv | cut -f 5 | transpose_tab) - | awk -v M=$MIN_DEPTH -v S=$SKIP_SAMP 'BEGIN{FS="\t"} {if(NR==1){for(i=2;i<=NF;i++){ref[i]=$i}} ; C=0 ;for(i=2;i<=NF;i++){if($i<M || $i<ref[i]*0.75){C+=1}};if(C<=S){print $1;exit}}' | sed 's/Trimmed at //;s/ Phred score//;s/ maxEE//' > optimized.quality.txt
	else
		# above ratio of pair-end reads
		head -n -4 $SUBPROJECT.sample_counts.tsv | cut -f 5- | paste - <(head -n -4 $SUBPROJECT.sample_counts.tsv | cut -f 4) | transpose_tab | tac | awk -v M=$MIN_DEPTH -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for (i=2;i<=NF;i++){R[i]=$i}} ; C=0 ; for(i=2;i<=NF;i++){if($i<R[i]*M){C+=1}};if(C<=S){print $1;exit}}' | sed 's/Trimmed at //;s/ Phred score//;s/ maxEE//' > optimized.quality.txt
	fi
	QUAL=`cat optimized.quality.txt`
	if [ $QFILT == "average" ]
	then
		echo "Minimum average quality optimized to $QUAL"
		QUALPOS=$(($QUAL - $MINQUAL + 5))
	elif [ $QFILT == "maxee" ]
	then
		echo "Maximum expected error optimized to $QUAL"
		QUALPOS=$(printf %.0f $(echo "($MAXEE - $QUAL) * (1 / $EESTEP) + 5" | bc))
	fi
	cut -f 1-4,$QUALPOS $SUBPROJECT.sample_counts.tsv > $SUBPROJECT.summary.stat.tsv
	ln -s $PWD/$SUBPROJECT.summary.stat.tsv $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.read_counts.tsv
else
	for i in ${FWD_NAME} ${RVS_NAME}
	do
		if [ $i == "$FWD_NAME" ] ; then j=${RVS_NAME} ; else j=${FWD_NAME} ; fi
		if [ ! -z "$(find ../libraries/fastq -name $i.$j.*.pairend.fastq.$EXT)" ]
		then
			# initialize
			MAXLF=$(for x in ../libraries/raw_stat/$i.*.fwd.length ; do awk 'END{print $1}' $x ; done | sort -n | head -1)
			MAXLR=$(for x in ../libraries/raw_stat/$j.*.rvs.length ; do awk 'END{print $1}' $x ; done | sort -n | head -1)
			parallel -k echo ::: $(seq $TRUNCLEN $LENSTEP $MAXLF) ::: $(seq 0.5 $EESTEP $MAXEE) | awk -v EE=$MAXEE -v ES=$EESTEP -v L=$TRUNCLEN -v LS=$LENSTEP '{print $1,$2,($1-L+LS)/LS*((EE-$2+ES)/ES)^2}' > $i.fwd.stat
			parallel -k echo ::: $(seq $TRUNCLEN $LENSTEP $MAXLR) ::: $(seq 0.5 $EESTEP $MAXEE) | awk -v EE=$MAXEE -v ES=$EESTEP -v L=$TRUNCLEN -v LS=$LENSTEP '{print $1,$2,($1-L+LS)/LS*((EE-$2+ES)/ES)^2}' > $j.rvs.stat
			# optimize combination of length and maxEE
			while read samp fwd rvs
			do
				sort -k 1,1 $i.$fwd.eestat | join -t $'\t' -a 2 - <(seq $TRUNCLEN $LENSTEP $MAXLF | sort) | sort -k 1,1n | awk -v EE=$MAXEE -v ES=$EESTEP 'BEGIN{L=EE/ES;FS="\t"}{for(i=2;i<=L+1;i++){if(NF==1){print "0 0"}else{print $i}}}' | paste $i.fwd.stat - > $i.fwd.temp && mv $i.fwd.temp $i.fwd.stat
				sort -k 1,1 $j.$rvs.eestat | join -t $'\t' -a 2 - <(seq $TRUNCLEN $LENSTEP $MAXLR | sort) | sort -k 1,1n | awk -v EE=$MAXEE -v ES=$EESTEP 'BEGIN{L=EE/ES;FS="\t"}{for(i=2;i<=L+1;i++){if(NF==1){print "0 0"}else{print $i}}}' | paste $j.rvs.stat - > $j.rvs.temp && mv $j.rvs.temp $j.rvs.stat
			done < ../config/lib3.list
			# initial count for this direction and total count for each sample
			parallel --colsep "\t" -k "lib=\$(echo {2} {3} | sed 's/\(.*\)[^ ]* \1.*\$/\1/') ; awk '{sum+=\$2}END{print sum}' ../libraries/raw_stat/$i.\$lib.fwd.length" :::: ../config/lib3.list | paste -d " " - <(head -n -4 $SUBPROJECT.sample_counts.tsv | sed '1d' | cut -f 3) | tr "\n" "\t" | sed 's/^/primer removed\t/;s/\t$/\n/' > $i.$j.ref_count
			# First on reverse reads, then, for the same maxEE, length optimzation for forward reads
			sort -k 3,3nr -k 2,2n $j.rvs.stat | cat $i.$j.ref_count - | awk -v M=$MIN_DEPTH -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $j.rvs.optimized.quality.txt
			awk -v EE=$(cut -d " " -f 2 $j.rvs.optimized.quality.txt) '$2==EE{print}' $i.fwd.stat | sort -k 1,1nr | cat $i.$j.ref_count - | awk -v M=$MIN_DEPTH -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $i.fwd.optimized.quality.txt
			# the otherway around if it does not work
			if [ ! -s $i.fwd.optimized.quality.txt ]
			then
				sort -k 3,3nr -k 2,2n $i.fwd.stat | cat $i.$j.ref_count - | awk -v M=$MIN_DEPTH -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $i.fwd.optimized.quality.txt
				awk -v EE=$(cut -d " " -f 2 $i.fwd.optimized.quality.txt) '$2==EE{print}' $j.rvs.stat | cat $i.$j.ref_count - | sort -k 1,1nr | awk -v M=$MIN_DEPTH -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $j.rvs.optimized.quality.txt
				# with different maxEE if it is still not working
				if [ ! -s $j.rvs.optimized.quality.txt ]
				then
					sort -k 3,3nr -k 2,2n $j.rvs.stat | cat $i.$j.ref_count - | awk -v M=$MIN_DEPTH -v S=$SKIP_SAMP 'BEGIN{FS="\t"}{if(NR==1){for(i=2;i<=NF;i++){split($i,a," ");if(M<=1){R[i]=M*a[1]} else{R[i]=M*(a[1]/a[2])}}} else {C=0;for(i=2;i<=NF;i++){split($i,s," ");if(s[1]<R[i]){C+=1}};if(C<=S){split($1,a," ");print a[1],a[2];exit}}}' > $j.rvs.optimized.quality.txt
				fi
			fi
			cat <(grep "$(cat $i.fwd.optimized.quality.txt)" $i.fwd.stat) <(grep "$(cat $j.rvs.optimized.quality.txt)" $j.rvs.stat) | cut -f 2- | sed 's/ [0-9\.]*//g' | transpose_tab | awk '{if($1>$2){print $2} else print $1}' > $i.$j.trunc.nb
			rm $i.fwd.stat $j.rvs.stat $i.$j.ref_count
			echo "Truncation length and maximum expected error for $i orientated forward reads to $(cat $i.fwd.optimized.quality.txt | sed 's/ / and /')"
			echo "Truncation length and maximum expected error for $j orientated reverse reads to $(cat $j.rvs.optimized.quality.txt | sed 's/ / and /')"
		fi
	done
	paste *trunc.nb | awk '{s=$1;if(NF==2){s+=$2};print NR,s}' | mimato | awk 'BEGIN{print "Optimized truncation estimates"}{print $2}' | paste $SUBPROJECT.sample_counts.tsv - > $SUBPROJECT.summary.stat.tsv
	ln -s $PWD/$SUBPROJECT.summary.stat.tsv $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.read_counts.tsv
	rm *trunc.nb
fi

# Merge raw stat statistics
cd $EXEC/libraries/raw_stat
if [ $DEMULTI == "no" ] || [ $PERRUN == "yes" ]
then
	if [ $PERRUN == "yes" ]
	then
		LIB_NAME=($(cut -f 3 $EXEC/config/librun.list | sort -u))
	else
		LIB_NAME=($(cut -f 1 $EXEC/config/lib2.list))
	fi
	for i in ${LIB_NAME[@]}
	do
		Rscript --vanilla $BIN/Rscript_raw_stat_figures_Illumina.R $SUBPROJECT $BIN DeltaMP_${VERSION[DELTAMP]} $i $FWD_NAME $RVS_NAME $TRUNCLEN
		gs -q -sDEVICE=pdfwrite -o $i.raw_and_pair-end_reads_statistics.pdf $SUBPROJECT.$i.quality.*.pdf $SUBPROJECT.$i.length.*.pdf $SUBPROJECT.$i.position_quality.*.pdf $SUBPROJECT.$i.legend.pdf
		rm $SUBPROJECT.$i.quality.*.pdf $SUBPROJECT.$i.length.*.pdf $SUBPROJECT.$i.position_quality.*.pdf $SUBPROJECT.$i.legend.pdf
	done
	gs -q -sDEVICE=pdfwrite -o $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.raw_and_pair-end_reads_statistics.pdf *.raw_and_pair-end_reads_statistics.pdf
	rm *.raw_and_pair-end_reads_statistics.pdf
else
	Rscript --vanilla $BIN/Rscript_raw_stat_figures_Illumina.R $SUBPROJECT $BIN DeltaMP_${VERSION[DELTAMP]} all $FWD_NAME $RVS_NAME $TRUNCLEN
	gs -q -sDEVICE=pdfwrite -o $EXEC/archives/$SUBPROJECT.outputs/$SUBPROJECT.raw_and_pair-end_reads_statistics.pdf $SUBPROJECT.quality*.pdf $SUBPROJECT.length*.pdf $SUBPROJECT.position_quality*.pdf $SUBPROJECT.legend.pdf
fi

# list files and directories
. $BIN/list_step_files.sh

echo END

