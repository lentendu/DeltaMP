#!/bin/bash

# author: Guillaume Lentendu (guillaume.lentendu@unine.ch)

# Usage info
show_help() {
cat << EOF

NAME
	DeltaMP version ${VERSION[DELTAMP]} - a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
	
SYNOPSIS
	Usage: ${0##*/} [-a account_or_project_name] [-cdfhnqtx] [-m max_running_tasks] [-p reference_subproject] [-r step] configuration_file

DESCRIPTION
	-h	display this help and exit
	
	-a ACCOUNT
		account or project name for the job queuing system
	
	-c	check dry run (-d option) by preserving the SUBPROJECT and PROJECT directories in the output directory
		
	-d	dry run avoid any submission to the queuing system and only output submission informations
	
	-f	display default values for optional configuration parameters
		
	-n	avoid checkpointing (i.e. searching for previous SUBPROJECT) and run the pipeline from the beginning
	
	-m max_running_tasks
		fix a maximum number of concurrently running tasks per array jobs, default is 400
		
	-p SUBRPOJECT
		only execute additional jobs or with different input variables compared to the reference SUBPROJECT. This will only work if both configuration files have the same input libraries and output directory.
		
	-q	proceed until quality step only
	
	-r STEP
		restart pipeline computation from STEP. Replace STEP by 'list' to list all available steps of the subproject associated with the provided configuration file.
		
	-t	proceed until demultiplexing step only
	
	-x	delete the subproject associated with the provided configuration file

AUTHOR
	Guillaume Lentendu, Christina Weißbecker, Anna Heintz-Buschart and Tesfaye Wubet

REPORTING BUGS
	Submit suggestions and bug-reports at <https://github.com/lentendu/issues>, send a pull request on <https://github.com/lentendu>, or compose an e-mail to Guillaume Lentendu <guillaume.lentendu@unine.ch>.
	
COPYRIGHT
	Copyright (C) 2018 Guillaume Lentendu, Christina Weißbecker, Anna Heintz-Buschart and Tesfaye Wubet

	This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
	 
	This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
	 
	You should have received a copy of the GNU General Public License along with this program. If not, see <http://www.gnu.org/licenses/>.

EOF
}

show_doc() {
cat << EOF

# Refer to the manual at $DELTAMP_BUILD/README and be sure to use the correct configuration file format.
# Template configuration files can be found at $DELTAMP_BUILD/test/configuration_test_${TARG}_$TECH.tsv

# Aborting
EOF
}

show_default() {
echo ""
echo "## Configuration default values ##"
for i in `ls -v $BIN/variables_definition*`
do
	if [ ${i##*_} != "definition.tsv" ]
	then
		echo ${i##*_} | sed 's/\(.*\)\.tsv$/## \1 specific ##/'
	fi
	grep -v "#" $i | awk 'BEGIN{FS="\t"} {print $3"\t"$2}' | column -t -s $'\t'
	echo ""
done | sed '1d;$d'
echo ""
}

error_help(){
	echo "#Error: $1"
	show_help | fmt -s -w $(tput cols)
	rm -f /tmp/amp.$STIME.set
	exit 1
} >&2

error_doc(){
	echo -e "#Error: $1"
	show_doc | fmt -s -w $(tput cols)
	rm -f /tmp/amp.$STIME.set
	exit 1
} >&2

# record all variables set
STIME=`date +%s`
(set -o posix; set > /tmp/amp.$STIME.set)
START_TIME=`date +%s`
INIT_DIR=$PWD

# Version
declare -A VERSION
VERSION[DELTAMP]=
DELTAMP_BUILD=
DELTAMP_VER=deltamp${VERSION[DELTAMP]//./}
DELTAMP_COMMIT=
BIN=$DELTAMP_BUILD/bin
eval $(sed -n '/^BATCH_QUE/{s/\t/=/;p}' $DELTAMP_BUILD/config.txt)

# Option's default value
ARGUMENTS="$@"
CLEAN=yes
DRY=no
MAX_TASK=400
CHECKP=yes
REF_SUBPROJECT=no
QUAL_ONLY=no
RESTART=no
DEMULTI_ONLY=no
DELETE=no

# get options
while getopts ":a:cdfhm:np:qr:tx" opt
do
	case $opt in
		h)	show_help | fmt -s -w $(tput cols)
			rm -f /tmp/amp.$STIME.set
			exit 0;;
		a)	DELTAMP_ACCOUNT=${OPTARG};;
		c)	CLEAN=no;;
		d)	DRY=yes;;
		f)	show_default | fmt -s -w $(tput cols)
			rm -f /tmp/amp.$STIME.set
			exit 0;;
		m)	[[ ${OPTARG} =~ ^[0-9]+$ ]] || error_help " ${OPTARG} is not an integer"
			MAX_TASK=${OPTARG};;
		n)	CHECKP=no;;
		p)	[[ -d ${OPTARG} ]] || error_help "Directory ${OPTARG} does not exist"
			[[ -w ${OPTARG} ]] || error_help "Directory ${OPTARG} is not writable"
			REF_SUBPROJECT=${OPTARG};;
		q)	QUAL_ONLY=yes;;
		r)	RESTART=${OPTARG};;
		t)	DEMULTI_ONLY=yes;;
		x)	DELETE=yes;;
		\?)	error_help "# Invalid option: -${OPTARG}"
			;;
		:)	error_help "# Option -${OPTARG} requires an argument."
			;;
	esac
done
shift "$((OPTIND-1))" # Shift off the options and optional --.

if [ -z "$1" ]
then 
	error_help "the configuration file is missing." 1 
else
	METAD=`readlink -f $1` ; shift
fi

# set general variables from configuration file
while IFS=$'\t' read var std def acc
do
	unset $var
	val=`grep "$def" $METAD | cut -f 2- | sed 's/[ \t]*$//'`
	if [ -z "$val" ]
	then
		if [ $std == "#" ]
		then
			error_doc " in the configuration file, the parameter '$def' is missing and is compulsory."
		else
			declare $var="$std"
		fi
	elif [ "$std" != "#" ]
	then
		flag=1
		for i in $acc
		do
			if [[ $val =~ $i ]]
			then
				flag=0
			fi
		done
		if [ $flag -eq 0 ]
		then
			if [ -z "`echo "$val" | sed -n '/\t/p'`" ]
			then
				declare $var="$val"
			else
				IFS=$'\t' read -r -a $var <<< "$val"
			fi
		else
			error_doc "in the configuration file, the value of parameter '$def' is not accepted (currently set to $val).\nThe accepted values $(if [[ $acc == *"^"* ]] ; then echo 'should match the regex(s)' ; else echo 'are' ; fi): $acc (default value is $std)."
		fi		
	else
		declare $var="$val"
	fi
done < $BIN/variables_definition.tsv

# set plateform specific variables from configuration file
while IFS=$'\t' read var std def acc
do
	unset $var
	val=`grep "$def" $METAD | awk 'BEGIN{FS="\t"}{print $2}'`
	if [ -z "$val" ]
	then
		declare $var="$std"
	else
		flag=0
		for i in $acc
		do
			if [[ $val =~ $i ]]
			then
				flag=1
			fi
		done
		if [ $flag -eq 1 ]
		then
			declare $var="$val"
		else
			error_doc "in the configuration file, the value of parameter '$def' is not accepted (currently set to $val).\nThe accepted values $(if [[ $acc == *"^"* ]] ; then echo 'should match the regex(s)' ; else echo 'are' ; fi): $acc (default value is $std)."
		fi
	fi
done < $BIN/variables_definition_$TECH.tsv

# check output and execution directories
if [ ! -d $OUT_PATH ]
then
	error_doc "the output directory $OUT_PATH does not exist."
	if [ ! -w $OUT_PATH ]
	then
		error_doc "the output directory $OUT_PATH is not writable."
	fi
fi
if [ ! -d $EXEC_PATH ]
then
	error_doc "the execution directory $EXEC_PATH does not exist."
	if [ ! -w $OUT_PATH ]
	then
		error_doc "the execution directory $EXEC_PATH is not writable."
	fi
fi

# switch to special options
if [ $DELETE == "yes" ]
then
	OPTION_OUT=$(. $BIN/delete_subproject)
	OPTION_EC=$?
elif [ $RESTART != "no" ]
then
	OPTION_OUT=$(. $BIN/restart_from_step)
	OPTION_EC=$?
fi
if [ $DELETE == "yes" ] || [ $RESTART != "no" ]
then
	if [ $OPTION_EC -eq 0 ]
	then
		echo -e "$OPTION_OUT" >&2
		rm -f /tmp/amp.$STIME.set
		exit 0
	elif [ $OPTION_EC -eq 1 ]
	then
		error_doc "$OPTION_OUT"
	elif [ $OPTION_EC -eq 2 ]
	then
		echo -e "$OPTION_OUT" | sed 's/@/ /g' >&2
		rm -f /tmp/amp.$STIME.set
		exit 0
	fi
fi

# check configuration consistency
if [ $TECH == "454" ]
then
	RAW_EXT=sff
	ASV=no
	if [ $SEQ_DIR == "forward" ]
	then
		FLIP=false
	elif [ $SEQ_DIR == "reverse" ]
	then
		FLIP=true
		read FWD RVS <<<"$RVS $FWD"
		read FWD_NAME RVS_NAME <<<"$RVS_NAME $FWD_NAME"
	elif [ $SEQ_DIR == "both" ]
	then
		if [ $DENOISE == "yes" ]
		then
			error_doc "cannot denoise for sequencing in both directions"
		fi
		FLIP=false
	else
		error_doc "sequencing direction should be either forward, reverse or both, not ${SEQ_DIR}."
	fi
	if [ $QFILT == "maxee" ]
	then
		error_doc "maximum expected error filtering is not implemented for 454 reads"
	fi
elif [ $TECH == "Illumina" ]
then
	RAW_EXT=fastq
	ASV=no
	PERRUN=no
	if [ $CLUST == "dada2" ]
	then
		ASV=yes
		if [ $DEMULTI == "no" ] || [ $ONERUN == "yes" ]
		then
			PERRUN=yes
		fi
		if [ $TRUNCLEN == "no" ]
		then
			error_doc "dada2 require length truncation, provide a length to the parameter: 'Minimum length truncation of unpaired reads' "
		elif [ $ASSIGN_ALL == "yes" ]
		then
			error_doc "cannot assign all reads with dada2, only ASV are available for assignment, turn the 'Assign all reads' option to no or change clustering algorithm "
		fi
	fi
	if ([ $CLUST == "dada2" ] || [ $CLUST == "swarm" ]) && [ $MAXAMBIG -gt 0 ]
	then
		error_doc "$CLUST cannot process reads with ambiguous bases, so set 'Maximum number of ambiguities allowed in the sequence' to 0 "
	fi
	if [ $QFILT == "average" ] && [ $TRUNCLEN != "no" ]
	then
		error_doc "length of unpaired reads cannot be truncated when using the average quality filtering method, use maxee instead or set 'Minimum length truncation of unpaired reads' to no "
	fi
	if [ $TRUNCLEN != "no" ] && [ $TRUNCBE == "no" ]
	then
		error_doc "a 'Minimum length truncation of unpaired reads' can only be used if 'Truncation before pair-end' is set to yes "
	fi
	if [ $TRUNCLEN == "no" ] && [ $MAXTRUNCLEN != "no" ]
	then
		error_doc "first set a 'Minimum length truncation of unpaired reads' to be able to use the 'Maximum length truncation of unpaired reads' option "
	fi
	if [ $UNPAIR == "yes" ] && ( [ $TRUNCBE == "no" ] || [ $TRUNCLEN == "no" ] || [ $MAXTRUNCLEN == "no" ] )
	then
		error_doc "When the 'Avoid pair-end' option is turn to yes, 'Truncation before pair-end' need to be turn to yes and 'Minimum length truncation of unpaired reads' and 'Maximum length truncation of unpaired reads' need to be set to a real number " 
	fi
	if [ $UNPAIR == "yes" ] && [ $CLUST != "swarm" ] && [ $CLUST != "dada2" ]
	then
		error_doc "When the 'Avoid pair-end' option is turn to yes, 'Clustering algorithm' can only be set to 'dada2' or 'swarm'"
	fi
	if [ $UNPAIR == "yes" ] && [ $CLASSIF != "vsearch" ]
	then
		error_doc "When the 'Avoid pair-end' option is turn to yes, the 'Taxonomic classifier' can only be set to 'vsearch'"
	fi
	if [ $PREVQ != "no" ]
	then
		if [ ! -d "$PREVQ" ]
		then
			error_doc "The directory provided to reuse previous subproject optimized quality parameters was not found"
		elif [ "$(ls -1 $PREVQ/quality_check/*optimized.quality.txt 2> /dev/null | wc -l)" -eq 0 ]
		then
			error_doc "No optimized quality parameter files found in $PREVQ/quality_check/. Check log files of the Illumina_quality step."
		fi
		PREVFWD_NAME=$(sed -nr 's/^FWD_NAME (.*)$/\1/p' $PREVQ/config/env.txt)
		PREVRVS_NAME=$(sed -nr 's/^RVS_NAME (.*)$/\1/p' $PREVQ/config/env.txt)
		PREVTRUNCBE=$(sed -nr 's/^TRUNCBE (.*)$/\1/p' $PREVQ/config/env.txt)
		PREVQFILT=$(sed -nr 's/^QFILT (.*)$/\1/p' $PREVQ/config/env.txt)
		PREVTRUNCLEN=$(sed -nr 's/^TRUNCLEN (.*)$/\1/p' $PREVQ/config/env.txt)
		if [ $PREVFWD_NAME != $FWD_NAME ] || [ $PREVRVS_NAME != $RVS_NAME ]
		then
			error_doc "The previous subproject provided to reuse optimized quality parameters have different primers (Forward primer name : $PREVFWD_NAME , Reverse primer name : $PREVRVS_NAME )"
		elif [ $PREVTRUNCBE != $TRUNCBE ] || [ $PREVQFILT != $QFILT ] || [ "$PREVTRUNCLEN" != "$TRUNCLEN" ]
		then
			error_doc "The previous subproject provided to reuse optimized quality parameters have different quality filtration options (Type of quality filtering: $PREVQFILT , Truncation before pair-end : $PREVTRUNCBE , Minimum length truncation of unpaired reads : $PREVTRUNCLEN )"
		fi
	fi
fi

# Databases
declare -A CITATION FULLCITATION
if [ $TARG == "ITS" ]
then
	if [ $CUT_DB == "yes" ]
	then
		if [ $ITSX == "no" ]
		then
			error_doc "no ITS region was provided to cut the database."
		else
			DBCUT=$DB.$ITSX
		fi
	fi
	if [ $ASSIGN_FUNCT == "yes" ]
	then
		CITATION[FUN]="Nguyen et al., 2016"
		FULLCITATION[FUN]="Nguyen, N. H., Song, Z., Bates, S. T., Branco, S., Tedersoo, L., Menke, J., … Kennedy, P. G. (2016). FUNGuild: An open annotation tool for parsing fungal community datasets by ecological guild. Fungal Ecology, 20, 241–248."
		VERSION[FUN]=1.1
	fi
elif [ $TARG == "18S" ] || [ $TARG == "16S" ] || [ $TARG == "28S" ] || [ $TARG == "COI" ] || [ $TARG == "rbcl" ]
then
	if [ $CUT_DB == "yes" ]
	then
		if [ $TECH == "454" ] && [ $FLIP == "true" ]
		then
			DBCUT=$RVS_NAME.$FWD_NAME.$DB
		else
			DBCUT=$FWD_NAME.$RVS_NAME.$DB
		fi
	fi
	if [ -f $DBFOLD/$DB.align ]
	then
		DBALIGN=$DB.align
		if [ $CUT_DB == "yes" ]
		then
			DBCHOP=$DBCUT.align
		fi
	fi
fi

if [ ! -f $DBFOLD/$DBCUT.fasta ]
then
	error_cut=", neither the cutted version of the database ($DBCUT.fasta)"
fi

if [ $CLASSIF == "bayesian" ]
then
	if [ ! -f $DBFOLD/$DB.fasta ] && [ ! -f $DBFOLD/$DBCUT.fasta ]
	then
		if [ ! -f $DBFOLD/$DB.txt ]
		then
			error_doc "the database description file $DB.txt is present in the database directory ${DBFOLD}, but not the database sequence files ($DB.fasta)${error_cut}."
		else
			error_doc "the database files ($DB.txt, $DB.fasta) were not found in the database directory ${DBFOLD}${error_cut}."
		fi
	fi
elif [ $CLASSIF == "vsearch" ]
then
	if [ ! -f $DBFOLD/$DB.udb ] && [ ! -f $DBFOLD/$DBCUT.udb ]
	then
		if [ -f $DBFOLD/$DB.txt ]
		then
			error_doc "the database description file $DB.txt is present in the database directory ${DBFOLD},\nbut not the database sequence files ($DB.udb)${error_cut}."
		else
			error_doc "the database files ($DB.txt, $DB.udb) were not found in the database directory ${DBFOLD}${error_cut}."
		fi
	fi
fi
eval $(sed 's/[\t ][\t ]*/[DB]=\"/;s/$/\"/' $DBFOLD/$DB.txt)

# Chimera
if [ $CHIMERA == "before" ] || [ $CHIMERA == "both" ]
then
	CHIMERA1="yes"
else
	CHIMERA1="no"
fi
if [ $CHIMERA == "after" ] || [ $CHIMERA == "both" ]
then
	CHIMERA2="yes"
else
	CHIMERA2="no"
fi

# Pre-clustering
if [ $CLUST == "swarm" ]
then
	if [ $PRECLUST != "no" ]
	then
		error_doc "pre-clustering is not allowed for swarm based OTU clustering.\nIn the configuration file, turn off the 'Pre-clustering' argument with 'no' or use another clustering algorithm."
	elif [ $MAXAMBIG -gt 0 ]
	then
		error_doc "swarm clustering do not allow ambiguous nucleotide.\nIn the configuration file, set 'Maximum number of ambiguities allowed in the sequence' to 0 or use another clustering algorithm."
	fi
fi

if [ $PRECLUST == "mothur" ]
then
	if [ ! -f $DBFOLD/$DBCHOP.fasta ] && [ ! -f $DBFOLD/$DBALIGN.fasta ] 
	then
		error_doc "the mothur pre-clustering method could only be used if an aligned version of the reference database is available."
	fi
fi

if [ $PREV_PATH != "no" ]
then
	for i in ${!PREV_PATH[@]}; do PREV_SUB[$i]=${PREV_PATH[$i]##*/}; done
	for i in ${!PREV_PATH[@]}
	do
		if [ ! -d ${PREV_PATH[$i]} ]
		then
			error_doc "The path to the previous subproject output directory for reference clustering ${PREV_PATH[$i]} was not found."
		elif [ ! -f ${PREV_PATH[$i]}/${PREV_SUB[$i]}.processing.files.tar.gz ]
		then
			error_doc "There is no processing.files.tar.gz archive in the path to the previous subproject output directory for reference clustering."
		elif [ ! -f ${PREV_PATH[$i]}/${PREV_SUB[$i]}.outputs.tar.gz ]
		then
			error_doc "There is no outputs.tar.gz archive in the path to the previous subproject output directory for reference clustering."
		fi
	done
fi

# Dependencies
# modules
# gnu parallel
# coreutils
# ghostscript
# fontconfig
# R
# pigz

# Citations
	# VSEARCH
VERSION[VSEARCH]=`vsearch --version 2>&1 | sed -n '1s/vsearch v\([^_]*\)_.*$/\1/p'`
CITATION[VSEARCH]="Rognes et al., 2016"
FULLCITATION[VSEARCH]="Rognes, T., Flouri, T., Nichols, B., Quince, C., & Mahé, F. (2016). VSEARCH: a versatile open source tool for metagenomics (No. e2409v1). PeerJ Preprints. "
	
	# MOTHUR, UCHIME, classifier
CITATION[MOTHUR]="Schloss et al., 2009"
FULLCITATION[MOTHUR]="Schloss PD, Westcott SL, Ryabin T et al. (2009) Introducing mothur: Open-Source, Platform-Independent, Community-Supported Software for Describing and Comparing Microbial Communities. Applied and Environmental Microbiology, 75, 7537–7541."
VERSION[MOTHUR]=`mothur --version | grep version | cut -d "=" -f 2`
CITATION[UCHIME]="Edgar et al., 2011"
FULLCITATION[UCHIME]="Edgar RC, Haas BJ, Clemente JC, Quince C, Knight R (2011) UCHIME improves sensitivity and speed of chimera detection. Bioinformatics, 27, 2194–2200."
CITATION[TAXO]="Wang et al., 2007"
FULLCITATION[TAXO]="Wang Q, Garrity GM, Tiedje JM, Cole JR (2007) Naïve Bayesian Classifier for Rapid Assignment of rRNA Sequences into the New Bacterial Taxonomy. Applied and Environmental Microbiology, 73, 5261–5267."

	# ecoPCR
CITATION[ECO]="Ficetola et al. 2010"
FULLCITATION[ECO]="Ficetola GF, Coissac E, Zundel S et al. (2010) An in silico approach for the evaluation of DNA barcodes. Bmc Genomics, 11, 434."

	#BIOM format
CITATION[BIOM]="McDonald et al., 2012"
FULLCITATION[BIOM]="McDonald, D., Clemente, J. C., Kuczynski, J., Rideout, J. R., Stombaugh, J., Wendel, D., … others. (2012). The Biological Observation Matrix (BIOM) format or: how I learned to stop worrying and love the ome-ome. GigaScience, 1(1), 7."
VERSION[BIOM]=`biom --version | awk '{print $3}'`

	#ITSx
if [ $TARG == "ITS" ] && [ $ITSX != "no" ]
then
	CITATION[ITSX]="Bengtsson‐Palme Johan et al. 2013"
	FULLCITATION[ITSX]="Bengtsson‐Palme Johan, Ryberg Martin, Hartmann Martin, Branco Sara, Wang Zheng, Godhe Anna, … Bunce Michael. (2013). Improved software detection and extraction of ITS1 and ITS2 from ribosomal ITS sequences of fungi and other eukaryotes for analysis of environmental sequencing data. Methods in Ecology and Evolution, 4(10), 914–919. doi:10.1111/2041-210X.12073"
	VERSION[ITSX]=`ITSx --license 2>&1 | sed -n 's/^Version: //p'`
fi

if [ $TECH == "454" ]
then
	# 454 SOP
	CITATION[SOP]="Schloss et al., 2011"
	FULLCITATION[SOP]="Schloss PD, Gevers D, Westcott SL (2011) Reducing the Effects of PCR Amplification and Sequencing Artifacts on 16S rRNA-Based Studies. PLOS ONE, 6, e27310."
	# Denoising
	CITATION[DEN]="Gaspar et al., 2015"
	FULLCITATION[DEN]="Gaspar, J. M., & Thomas, W. K. (2015). FlowClus: efficiently filtering and denoising pyrosequenced amplicons. BMC Bioinformatics, 16(1). doi:10.1186/s12859-015-0532-1"
	VERSION[DEN]=`FlowClus -h 2>&1 | head -1 | grep -o "version [0-9]*.[0-9]*" | sed 's/version //'`
	CITATION[CUT]="Martin, 2011"
	FULLCITATION[CUT]="Martin, M. (2011). Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet.Journal, 17(1), 10–12."
	VERSION[CUT]=`cutadapt --version`
elif [ $TECH == "Illumina" ]
then
	# MiSeq SOP
	CITATION[SOP]="Kozich et al., 2013"
	FULLCITATION[SOP]="Kozich, J. J., Westcott, S. L., Baxter, N. T., Highlander, S. K., & Schloss, P. D. (2013). Development of a dual-index sequencing strategy and curation pipeline for analyzing amplicon sequence data on the MiSeq Illumina sequencing platform. Applied and Environmental Microbiology, AEM.01043-13. doi:10.1128/AEM.01043-13"
	# PANDAseq
	CITATION[PANDA]="Masella et al., 2012"
	FULLCITATION[PANDA]="Masella AP, Bartram AK, Truszkowski JM, Brown DG, Neufeld JD (2012) PANDAseq: paired-end assembler for illumina sequences. BMC Bioinformatics, 13, 31."
	VERSION[PANDA]=`pandaseq -v 2>&1 | awk '{print $2}'`
	# pre-clustering
	CITATION[PRECL]="Huse et al., 2010"
	FULLCITATION[PRECL]="Huse SM, Welch DM, Morrison HG, Sogin ML (2010) Ironing out the wrinkles in the rare biosphere through improved OTU clustering. Environmental Microbiology, 12, 1889–1898."
	# cd-hit-454
	CITATION[PRECDHIT]="Niu et al., 2010"
	FULLCITATION[PRECDHIT]="Niu B, Fu L, Sun S, Li W (2010) Artificial and natural duplicates in pyrosequencing reads of metagenomic data. BMC Bioinformatics, 11, 187."
	VERSION[PRECDHIT]=4.6.1
fi

	# Clustering algorithms
if [ $CLUST == "cd-hit-est" ]
then
	VERSION[CLUST]=4.6.1
	CITATION[CLUST]="Fu et al., 2012"
	FULLCITATION[CLUST]="Fu L, Niu B, Zhu Z, Wu S, Li W (2012) CD-HIT: accelerated for clustering the next-generation sequencing data. Bioinformatics, 28, 3150–3152."
elif [ $CLUST == "sumaclust" ]
then
	VERSION[CLUST]=`sumaclust -h 2>&1 | grep Version | awk '{print $3}'`
	CITATION[CLUST]="Mercier et al., 2013"
	FULLCITATION[CLUST]="Mercier C, Boyer F, Bonin A, Coissac É (2013) SUMATRA and SUMACLUST: fast and exact comparison and clustering of sequences. http://metabarcoding.org/sumatra"
elif [ $CLUST == "mcl" ]
then
	VERSION[CLUST]=`mcl --version | awk 'NR==1{print $2}'`
	CITATION[CLUST]="van Dongen, 2000"
	FULLCITATION[CLUST]="van Dongen S (2000) Graph Clustering by Flow Simulation. University of Utrecht. http://micans.org/mcl/"
elif [ $CLUST == "vsearch" ]
then
	VERSION[CLUST]=${VERSION[VSEARCH]}
	CITATION[CLUST]="${CITATION[VSEARCH]}"
	FULLCITATION[CLUST]="${FULLCITATION[VSEARCH]}"
	CITATION[CLUST2]="Edgar, 2013"
	FULLCITATION[CLUST2]="Edgar RC (2013) UPARSE: highly accurate OTU sequences from microbial amplicon reads. Nature Methods, 10, 996–998."
elif [ $CLUST == "swarm" ]
then
	VERSION[CLUST]=`swarm --version 2>&1 | awk 'NR==1{print $2}'`
	CITATION[CLUST]="Mahé et al., 2015"
	FULLCITATION[CLUST]="Mahé F, Rognes T, Quince C, Vargas C de, Dunthorn M (2015) Swarm v2: highly-scalable and high-resolution amplicon clustering. PeerJ, 3, e1420."
fi

	# QIIME for demultiplexing
CITATION[QIIME]="Caporaso et al., 2010"
FULLCITATION[QIIME]="Caporaso JG, Kuczynski J, Stombaugh J et al. (2010) QIIME allows analysis of high-throughput community sequencing data. Nature Methods, 7, 335–336."
VERSION[QIIME]=`pip show QIIME 2> /dev/null | grep Version | awk '{print $2}'`

# [Create and] dive to output PROJECT directory
if [ -d $OUT_PATH/$PROJECT ]
then
	cd $OUT_PATH/$PROJECT
else
	mkdir $OUT_PATH/$PROJECT && cd $OUT_PATH/$PROJECT
fi

# Create SUBPROJECT directory
HASH=`cat <(echo $START_TIME ${VERSION[DELTAMP]}) $METAD | cksum | awk '{print $1}'`
SUBPROJECT=`echo $PROJECT\_$TECH\_$TARG\_$HASH`
mkdir $SUBPROJECT
cd $SUBPROJECT
mkdir config
cp $METAD config/configuration.$SUBPROJECT.tsv && METADATA=configuration.$SUBPROJECT.tsv
OUT=$OUT_PATH/$PROJECT/$SUBPROJECT
EXEC=$EXEC_PATH/$SUBPROJECT

if [ $DEMULTI == "no" ]
then
	RAW_DIR=$EXEC/libraries/$RAW_EXT
else
	RAW_DIR=$EXEC/libraries
fi

# Store barcodes, libraries and sample lists into files
sed '1,/^Barcode sequence/d;/^$/d;s/^\t/barcode\t/' config/$METADATA > config/barcodes.txt
COMP_EXT=($(sed "s/.*${RAW_EXT}\([^ \t$]*\).*/\1/;s/\.//" config/barcodes.txt | sort -u))
if [ ${#COMP_EXT[@]} -gt 1 ] || [ ${#COMP_EXT[@]} -eq 0 ] || [[ "gz bz2" != *${COMP_EXT[0]}* ]]
then
	EXT=gz

else
	EXT=${COMP_EXT[0]}
fi
if [ $EXT == "gz" ]
then
	DECOMP="unpigz -p \$NCPUS -b 1024 -ck"
	COMP="pigz -p \$NCPUS -b 1024 -f"
elif [ $EXT == "bz2" ]
then
	DECOMP="bunzip2 -ck"
	COMP="bzip2 -f"
fi

# Libraries and samples lists
if [ $TECH == "454" ]
then
	# lib1 : original unique library full paths or filenames
	cut -f 3 config/barcodes.txt | sort -u > config/lib1.list
	# lib2 : unique library filenames
	sed 's/ftp\.sra.*\///' config/lib1.list > config/lib2.list
	# lib3 : samples and demultiplexed library filename prefix (one line per sample per library even if multiple barcodes, a sample could be in multiple libraries, i.e. repeated on multiple lines)
	if [ $DEMULTI == "no" ]
	then
		sed 's/\.'$RAW_EXT'[^\t$]*//g;s/ftp\.sra.*\///' config/barcodes.txt | awk '{print $2"\t"$2"."$3}' | sort -u | sort -k 1,1 -t $'\t' > config/lib3.list
	else
		if [ $(cut -f 2 config/barcodes.txt | sort -u | wc -l) -gt $(cut -f 3 config/barcodes.txt | sort -u | wc -l) ]
		then
			cd .. && rm -r $SUBPROJECT
			if [ ! "$(ls -A)" ] ; then cd .. && rmdir $PROJECT ; fi
			error_doc "there is more samples than libraries, it seems that the libraries are not demultiplexed\nSet 'Libraries already demultiplexed' to 'no' in the configuration file to allow deltamp execution."
		else
			sed 's/\.'$RAW_EXT'[^\t$]*//;s/ftp\.sra.*\///' config/barcodes.txt | awk '{print $2"\t"$3}' | sort -u | sort -k 1,1 -t $'\t' > config/lib3.list
		fi
	fi
	LIB3_SIZE=`sed -n '$=' config/lib3.list | sed 's/$/:10/'`
	# lib4 : one line per sample with all library prefixes as additionnal fields
	sort -k 1,1 config/lib3.list | awk '{if(NR==1){S=$1;printf "%s\t%s",S,$2} else {if($1==S){printf "\t%s",$2} else {S=$1;printf "\n%s\t%s",S,$2}}}END{printf "\n"}' > config/lib4.list
elif [ $TECH == "Illumina" ]
then
	# lib1 : original unique library full path or filename common prefix and R1 and R2 suffixes
	cut -f 3-4 config/barcodes.txt | sed 's/\(.*\)\([^\t]*\)\t\1\(.*\)$/\1\t\2\t\3/' | sort -u > config/lib1.list
	# lib2 : unique library filename common prefix and R1 and R2 suffixes
	sed 's/ftp\.sra[^\t]*\///g' config/lib1.list > config/lib2.list
	# lib3 : sample and demultiplexed library full filename for R1 and R2 without $RAW_EXT extension
	if [ $DEMULTI == "no" ]
	then
		sed 's/\.'$RAW_EXT'[^\t$]*//g;s/ftp\.sra[^\t]*\///g' config/barcodes.txt | awk '{print $2"\t"$2"."$3"\t"$2"."$4}' | sort -u | sort -k 1,1 -t $'\t' > config/lib3.list
		# control potential dual indexing
		if [ $(cut -f 1 config/barcodes.txt | grep -c "^[NATCG]*,[NATCG]*$") -gt 0 ]
		then
			if [ $(cut -f 1 config/barcodes.txt | grep -c "^[NATCG]*,[NATCG]*$") -eq $(sed -n '$=' config/barcodes.txt) ]
			then
				DUALID=yes
			else
				cd .. && rm -r $SUBPROJECT
				if [ ! "$(ls -A)" ] ; then cd .. && rmdir $PROJECT ; fi
				error_doc "not all samples have dual indexes in the barcode list. Demultiplexing does not support mixing of single and dual indexing."
			fi
		else
			if [ $BINDBP == "yes" ]
			then
				cd .. && rm -r $SUBPROJECT
				if [ ! "$(ls -A)" ] ; then cd .. && rmdir $PROJECT ; fi
				error_doc "the option 'Bind barcode to primer for demultiplexing' is set to 'yes' but no dual index was detectected in the barcode list."
			fi
		fi
	else
		if [ $(cut -f 2 config/barcodes.txt | sort -u | wc -l) -gt $(cut -f 3 config/barcodes.txt | sort -u | wc -l) ]
		then
			cd .. && rm -r $SUBPROJECT
			if [ ! "$(ls -A)" ] ; then cd .. && rmdir $PROJECT ; fi
			error_doc "there is more samples than libraries, it seems that the libraries are not demultiplexed\nSet 'Libraries already demultiplexed' to 'no' in the configuration file to allow deltamp execution."
		else
			sed 's/\.'$RAW_EXT'[^\t$]*//g;s/ftp\.sra[^\t]*\///g;s/^barcode\t//' config/barcodes.txt | sort -u | sort -k 1,1 -t $'\t' > config/lib3.list
		fi
	fi
	LIB3_SIZE=`sed -n '$=' config/lib3.list`
	# lib4 : sample and library filename common prefixes (multiple library allowed for one sample)
	sed 's/\t\(.*\)[^\t]*\t\1.*$/\t\1/' config/lib3.list | awk '{t[$1]=t[$1]"\t"$2}END{for(i in t){printf "%s%s\n",i,t[i]}}' | sort > config/lib4.list
	if [ $CLUST == "dada2" ]
	then
		awk 'BEGIN{FS=OFS="\t"}{for(i=2;i<=NF;i++){print $1,$i}}' config/lib4.list | sed -r 's/(.*)\t\1\.(.*)$/\1\t\1.\2\t\2/' | awk '{if(NF==2){exit} else print}' > config/librun.list
		if [ $PERRUN == "no" ] && [ -s config/librun.list ]
		then
			if [ $(sed -n '$=' config/librun.list) -eq $(sed -n '$=' config/lib4.list) ] && [ $(cut -f 3 config/librun.list | sort -u | sed -n '$=') -lt $(sed -n '$=' config/lib4.list) ]
			then
				PERRUN=yes
			else
				rm config/librun.list
			fi
		fi
		if [ $PERRUN == "yes" ]
		then
			if [ $ONERUN == "yes" ]
			then
				awk '{print $0"\tlibrary1"}' config/lib4.list > config/librun.list
			fi
			NBRUN=`cut -f 3 config/librun.list | sort -u | wc -l`
		fi
	fi
fi
LIB1_SIZE=`sed -n '$=' config/lib1.list`
SAMP_SIZE=`sed -n '$=' config/lib4.list`

# Save newly set variables to file (avoiding lowercase variables from loops):
join -v 1 <(set -o posix; set | tr "=" "\t" | sort -k 1,1 ) <(cat /tmp/amp.$STIME.set | tr "=" "\t" | sort -k 1,1 ) | grep -v "^[a-z]\|BASH_REMATCH" | sed "s/'//g" > config/env.txt
rm -f /tmp/amp.$STIME.set
(set -o posix; set > /tmp/amp.$STIME.set)

# Steps to queue (avoid archiving for already demultiplexed libraries)
if [ $DEMULTI_ONLY == "yes" ]
then
	. $BIN/pipeline_master | sed '/^raw_jobid/,${s/^/#/};/^#raw_arch/{s/^#//}' > config/steps
elif [ $QUAL_ONLY == "yes" ]
then
	if [ $DEMULTI == "no" ]
	then
		. $BIN/pipeline_master | sed '/^trim/,${s/^/#/};/^#output/,/^#raw_arch/{s/^#//}' > config/steps
	else
		. $BIN/pipeline_master | sed '/^trim/,${s/^/#/};/^#output/s/^#//' > config/steps
	fi
else
	if [ $DEMULTI == "no" ]
	then
		. $BIN/pipeline_master > config/steps
	else
		. $BIN/pipeline_master | sed '/^raw_arch/{s/^/#/}' > config/steps
	fi
fi

# avoid pair-end
if [ $TECH == "Illumina" ]
then
	if [ $UNPAIR == "yes" ]
	then
		sed -E -i 's/^(pair_end_)/#\1/' config/steps
	fi
fi

# cap number of CPUs for get step
MP_CPUS=$(awk '$1=="MAX_CPU_PER_NODES"{print $2}' $DELTAMP_BUILD/config.txt)
NB_ARCH=$(if [[ "${ARCHIVES[@]}" != "no" ]] ; then echo ${#ARCHIVES[@]} ; else sed -n '$=' config/lib1.list ; fi)
if [ $NB_ARCH -lt $MP_CPUS ]
then
	AR_CPUS=$(awk '$1=="MAX_ARRAY_CPU_PER_NODES"{print $2}' $DELTAMP_BUILD/config.txt)
	MP_MEM=$(awk '$1=="MAX_ARRAY_MEMORY_FOR_PARALLEL"{print $2}' $DELTAMP_BUILD/config.txt)
	SER_MEM=$(awk '$1=="MAX_MEMORY_FOR_SERIAL"{print $2}' $DELTAMP_BUILD/config.txt)
	if [ $NB_ARCH -lt $AR_CPUS ]
	then
		sed "/get_jobid=/s/QUEUE_SUB/QUEUE_SUB QUEUE_CPUS $AR_CPUS QUEUE_MEM${MP_MEM}G/" config/steps > config/steps.tmp && mv config/steps.tmp config/steps
	else
		sed "/get_jobid=/s/QUEUE_SUB/QUEUE_SUB QUEUE_CPUS $NB_ARCH QUEUE_MEM$(($SER_MEM*$NB_ARCH))G/" config/steps > config/steps.tmp && mv config/steps.tmp config/steps
	fi
	unset AR_CPUS MP_MEM SER_MEM
fi
unset MP_CPUS NB_ARCH

# Compare with previous (the one with less differences) or with the provided previous SUBPROJECT, and cut to avoid redo identical part(s)
cd ..
if [ $CHECKP == "yes" ]
then
	if [ $REF_SUBPROJECT == "no" ]
	then
		PREV_LIST=(`ls -dtr $PROJECT\_$TECH\_$TARG\_*/config | grep -v $SUBPROJECT | sed 's@/.*@@'`) # oldest first
	else
		PREV_LIST=$REF_SUBPROJECT
	fi

	if [ ! -z "$PREV_LIST" ]
	then
		unset TMP_SCRIPT TMP_DIF
		declare -A TMP_SCRIPT TMP_DIF BAR_DIF TMP_PREV PREV_EXEC
		for i in ${PREV_LIST[@]}
		do
			# check execution directory of previous subproject
			if [ -d $EXEC_PATH/$i ]
			then
				PREV_EXEC[$i]=1
			else
				PREV_EXEC[$i]=0
			fi
			# which environmental variable(s) differ between the two SUBPROJECTs
			TMP_DIF[$i]=$(join -t $'\t' -a 1 -a 2 <(sort -k 1,1 $i/config/env.txt | sed 's/ /\t/') <(sort -k 1,1 $SUBPROJECT/config/env.txt | sed 's/ /\t/') | grep -v "$HASH\|TIME\|CLEAN\|REF_SUBPROJECT\|CITATION\|VERSION\|ARGUMENTS\|DRY\|CHIMERA\|NBRUN " | awk -F'\t' '$2!=$3{printf "%s#",$1}' | sed 's/#$//')
			BAR_DIF[$i]=$(comm -3 <(sort $i/config/barcodes.txt) <(sort $SUBPROJECT/config/barcodes.txt) | head -1 | tr "\t" "#")
			if [ -z "${TMP_DIF[$i]}" ] && [ -z "${BAR_DIF[$i]}" ]
			then
				rm -r $SUBPROJECT
				error_doc "the previous subproject $i is identical.\nAt least one parameter need to differ with previous subproject to allow deltamp execution."
			elif [ ! -z "${BAR_DIF[$i]}" ]
			then
				rm -r $SUBPROJECT
				error_doc "the previous subproject $i have a different barcode and/or library list.\nTo avoid using $i as reference subproject, you can for example change the output directory (currently $OUT_PATH) in the configuration file."
			fi
			# in which step script(s) of the new SUBPROJECT are the differing variable(s) found first
			unset MATCH_STEP
			MATCH_STEP=$(for j in $(sed 's/^.* //;s/)$//' $SUBPROJECT/config/steps); do TMP=$(for VAR in $(echo ${TMP_DIF[$i]} | tr "#" " "); do REG="\\\$$VAR\$\\|\\\$$VAR[^A-Z_]" ; grep -m 1 -o "$REG" $j ; done) ; if [ ! -z "$TMP" ]; then basename $j | sed 's/\.sh//' && break ; fi ; done)
			if [ -z $MATCH_STEP ]
			then
				if [ ${TMP_DIF[$i]} == "QUAL_ONLY" ]
				then
					TMP_SCRIPT[$i]=trim
				else
					TMP_SCRIPT[$i]=$(sed '1d;s/ QUEUE_HOLD[^ ]*//;s/ /_/g' $SUBPROJECT/config/steps | nl | sort -k 2,2 | join -v 1 -1 2 - <(sed 's/ QUEUE_HOLD[^ ]*//;s/'$i'/'$SUBPROJECT'/g;s/ /_/g' $i/config/steps.final | sort) | sort -k 2,2n | head -1 | sed 's@.*/@@;s@\.sh.*$@@')
				fi
			else
				# exception for db_cut step, search for the second step with difference, which is not necessarilly the trim step
				if [ $MATCH_STEP == "cut_db" ] && ( [ $ASV == "yes" ] || [ $PRECLUST != "mothur" ] )
				then
					ADD_CUT_DB="cut_db and "
					unset MATCH_STEP
					MATCH_STEP=$(for j in $(sed 's/^.* //;s/)$//' $SUBPROJECT/config/steps | grep -v "/cut_db\.sh$"); do TMP=$(grep -o -m 1 $(echo ${TMP_DIF[$i]} | sed 's/#/[^A-Z_]\\\|$/g;s/^/$/;s/$/[^A-Z_]/') $j) ; if [ ! -z "$TMP" ]; then basename $j | sed 's/\.sh//' && break ; fi ; done)
					TMP_SCRIPT[$i]=$MATCH_STEP
				else
					TMP_SCRIPT[$i]=$MATCH_STEP
				fi
			fi
			# which was the last step executed before the differing step
			TMP_PREV[$i]=$(awk '$0!~"^#"{print $NF}' $i/config/steps.final | tac | grep -o -m 1 $(sed '/'"${TMP_SCRIPT[$i]}"'/,$d' $BIN/ref.steps.$TECH | tr "\n" " " | sed 's/ $/\n/;s/ /\\\|/g'))
		done
		# check if any subproject still have their execution directory or avoid checkpointing
		if [ $(echo ${PREV_EXEC[@]} | awk '{for(i=1;i<=NF;i++){s+=$i};print s}') -gt 0 ]
		then
			# the previous SUBPROJECT which has the most number of steps in common with the current SUBPROJECT is set as seed
			REF_SUBPROJECT=`for i in "${PREV_LIST[@]}"; do if [ ${PREV_EXEC[$i]} == 1 ] ; then sed -n '/'"${TMP_PREV[$i]}"'/=' $BIN/ref.steps.$TECH | paste <(echo $i) <(stat -c "%Y" $i) - ; fi ; done | sort -k 3,3nr -k 2,2nr | cut -f 1 | head -1`
			FIRST_STEP=${TMP_SCRIPT[$REF_SUBPROJECT]}
			LAST_REF=${TMP_PREV[$REF_SUBPROJECT]}
			# the steps to be queued are updated accordingly: start with init, jump till FIRST_STEP (or cut_db) and make it dependent on init step completion
			if [ -z "$ADD_CUT_DB" ]
			then
				sed "2,/${FIRST_STEP}\.sh)$/s/^/#/;/${FIRST_STEP}\.sh)$/s/^#//;/${FIRST_STEP}\.sh)$/s/QUEUE_HOLD[^ ]* /QUEUE_HOLD\${init_jobid} /" $SUBPROJECT/config/steps > $SUBPROJECT/config/steps.final
			else
				sed "2,/${FIRST_STEP}\.sh)$/s/^/#/;/^#cut_db_jobid=/{s/^#//;s/ \([^ ]*\)$/ QUEUE_HOLD\${init_jobid} \1/};/${FIRST_STEP}\.sh)$/{s/^#//;s/QUEUE_HOLD[^ ]* /QUEUE_HOLD\${cut_db_jobid} /}" $SUBPROJECT/config/steps > $SUBPROJECT/config/steps.final
			fi
			# hold on previous subproject last step if still in the queue
			LAST_REF_JOBID=$(grep ${DELTAMP_VER}.${LAST_REF}.${REF_SUBPROJECT} $EXEC_PATH/$REF_SUBPROJECT/config/jobid | awk '{print $1}')
			if [ ! -z "$(deltamp.queue | grep $LAST_REF_JOBID)" ]
			then
				sed "1 s/ \([^ ]*\)$/ QUEUE_HOLD${LAST_REF_JOBID} \1/" $SUBPROJECT/config/steps.final > $SUBPROJECT/config/steps.final.tmp && mv $SUBPROJECT/config/steps.final.tmp $SUBPROJECT/config/steps.final
			fi
			# Check archiving of raw reads in previous subproject
			if [ $DEMULTI == "no" ]
			then
				for i in "" -internal.md5 .md5
				do
					ln -s $OUT_PATH/$PROJECT/$REF_SUBPROJECT/$REF_SUBPROJECT.$RAW_EXT.tar.gz$i $OUT/$SUBPROJECT.$RAW_EXT.tar.gz$i
				done
				sed 's/^\(raw_archiver_jobid\)/#\1/' $SUBPROJECT/config/steps.final > $SUBPROJECT/config/steps.final.tmp && mv $SUBPROJECT/config/steps.final.tmp $SUBPROJECT/config/steps.final
			fi
		else
			# if no previous SUBPROJECT still have their execution directory, the init step is skipped
			sed '/^init_jobid/s/^/#/;/get.sh)$/s/ QUEUE_HOLD[^ ]* / /' $SUBPROJECT/config/steps > $SUBPROJECT/config/steps.final
		fi
	else
		# if there is no previous SUBPROJECT, the init step is skipped
		sed '/^init_jobid/s/^/#/;/get.sh)$/s/ QUEUE_HOLD[^ ]* / /' $SUBPROJECT/config/steps > $SUBPROJECT/config/steps.final
	fi
else
	# if checkpointing is not allowed, the init step is skipped
	sed '/^init_jobid/s/^/#/;/get.sh)$/s/ QUEUE_HOLD[^ ]* / /' $SUBPROJECT/config/steps > $SUBPROJECT/config/steps.final
fi

# Save variables related to previous SUBPROJECT
comm -23 <(set -o posix; set | sort) <(sort /tmp/amp.$STIME.set) | tr "=" "\t" | grep -v "^[a-z]" | grep -P -v "^PWD\t" | sed "s/'//g" > $SUBPROJECT/config/prev.txt
rm -f /tmp/amp.$STIME.set

# fix job dependencies
cd $SUBPROJECT
while read reg
do
	sed 's/QUEUE_SEP${'$reg'[^}]*}//' config/steps.final > config/steps.final.tmp && mv config/steps.final.tmp config/steps.final
done < <(sed -n '/^#/!{s/^.*QUEUE_HOLD\([^ ]*\).*$/\1/p;s/^.*QUEUE_HARRAY\([^ ]*\).*$/\1/p}' config/steps.final | sed 's/QUEUE_SEP/\n/' | sed 's/^[^a-z]*\([a-z_]*\)[^a-z]*$/\1/' | sed '/^$/d' | sort -u | join -v 1 - <(sed -n '/^#/!s/=.*$//p' config/steps.final | sort))
QUEUE_HANG=$(echo QUEUE_HOLD | sed 's/QUEUE_SEP$//') && QUEUE_AHANG=$(echo QUEUE_HARRAY | sed 's/QUEUE_SEP$//') && sed 's/ '"$QUEUE_HANG"' / /;s/ '"$QUEUE_AHANG"' / /' config/steps.final > config/steps.final.tmp && mv config/steps.final.tmp config/steps.final

# Add account/project name to queuing commands
if [ ! -z $DELTAMP_ACCOUNT ]
then
	sed "s/QUEUE_SUB/QUEUE_SUB QUEUE_ACCOUNT $DELTAMP_ACCOUNT/" config/steps.final > config/steps.final.tmp && mv config/steps.final.tmp config/steps.final
fi
cd $OUT_PATH/$PROJECT

# Tree 
sed '/^#/d;s/^.* '${DELTAMP_VER}.'\([^\.]*\)'.$SUBPROJECT' .*$/\1\tx/' $SUBPROJECT/config/steps.final | sort | join -a 2 -2 2 -o 2.1,0,1.2 -e "." -t $'\t' - <(nl $BIN/ref.steps.$TECH | sort -k 2,2) | sort -k 1,1n | cut -f 2- > $SUBPROJECT/config/steps.summary
if [ $REF_SUBPROJECT != "no" ]
then
	if [ -f $REF_SUBPROJECT/config/tree.summary ]
	then
		PARAM=`cat <(sed '1,/^Parameters$/d' $REF_SUBPROJECT/config/tree.summary | cut -f 1) <(echo ${TMP_DIF[$REF_SUBPROJECT]} | tr "#" "\n") | sort -u`
		ALL_PREV=(`head -1 $REF_SUBPROJECT/config/tree.summary | cut -f 2- | paste - <(echo $SUBPROJECT)`)
		cat <(paste <(sed '/^Parameters$/,$d' $REF_SUBPROJECT/config/tree.summary) <(cat <(echo $SUBPROJECT) <(cut -f 2 $SUBPROJECT/config/steps.summary))) <(echo Parameters) <(paste <(echo $PARAM | tr " " "\n") <(for i in "${ALL_PREV[@]}"; do grep "$(echo $PARAM | sed 's/^/\^/;s/ /[ \t]\\\|\^/g;s/$/[ \t]/')" $i/config/env.txt | cut -d " " -f 2 | tr "\n" "\t" | sed 's/\t$/\n/' ; done | transpose_tab)) > $SUBPROJECT/config/tree.summary
	else
		cat <(echo -e "Steps\t$REF_SUBPROJECT\t$SUBPROJECT") <(paste $REF_SUBPROJECT/config/steps.summary <(cut -f 2 $SUBPROJECT/config/steps.summary)) <(echo Parameters) <(join -a 1 -a 2 -o 0,1.2,2.2 -e "NA" <(grep "$(echo ${TMP_DIF[$REF_SUBPROJECT]} | sed 's/^/\^/;s/#/[ \t]\\\|\^/g;s/$/[ \t]/')" $REF_SUBPROJECT/config/env.txt | sort -k 1,1) <(grep "$(echo ${TMP_DIF[$REF_SUBPROJECT]} | sed 's/^/\^/;s/#/[ \t]\\\|\^/g;s/$/[ \t]/')" $SUBPROJECT/config/env.txt | sort -k 1,1) | tr " " "\t") > $SUBPROJECT/config/tree.summary
	fi
fi

# Execution
if [ $DRY == "yes" ]
then
	declare -a TITLE=("deltamp options" "new SUBPROJECT" "use of previous SUBPROJECT" "Commands to be passed to queuing system")
	echo "DRY RUN"
	echo ""
	printf '%'$((${#TITLE[0]}+9))'s\n' |tr " " "#"
	echo "### ${TITLE[0]}: ###"
	printf '%'$((${#TITLE[0]}+9))'s\n' |tr " " "#"
	printf 'dry run\t%s\nclean after dry run\t%s\ncheckpointing allowed\t%s\ndemultiplexing only\t%s\nquality check only\t%s\nreference subproject\t%s\nconfiguration file\t%s\n' "$DRY" "$CLEAN" "$CHECKP" "$DEMULTI_ONLY" "$QUAL_ONLY" "$REF_SUBPROJECT" "$METAD" | column -t -s $'\t'
	echo ""
	printf '%'$((${#TITLE[1]}+9))'s\n' |tr " " "#"
	echo "### ${TITLE[1]}: ###"
	printf '%'$((${#TITLE[1]}+9))'s\n' |tr " " "#"
	if [ $CLEAN == "no" ]
	then
		echo "The newly created subproject directory is $OUT"
	else
		echo "The newly created subproject directory would have been $OUT"
	fi
	echo ""
	if [ $REF_SUBPROJECT != "no" ]
	then
		printf '%'$((${#TITLE[2]}+9))'s\n' |tr " " "#"
		echo "### ${TITLE[2]}: ###"
		printf '%'$((${#TITLE[2]}+9))'s\n' |tr " " "#"
		echo "The initial steps of the pipeline are identical to $REF_SUBPROJECT (until ${LAST_REF} step)."
		echo "deltamp execution will begin with ${ADD_CUT_DB}${FIRST_STEP} step."
		echo ""
		echo "The following parameters differ between both SUBPROJECTs:"
		join -a 1 -a 2 -o 0,1.2,2.2 -e "NA" <(sort -k 1,1 $SUBPROJECT/config/env.txt | grep -v "${SUBPROJECT##*_}\|START\|CITATION\|VERSION\|ARGUMENTS\|CHIMERA[12]\|NBRUN") <(sort -k 1,1 $REF_SUBPROJECT/config/env.txt | grep -v "${REF_SUBPROJECT##*_}\|START\|CITATION\|VERSION\|ARGUMENTS\|CHIMERA[12]\|NBRUN") | awk '$2!=$3{print $1"\t"$2"\t"$3}' | cat <(echo -e "Parameter\tCurrent SUBPROJECT\tPrevious SUBPROJECT") - > $SUBPROJECT/config/prev.diff.txt
		column -t -s $'\t' $SUBPROJECT/config/prev.diff.txt
		echo ""
	fi
	printf '%'$((${#TITLE[3]}+9))'s\n' |tr " " "#"
	echo "### ${TITLE[3]}: ###"
	printf '%'$((${#TITLE[3]}+9))'s\n' |tr " " "#"
	grep -v "^#" $SUBPROJECT/config/steps.final
	echo ""
	echo "END DRY RUN"
	if [ $CLEAN == "yes" ]
	then
		rm -r $SUBPROJECT
		if [ ! "$(ls -A)" ] ; then cd .. && rmdir $PROJECT ; fi
	fi
	exit 0
else
	if [ $REF_SUBPROJECT != "no" ]
	then
		if [ $DRY == "no" ] && [ ! -z "$(grep "DRY yes" $REF_SUBPROJECT/config/env.txt)" ]
		then
			rm -r $SUBPROJECT
			if [ ! "$(ls -A)" ] ; then cd .. && rmdir $PROJECT ; fi
			error_doc "the previous subproject $REF_SUBPROJECT was a DRY RUN only.\nRemove $REF_SUBPROJECT from $OUT_PATH/$PROJECT or provide another output directory in the configuration file."
		fi
	fi
	cd $EXEC_PATH
	mkdir $SUBPROJECT
	cd $SUBPROJECT
	mkdir config log
	for i in $OUT/config/*; do dd if=$i of=$EXEC/config/${i##*/} bs=1M > log/deltamp.log 2>&1 ; done
	if [ $REF_SUBPROJECT == "no" ]
	then
		mkdir archives archives/$SUBPROJECT.outputs archives/$SUBPROJECT.processing processing libraries quality_check
		ln -s $EXEC/config/configuration.$SUBPROJECT.tsv $EXEC/archives/$SUBPROJECT.outputs
	fi
	#paste <(date +%F -d @$START_TIME) <(date +%T -d @$START_TIME) <(echo -e "${VERSION[DELTAMP]}\t$USER\t$INIT_DIR\t$ARGUMENTS\t$SUBPROJECT") >> ${DELTAMP_BUILD%/*}/history
	echo "###"
	echo "execution of deltamp version ${VERSION[DELTAMP]} for the SUBPROJECT $SUBPROJECT"
	echo "###"
	bash <(sed '/^#/!{p;s/^\([^=]*\)=\$(.*QUEUE_JOBNAME \([^ ]*\) .*$/echo $\1 \2/}' config/steps.final) 2> log/deltamp.log > config/jobid
fi
