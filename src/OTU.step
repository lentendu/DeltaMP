# 
# DeltaMP, a flexible, reproducible and resource efficient metabarcoding amplicon pipeline for HPC
# Copyright (C) 2018 Guillaume Lentendu, Christina Wei√übecker, Anna Heintz-Buschart, Tesfaye Wubet
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# 

# load modules
module load DeltaMP/DELTAMP_VERSION

# Define Variables
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/env.txt
while read var val; do unset $var ; if [[ $val == "(["* ]]; then declare -A $var="`echo $val | sed 's/].\"/]=\"/g'`" ; else declare $var="$val" ; fi ; done < config/prev.txt
. $BIN/check_previous_step

# record newly set variables
(set -o posix; set > config/OTU.set)
set -- config/*missing
if [ -f "$1" ]
then
	SAMP_NAME=$(cut -f 1 config/lib4.list | join -v 1 - <(cat config/*missing | sort))
else
	SAMP_NAME=$(cut -f 1 config/lib4.list)
fi
cd processing

# Merge all sample's fasta and count files (removing gaps if any)
if [ $ASV == "no" ]
then
	export EXT DECOMP SAMP_NAME BIN
	parallel -j $NCPUS -k 'FASTA=$(sed -n "/^fasta=/{s/.*=//;p}" {}/current_files.summary); eval $DECOMP {}/$FASTA.$EXT | sed "/>/!s/[-\.]//g"' ::: $SAMP_NAME > $SUBPROJECT.fasta
	parallel -j $NCPUS -k 'COUNT=$(sed -n "/^count=/{s/.*=//;p}" {}/current_files.summary); eval $DECOMP {}/$COUNT.$EXT | sed "1d;s/$/\t{}/"' ::: $SAMP_NAME > $SUBPROJECT.groups
	
	# If denoised 454 reads, no ITSx extraction and reverse primer not removed, chop to the same length
	if [ "$DENOISE" == "yes" ] && [ $ITSX == "no" ] && [ $CLIPPING != "both" ]
	then
		LENGTH=`cut -d "." -f 1 $EXEC/quality_check/trimming.parameters.txt`
		MIN_LENGTH=`awk -v L=$LENGTH 'BEGIN{min=L} $1!~"^>" && length($1)<min{min=length($1)}END{print min}' $SUBPROJECT.fasta`
		seqkit subseq -w 0 -r 1:$MIN_LENGTH $SUBPROJECT.fasta | sed 's/_SUB.*$//' > $SUBPROJECT.tmp.fasta && mv $SUBPROJECT.tmp.fasta $SUBPROJECT.fasta
	fi
	
	# Dereplicate
	vsearch --no_progress --derep_fulllength $SUBPROJECT.fasta --relabel_sha1 --output - --uc $SUBPROJECT.uc | seqkit seq -w0 > $SUBPROJECT.unique.fasta
	sed -n '/>/s/>//p' $SUBPROJECT.unique.fasta | paste - <(grep '^[SH]' $SUBPROJECT.uc | awk '{if(NR==1){printf "%s",$9} else {if($10=="*"){printf "\n%s",$9} else {printf ",%s",$9}}}END{printf "\n"}') > $SUBPROJECT.names
	FASTA=$SUBPROJECT.unique
	NAMES=$SUBPROJECT
	echo -e "FASTA=$FASTA\nNAMES=$NAMES" > current_files.summary
	
	# count table
	tr "," " " < $NAMES.names | awk '{for(i=2;i<=NF;i++){print $i,$1}}' | sort --parallel=$NCPUS -k 1,1 | join -o 1.2,0,2.3,2.2 - <(sort --parallel=$NCPUS -k 1,1 $SUBPROJECT.groups) | sort --parallel=$NCPUS -k 1,1 -k 3,3 | awk '$1!=p{p=$1;sub("^",">",$1)} {print}' | parallel -j $NCPUS --recstart ">" --remove-rec-sep --pipe -k "awk -v S=$(echo $SAMP_NAME | sed 's/ /#/g') -f $BIN/make_count.awk" | cat <(echo Representative_Sequence total $SAMP_NAME | tr " " "\t") - > $FASTA.count_table
	eval $(echo COUNT=$FASTA | tee -a current_files.summary)
	rm $SUBPROJECT.fasta $SUBPROJECT.groups $SUBPROJECT.uc
else
	if [ $PERRUN == "no" ]
	then
		# pool all prior ASVs and dereplicate them
		for i in ${FWD_NAME} ${RVS_NAME}
		do
			if [ $i == "$FWD_NAME" ] ; then j=${RVS_NAME} ; else j=${FWD_NAME} ; fi
			if [ ! -z "$(find ./ -name $i.*.fwd.filtered.derep)" ]
			then
				cat */$i.*.fwd.asv.fasta | vsearch --quiet --derep_fulllength - --relabel_sha1 --output - | twofasta > $i.fwd.fasta
				cat */$j.*.rvs.asv.fasta | vsearch --quiet --derep_fulllength - --relabel_sha1 --output - | twofasta > $j.rvs.fasta
			fi
		done
	fi
fi

# Clustering
SIM=`awk -v T=$TRESH 'BEGIN{print T/100}'`
DISIM=`awk -v S=$SIM 'BEGIN{print 1-S}'`

if [ $CLUST == "cd-hit-est" ]
then
	paste - - < $FASTA.fasta | sed 's/>//;s/ size=[^ \t]*//' | sort -k 1,1 | join - <(sed '1d' $COUNT.count_table | cut -f 1,2 | sort -k 1,1) | sort -k 3,3nr | awk '{print ">"$1"\n"$2}' > $FASTA.sort.fasta
	if [ $PREV_PATH == "no" ]
	then
		cd-hit-est -T $NCPUS -M 0 -c $SIM -r 0 -g 1 -d 0 -i $FASTA.sort.fasta -o $FASTA.cdhit.fasta
		awk '{if($1~">"){otu=$2} else print $3,$4,otu}' $FASTA.cdhit.fasta.clstr | sed 's/>//;s/\.\.\.//;s/*/S/;s/at/H/' | sort -k 1,1 | join - <(sed '1d' $COUNT.count_table | sort -k 1,1) | sort -k 3,3n -k 2,2r | cut -d " " -f 1,3- | awk -f $BIN/sum_count.awk | cat <(head -1 $COUNT.count_table) - > $COUNT.cdhit.count_table
		sed 's/\.\.\.//;s/>//' $FASTA.cdhit.fasta.clstr | awk '{if($4~"\\*"){print $3"\t"$3} else if($4=="at"){print ","$3}}' | sed -e :a -e '$!N;s/\n,/,/;ta' -e 'P;D' > $FASTA.cdhit.names
		rm $FASTA.cdhit.fasta.clstr
	else
		## to fix ##
		cdhit2mothur-2d () {
			clstr=$1 ; db1=$2 ; db2=$3 ; names=$4 ; tresh=$5
			# Keep only OTUs with sequences from db2 and output their representative sequences (the most abundant variant, if tie then the variant with highest similarity to db1 seed)
			awk '{if($1~"^>"){otu=$2} else {if(NF<5){print otu,$3,"100"} else print otu,$3,$5}}' $clstr | sed 's/>//;s/\.\.\.//;s/+\///;s/%//' | sort -k 2,2 | join -v 1 -1 2 - <(awk '$1~">"{sub(">","",$1);print $1}' $db1 | sort) | join - <(sort $names) | awk '{print $1,$2,$3,split($4,a,","),$4}' | sort -k 2,2n -k 4,4nr -k 3,3nr | tee tmp.$clstr | awk '{if(NR==1){otu=$2;print $1} else if($2!=otu){otu=$2;print $1}}' > repseq.$clstr
			seqkit grep -f repseq.$clstr $db2 > ${clstr%.*}
			size=`sed -n '$=' repseq.$clstr`
			awk -v L=${#size} '{if(NR==1){printf "%s%0"L"d\t%s", "Otu",$2+1,$5;prev=$2} else if($2==prev){printf ",%s",$5} else printf "\n%s%0"L"d\t%s", "Otu",$2+1,$5;prev=$2}END{printf "\n"}' tmp.$clstr | cat <(echo -e "label\t"$tresh) <(echo -e "numOtus\t"$size) - | tee tmp2.$clstr | transpose > ${names%.*}.cdhit.list
			sed '1,2d' tmp2.$clstr | awk '{split($2,a,",");print a[1]"\t"$2}' > ${names%.*}.cdhit.names
			rm repseq.$clstr tmp.$clstr tmp2.$clstr
			echo "cdhit2mothur output files:#${clstr%.*}#${names%.*}.cdhit.list#${names%.*}.cdhit.names" | tr "#" "\n"
		}
		PREV_SUB=${PREV_PATH##*/}
		tar -xzvf $PREV_PATH/$PREV_SUB.processing.files.tar.gz $PREV_SUB.processing/$PREV_SUB.*cdhit.names
		tar -xzvf $PREV_PATH/$PREV_SUB.processing.files.tar.gz $PREV_SUB.processing/$PREV_SUB.*cdhit.fasta
		mv $PREV_SUB.processing*/* ./
		rm -r $PREV_SUB.processing*
		REP_N=`ls $PREV_SUB.*cdhit.names | sed 's/\.names//'`
		REP_F=`ls $PREV_SUB.*cdhit.fasta | sed 's/\.fasta//'`
		sed '/>/G' $REP_F.fasta |  sed -e :a -e '$!N;/>/!s/\n//;ta' -e 'P;D' | paste - - | sed 's/>//' | sort -k 1,1 | join -o 2.2,0,1.2 - <(awk '{print $1,NR}' $REP_N.names | sort -k 1,1) | sort -k 1,1n | cut -d " " -f 2,3 | sed 's/^/>/;s/ /\n/' > $REP_F.sort.fasta
		cd-hit-est-2d -T $NCPUS -M 0 -c $SIM -r 0 -g 1 -d 0 -i $REP_F.sort.fasta -i2 $FASTA.sort.fasta -o $FASTA.cdhit.db1_db2.fasta
		cd-hit-est -c $SIM -r 0 -g 1 -d 0 -i $FASTA.cdhit.db1_db2.fasta -o $FASTA.cdhit.db2.fasta
		cat $FASTA.cdhit.db1_db2.fasta.clstr $FASTA.cdhit.db2.fasta.clstr | clstr_renumber.pl > $FASTA.cdhit.fasta.clstr
		cdhit2mothur-2d $FASTA.cdhit.fasta.clstr $REP_F.sort.fasta $FASTA.fasta $NAMES.names $DISIM
		####
	fi
	FASTA_OTUS=$FASTA.cdhit
	NAMES_OTUS=$FASTA.cdhit
	COUNT_OTUS=$COUNT.cdhit

elif [ $CLUST == "sumaclust" ]
then
	paste - - < $FASTA.fasta | sed 's/>//;s/ size=[^ \t]*//' | sort -k 1,1 | join - <(sed '1d' $COUNT.count_table | cut -f 1,2 | sort -k 1,1) | sort -k 3,3nr | awk '{print ">"$1" count="$3";\n"$2}' > $FASTA.sort.fasta
	sumaclust -t $SIM -p $NCPUS -e -O $FASTA.suma.map $FASTA.sort.fasta | seqkit grep -nr -w 0 -p "cluster_center=True" | sed -r 's/ .*cluster_weight=([0-9]*).*$/ \1/' | paste - - | sort -k 2,2nr | awk '{print $1";size="$2"\n"toupper($3)}' > $FASTA.suma.fasta
	sed 's/\t/###/;s/\t/,/g;s/###/\t/' $FASTA.suma.map | sort -k 1,1 | join -1 2 <(sed -n '/>/{s/>//;p}' $FASTA.suma.fasta | nl | sort -k 2,2) - | sort -k 2,2n | awk '{print $1"\t"$3}' > $FASTA.suma.names
	awk '{print $2,"S",NR;for(i=3;i<=NF;i++){print $i,"H",NR}}' $FASTA.suma.map | sort -k 1,1 | join - <(sed '1d' $COUNT.count_table | sort -k 1,1) | sort -k 3,3n -k 2,2r | cut -d " " -f 1,3- | awk -f $BIN/sum_count.awk | cat <(head -1 $COUNT.count_table) - > $COUNT.suma.count_table
	FASTA_OTUS=$FASTA.suma
	NAMES_OTUS=$FASTA.suma
	COUNT_OTUS=$COUNT.suma
	rm $FASTA.suma.map $FASTA.sort.fasta

elif [ $CLUST == "mcl" ]
then
	sumatra -t $SIM -p $NCPUS -g $FASTA.fasta > $FASTA.simil
	mcxload -abc $FASTA.simil -write-tab $FASTA.mcl.dico -o $FASTA.mcl.load
	mcl $FASTA.mcl.load -I 1.2 -te $NCPUS -o $FASTA.mcl.clust
	mcxdump -imx $FASTA.mcl.clust -tabr $FASTA.mcl.dico --lazy-tab --no-values -o - | sort -k 2,2 | join -1 2 - <(sort -k 1,1 $COUNT.count_table) | sort -k 2,2n -k 3,3nr | awk -f $BIN/sum_count.awk | cat <(head -1 $COUNT.count_table) - > $COUNT.mcl.count_table
	mcxdump -icl $FASTA.mcl.clust -tabr $FASTA.mcl.dico --lazy-tab --no-values -o - | tr "\t" "," | paste <(sed '1d' $COUNT.mcl.count_table | cut -f 1) - > $FASTA.mcl.names
	seqkit grep -f <(sed '1d' $COUNT.mcl.count_table | cut -f 1) $FASTA.fasta | twofasta > $FASTA.mcl.fasta
	FASTA_OTUS=$FASTA.mcl
	NAMES_OTUS=$FASTA.mcl
	COUNT_OTUS=$COUNT.mcl
	rm $FASTA.simil $FASTA.mcl.dico $FASTA.mcl.load $FASTA.mcl.clust

elif [ $CLUST == "vsearch" ]
then
	paste - - < $FASTA.fasta | sed 's/>//' | sort -k 1,1 | join - <(sed '1d' $COUNT.count_table | sort -k 1,1) | sort -k 3,3nr | awk '{print ">"$1";size="$3"\n"$2}' > $FASTA.sort.fasta
	vsearch --quiet --threads $NCPUS --cluster_smallmem $FASTA.sort.fasta --usersort --id $SIM --centroids $FASTA.vsearch.fasta --xsize -uc $FASTA.uc
	grep -P -v "^C\t" $FASTA.uc | cut -f 1,2,9 | sed 's/;size=.*//' | sort -k 2,2n -k 1,1r | awk '{if($1=="S"){print $3"\t"$3} else print","$3}' | sed -e :a -e '$!N;s/\n,/,/;ta' -e 'P;D' > $FASTA.vsearch.names
	grep -P -v "^C\t" $FASTA.uc | cut -f 1,2,9 | sed 's/;size=.*//' | sort -k 3,3 | join -1 3 - <(sed '1d' $COUNT.count_table | sort -k 1,1) | sort -k 3,3n -k 2,2r | cut -d " " -f 1,3- | awk -f $BIN/sum_count.awk | cat <(head -1 $COUNT.count_table) - > $COUNT.vsearch.count_table
	FASTA_OTUS=$FASTA.vsearch
	NAMES_OTUS=$FASTA.vsearch
	COUNT_OTUS=$COUNT.vsearch
	rm $FASTA.uc $FASTA.sort.fasta

elif [ $CLUST == "swarm" ]
then
	paste - - < $FASTA.fasta | sed 's/>//;s/ size=[^ \t]*//' | sort -k 1,1 | join - <(sed '1d' $COUNT.count_table | cut -f 1,2 | sort -k 1,1) | sort -k 3,3nr | awk '{print ">"$1";size="$3"\n"$2}' > $FASTA.sort.fasta
	MEM=`awk -v N=$NCPUS 'BEGIN{print 4000*N}'`
	swarm -f -z -c $MEM -t $NCPUS -w - -o $FASTA.swarm.tmp.names -u $FASTA.swarm -i $SUBPROJECT.internal.swarm.txt $FASTA.sort.fasta | sed '/>/s/;.*//' > $FASTA.swarm.fasta
	grep -P -v "^C\t" $FASTA.swarm | cut -f 1,2,9 | sed 's/;size=.*//' | sort -k 3,3 | join -1 3 - <(sed '1d' $COUNT.count_table | sort -k 1,1) | sort -k 3,3n -k 2,2r | cut -d " " -f 1,3- | awk -f $BIN/sum_count.awk | cat <(head -1 $COUNT.count_table) - > $COUNT.swarm.count_table
	sed 's/;size=[0-9]*//g;s/^\([^ ]*\)/\1\t\1/;s/ /,/g' $FASTA.swarm.tmp.names > $FASTA.swarm.names
	FASTA_OTUS=$FASTA.swarm
	NAMES_OTUS=$FASTA.swarm
	COUNT_OTUS=$COUNT.swarm
	rm $FASTA.swarm $FASTA.swarm.tmp.names $FASTA.sort.fasta

elif [ $CLUST == "dada2" ]
then
	if [ $PERRUN == "no" ]
	then
		# pseudo-pool approach
		Rscript --vanilla $BIN/Rscript_dada2_all_libraries.R $NCPUS $SUBPROJECT $FWD_NAME $RVS_NAME $MIN_OV $PTRESH $MINLEN
		find ./ -type f -name "*.index" | parallel eval $COMP
	elif [ $PERRUN == "yes" ]
	then
		# finalise pooled approach
		Rscript --vanilla $BIN/Rscript_dada2_run.R $NCPUS $SUBPROJECT $MINLEN
	fi
	FASTA_OTUS=$SUBPROJECT.dada2
	COUNT_OTUS=$SUBPROJECT.dada2
	NAMES_OTUS=$SUBPROJECT.dada2
	# create the names file (index in the asv.index file correspond to the seqeunce position in the filtered.fastq file) 
	match_index () {
		i=$1
		for j in $i/*fwd.filtered.derep
		do
			eval $DECOMP ${j%.*}.fastq | sed -n '1~4{s/^@//;s/ .*//;p}' | nl -n ln | sort -k 1,1 | join -o 2.2,1.2 - <(eval $DECOMP ${j%.*}.asv.index.$EXT | sort -k 2,2 | join -1 2 -o 1.1,0 - <(grep "^>" $FASTA_OTUS.fasta | sed 's/>//' | sort) | sort -k 1,1)
		done
	}
	export -f match_index
	export FASTA_OTUS DECOMP EXT
	parallel -j $NCPUS match_index ::: $SAMP_NAME | sort --parallel=$NCPUS -k 1,1 | awk '{if(NR==1){p=$1;print p"\t"$2} else {if($1==p){print ","$2} else {p=$1;print p"\t"$2}}}' | perl -0pe 's/\n,/,/g' > ${NAMES_OTUS}.names
fi

# Remove singletons
if [ $DEL_SING == "yes" ]
then
	awk 'NR==1 || $2>1{print}' $COUNT_OTUS.count_table | tee $COUNT_OTUS.pick.count_table | awk 'NR>1{print $1}' > $COUNT_OTUS.singletons.accnos
	seqkit grep -w0 -f $COUNT_OTUS.singletons.accnos $FASTA_OTUS.fasta > $FASTA_OTUS.pick.fasta
	nl $NAMES_OTUS.names | sort -k 2,2 -t $'\t' | join -1 2 -t $'\t' - <(sort -k 1,1 $COUNT_OTUS.singletons.accnos) | sort -k 2,2n -t $'\t' | cut -f 1,3 > $NAMES_OTUS.pick.names
	rm $FASTA_OTUS.fasta $NAMES_OTUS.names
	FASTA_OTUS=$FASTA_OTUS.pick
	NAMES_OTUS=$NAMES_OTUS.pick
	if [ $CLUST != "dada2" ]
	then
		cut -f 2 $NAMES_OTUS.names | tr "," "\n" > $NAMES_OTUS.accnos
		seqkit grep -f $NAMES_OTUS.accnos $FASTA.fasta > $FASTA.nochim.fasta
		sort $NAMES_OTUS.accnos | join -t $'\t' - <(sed '1d' $COUNT.count_table) | cat <(head -1 $COUNT.count_table) - > $COUNT.nochim.count_table
		sort -k 1,1 -t $'\t' $NAMES.names | join -t $'\t' - <(sort $NAMES_OTUS.accnos) > $NAMES.nochim.names
		rm $FASTA.fasta $COUNT.count_table
		sed -i '/^FASTA=/d;/^COUNT=/d;/^NAMES=/d' current_files.summary
		eval $(echo FASTA=$FASTA.nochim | tee -a current_files.summary)
		eval $(echo COUNT=$COUNT.nochim | tee -a current_files.summary)
		eval $(echo NAMES=$NAMES.nochim | tee -a current_files.summary)
		rm $NAMES_OTUS.accnos
	fi
	rm $COUNT_OTUS.count_table $COUNT_OTUS.singletons.accnos
	COUNT_OTUS=$COUNT_OTUS.pick
fi

# Chimera recheck
if [ $CHIMERA2 == "yes" ]
then
	awk '{print $1}' $FASTA_OTUS.fasta | twofasta | paste - - | sed 's/^>//' | nl | sort -k 2,2 | join -1 2 - <(sed '1d' $COUNT_OTUS.count_table | cut -f 1,2 | sort -k 1,1) | sort -k4,4nr -k2,2n | awk '{print ">"$1";size="$4"\n"$3}' > $FASTA_OTUS.sort.fasta
	vsearch --no_progress --uchime_denovo $FASTA_OTUS.sort.fasta --xsize --nonchimeras - | twofasta > $FASTA_OTUS.nochim.fasta
	sed -n '/^>/{s/>//;p}' $FASTA_OTUS.nochim.fasta | nl -s $'\t' -n ln | sort -k 2,2 -t $'\t' | join -t $'\t' -1 2 - <(sed '1d' $COUNT_OTUS.count_table | sort -k 1,1 -t $'\t') | sort -k 2,2n -t $'\t' | cut -f 1,3- | cat <(head -1 $COUNT_OTUS.count_table) - | tee $COUNT_OTUS.nochim.count_table | awk 'NR>1{print $1}' > $COUNT_OTUS.nochim.accnos
	if [ $CLUST == "dada2" ]
	then
		nl $NAMES_OTUS.names | sort -k 2,2 -t $'\t' | join -1 2 -t $'\t' - <(sort -k 1,1 $COUNT_OTUS.nochim.accnos) | sort -k 2,2n -t $'\t' | cut -f 1,3 > $NAMES_OTUS.pick.names
		rm $NAMES_OTUS.names
		NAMES_OTUS=$NAMES_OTUS.pick
	else
		awk '{print $1"\t"NR}' $COUNT_OTUS.nochim.accnos | sort -k 1,1 -t $'\t' | join -t $'\t' - <(sort -k 1,1 -t $'\t' $NAMES_OTUS.names) | sort -k 2,2n -t $'\t' | cut -f 1,3 > $NAMES_OTUS.nochim.names
		rm $NAMES_OTUS.names
		NAMES_OTUS=$NAMES_OTUS.nochim
		cut -f 2 $NAMES_OTUS.names | tr "," "\n" > $NAMES_OTUS.accnos
		seqkit grep -f $NAMES_OTUS.accnos $FASTA.fasta > $FASTA.nochim.fasta
		sort $NAMES_OTUS.accnos | join -t $'\t' - <(sed '1d' $COUNT.count_table) | cat <(head -1 $COUNT.count_table) - > $COUNT.nochim.count_table
		sort -k 1,1 -t $'\t' $NAMES.names | join -t $'\t' - <(sort $NAMES_OTUS.accnos) > $NAMES.nochim.names
		rm $FASTA.fasta $COUNT.count_table
		sed -i '/^FASTA=/d;/^COUNT=/d;/^NAMES=/d' current_files.summary
		eval $(echo FASTA=$FASTA.nochim | tee -a current_files.summary)
		eval $(echo COUNT=$COUNT.nochim | tee -a current_files.summary)
		eval $(echo NAMES=$NAMES.nochim | tee -a current_files.summary)
		rm $NAMES_OTUS.accnos
	fi
	rm $FASTA_OTUS.sort.fasta $FASTA_OTUS.fasta $COUNT_OTUS.count_table $COUNT_OTUS.nochim.accnos
	FASTA_OTUS=$FASTA_OTUS.nochim
	COUNT_OTUS=$COUNT_OTUS.nochim
fi


# grafting OTUs with previous subproject OTUs
if [ $PREV_PATH != "no" ]
then
	if [ $CLUST == "dada2" ]
	then
		# grafting already included in dada2 scripts, only need to separate new from previous ASVs
		PREV_ASV=${PREV_SUB}.all_repseq
		grep ">" $FASTA_OTUS.fasta | sort | join - <(grep ">" ${PREV_SUB}.outputs/${PREV_ASV}.fasta | sort) | sed 's/>//' > to_exclude.accnos
	else
		# access previous subproject OTUs and amplicons
		tar xzvf $PREV_PATH/$PREV_SUB.processing.files.tar.gz $PREV_SUB.processing/OTU_env.txt
		while read var val; do unset $var ; declare $var="$val" ; done < <(grep "^[FNC][AO]" $PREV_SUB.processing/OTU_env.txt | sed 's/^/PREV_/')
		tar xzvf $PREV_PATH/$PREV_SUB.processing.files.tar.gz $PREV_SUB.processing/$PREV_FASTA.fasta $PREV_SUB.processing/$PREV_COUNT.count_table $PREV_SUB.processing/$PREV_NAMES_OTUS.names
		sed 's/[; ]*size=\([0-9]*\).*$//' $PREV_SUB.processing/$PREV_FASTA.fasta | seqkit grep -w 0 -f <(awk -F'\t' -v I="$PREV_DOM" -'NR>1 && $2>=I{print $1}' $PREV_SUB.processing/$PREV_COUNT.count_table) > tmp_prev.fasta
		# find exact similar amplicons (not between singletons amplicons, allow internal matches) and the OTU they are belonging to
		sed 's/[; ]*size=\([0-9]*\).*$//' $FASTA.fasta | seqkit grep -w 0 -f <(awk -F'\t' -v I="$PREV_DOM" -'NR>1 && $2>=I{print $1}' $COUNT.count_table) | vsearch --usearch_global - --threads $NCPUS --db tmp_prev.fasta --id 1 --maxaccepts 0 --userfields query+target+id+ql+tl --userout - | awk -v P=${PREV_PERC} '($5>=$4 && $4>=$5*P/100) || ($4>=$5 && $5>=$4*P/100){print $1,$2}' > aa.tmp
		awk '{n=split($2,a,",");for(i in a){print a[i],$1,NR,n}}' $NAMES_OTUS.names | sort --parallel=$NCPUS -k 1,1 | join - <(sort -k 1,1 aa.tmp) | sort -k 5,5 | join -1 5 - <(awk '{n=split($2,a,",");for(i in a){print a[i],$1,NR,n}}' $PREV_SUB.processing/$PREV_NAMES_OTUS.names | sort --parallel=$NCPUS -k 1,1) | sort -k 3,3 -k 6,6 | awk '{if(NR==1){os=$3;op=$6;nos=$4;nop=$7;s=$2"|"$1;sos=$5;sop=$8} else {if($3==os && $6==op){s=s","$2"|"$1} else {print os,op,nos,nop,sos,sop,s;os=$3;op=$6;nos=$4;nop=$7;s=$2"|"$1;sos=$5;sop=$8}}}END{print os,op,nos,nop,sos,sop,s}' > otus.aa.tmp
		# report
		echo "There is $(sed -n '$=' aa.tmp) amplicons from $(cut -d " " -f 1 otus.aa.tmp | sort -u | wc -l) OTUs of $SUBPROJECT found in $(cut -d " " -f 2 otus.aa.tmp | sort -u | wc -l) OTUs of $PREV_SUB"
		cut -f 2 -d " " otus.aa.tmp | sort | uniq -c | awk '$1>1{print $2}' | sort | join -2 2 - <(sort -k 2,2 otus.aa.tmp) | awk '{if(NR==1){op=$1;os=$2} else {if($1==op){os=os" "$2} else {print op"\t"os;op=$1;os=$2}}}END{if(op!=""){print op"\t"os}}' > otus.aa.sopmos.tmp
		cut -f 1 -d " " otus.aa.tmp | sort | uniq -c | awk '$1>1{print $2}' | sort | join - <(sort -k 1,1 otus.aa.tmp) | awk '{if(NR==1){os=$1;op=$2} else {if($1==os){op=op" "$2} else {print os"\t"op;os=$1;op=$2}}}END{if(os!=""){print os"\t"op}}' > otus.aa.sosmop.tmp
		if [ -s otus.aa.sopmos.tmp ]
		then
			echo "Amplicons found in $(awk '{if(NR==1){m=NF-1;M=NF-1} else {if(NF-1>M){M=NF-1};if(NF-1<m){m=NF-1}}}END{print m" to "M}' otus.aa.sopmos.tmp) OTUs of $SUBPROJECT (total = $(awk '{s+=NF-1}END{print s}' otus.aa.sopmos.tmp) OTUs) were found in a single OTUs of $PREV_SUB (total = $(sed -n '$=' otus.aa.sopmos.tmp) OTUs)."
		fi
		if [ -s otus.aa.sosmop.tmp ]
		then
			echo "Amplicons found in a single OTU of $SUBPROJECT (total = $(sed -n '$=' otus.aa.sosmop.tmp) OTUs) were found in $(awk '{if(NR==1){m=NF-1;M=NF-1} else {if(NF-1>M){M=NF-1};if(NF-1<m){m=NF-1}}}END{print m" to "M}' otus.aa.sosmop.tmp) OTUs of $PREV_SUB (total = $(awk '{s+=NF-1}END{print s}' otus.aa.sosmop.tmp) OTUs)."
		fi
		echo "For $(($(sed -n '$=' otus.aa.tmp) - $(cut -f 2 otus.aa.sopmos.tmp | wc -w) - $(cut -f 2 otus.aa.sosmop.tmp | wc -w))) OTUS, amplicons of a single OTU of $SUBPROJECT were found in a single OTU of $PREV_SUB."
		# Remove OTUs for which amplicons were found in a single OTU of PREV_SUB
		sort -k 1,1 otus.aa.tmp | join -v 1 - otus.aa.sosmop.tmp | sort -k 3,3n | cut -d " " -f 1 > to_exclude.accnos
	fi
	mothur "#remove.seqs(accnos=to_exclude.accnos, fasta=$FASTA_OTUS.fasta, count=$COUNT_OTUS.count_table);
	get.current()"
	mv $FASTA_OTUS.fasta $PREV_SUB.match_otu.fasta
	mv $COUNT_OTUS.count_table $PREV_SUB.match_otu.count_table
	FASTA_OTUS=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
	COUNT_OTUS=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
	join -t $'\t' -v 2 to_exclude.accnos $NAMES_OTUS.names > $NAMES_OTUS.pick.names
	mv $NAMES_OTUS.names $PREV_SUB.match_otu.names
	NAMES_OTUS=$NAMES_OTUS.pick
	# Gather those OTUs in parallel files
	mothur "#get.seqs(accnos=to_exclude.accnos, fasta=$PREV_SUB.match_otu.fasta, count=$PREV_SUB.match_otu.count_table)"
	join -t $'\t' to_exclude.accnos $PREV_SUB.match_otu.names > $PREV_SUB.match_otu.pick.names
	if [ $CLUST != "dada2" ]
	then
		cut -f 2 $NAMES_OTUS.names | tr "," "\n" > $NAMES_OTUS.accnos
		mothur "#get.seqs(accnos=$NAMES_OTUS.accnos, fasta=$FASTA.fasta, count=$COUNT.count_table);
		get.current()"
		mv $FASTA.fasta $PREV_SUB.match.fasta
		mv $COUNT.count_table $PREV_SUB.match.count_table
		FASTA=`sed -n '/^fasta=/{s/.*=//;s/\.fasta//;p}' current_files.summary`
		COUNT=`sed -n '/^count=/{s/.*=//;s/\.count_table//;p}' current_files.summary`
		rm $NAMES_OTUS.accnos
		cut -f 2 $PREV_SUB.match_otu.pick.names | tr "," "\n" > $PREV_SUB.match_otu.pick.accnos
		mothur "#get.seqs(accnos=$PREV_SUB.match_otu.pick.accnos, fasta=$PREV_SUB.match.fasta, count=$PREV_SUB.match.count_table)"
		rm $PREV_SUB.match.fasta $PREV_SUB.match.count_table $PREV_SUB.match_otu.pick.accnos
	fi
	rm to_exclude.accnos $PREV_SUB.match_otu.fasta $PREV_SUB.match_otu.count_table $PREV_SUB.match_otu.names
fi

# Save newly set and updated variables
cd ..
unset SAMP_NAME
comm -23 <(set -o posix; set | sort) <(sort config/OTU.set) | tr "=" "\t" | grep -v "^[a-z]" | grep -P -v "^PWD\t" | sed "s/'//g" > config/OTU_env.txt
rm config/OTU.set

# list files and directories
(. $BIN/list_step_files.sh)

echo END
